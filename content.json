{"meta":{"title":"静默的魔法书","subtitle":"零","description":"A Salty Fish","author":"Hans Chung","url":"http://www.zhz.gift"},"pages":[{"title":"About Me","date":"2017-11-18T11:35:43.000Z","updated":"2017-11-18T11:58:26.965Z","comments":true,"path":"about/index.html","permalink":"http://www.zhz.gift/about/index.html","excerpt":"","text":"I’m only a salty fish.. i will make more efforts.i promise..maybe"},{"title":"tags","date":"2018-01-09T11:10:05.000Z","updated":"2018-01-09T14:05:39.629Z","comments":true,"path":"tags/index.html","permalink":"http://www.zhz.gift/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Docker Java教程4：运行一个Docker 容器","slug":"Docker Java教程4：运行一个Docker 容器","date":"2018-05-10T15:09:42.000Z","updated":"2018-05-10T13:22:07.120Z","comments":true,"path":"2018/05/10/Docker Java教程4：运行一个Docker 容器/","link":"","permalink":"http://www.zhz.gift/2018/05/10/Docker Java教程4：运行一个Docker 容器/","excerpt":"使用Docker运行一个应用的方式就是运行一个容器.如果你考虑使用一个开源的软件,那么有很大的可能Docker Store 已经有对应的Docker 镜像了.Docker 客户端能够通过镜像名称轻松地运行这个容器.客户端首先会检查Docker Host是否存在这个镜像,如果存在，则直接运行容器，否则host会首先去下载镜像.","text":"使用Docker运行一个应用的方式就是运行一个容器.如果你考虑使用一个开源的软件,那么有很大的可能Docker Store 已经有对应的Docker 镜像了.Docker 客户端能够通过镜像名称轻松地运行这个容器.客户端首先会检查Docker Host是否存在这个镜像,如果存在，则直接运行容器，否则host会首先去下载镜像. 拉取镜像运行容器交互式地隔离的容器使用默认端口使用指定的端口部署一个war文件到应用服务器停止容器移除容器端口映射的额外方式 拉取镜像 查看可用镜像: docker image ls 输出如下: REPOSITORY TAG IMAGE ID CREATED SIZE hellojava latest 8d76bf5691c4 32 minutes ago 740MB hello-java latest 93b1180c5d91 36 minutes ago 740MB helloworld 2 7fbedda27c66 41 minutes ago 1.13MB 更多关于镜像的细节可以使用docker image history jboss/wildfly命令: IMAGE CREATED CREATED BY SIZE COMMENT 9adbdb00cded 8 days ago /bin/sh -c #(nop) CMD [&quot;/opt/jboss/wildfl... 0B &lt;missing&gt; 8 days ago /bin/sh -c #(nop) EXPOSE 8080/tcp 0B &lt;missing&gt; 8 days ago /bin/sh -c #(nop) USER [jboss] 0B &lt;missing&gt; 8 days ago /bin/sh -c #(nop) ENV LAUNCH_JBOSS_IN_BAC... 0B 运行容器 交互式地 以交互模式运行WildFly 容器. docker container run -it jboss/wildfly 输出如下: ========================================================================= JBoss Bootstrap Environment JBOSS_HOME: /opt/jboss/wildfly JAVA: /usr/lib/jvm/java/bin/java . . . 00:26:27,455 INFO [org.jboss.as] (Controller Boot Thread) WFLYSRV0060: Http management interface listening on http://127.0.0.1:9990/management 00:26:27,456 INFO [org.jboss.as] (Controller Boot Thread) WFLYSRV0051: Admin console listening on http://127.0.0.1:9990 00:26:27,457 INFO [org.jboss.as] (Controller Boot Thread) WFLYSRV0025: WildFly Full 10.1.0.Final (WildFly Core 2.2.0.Final) started in 3796ms - Started 331 of 577 services (393 services are lazy, passive or on-demand) 这个输出说明服务器已经正常启动了,皮卡丘! 默认，Docker会运行在前台.-i 允许与STDIN(standard input,stdin是标准输入，一般指键盘输入到缓冲区里的东西)进行交互,-t 附加一个 TTY(通常使用tty来简称各种类型的终端设备terminal) 到进程. 两个开关能够合并为-it. 点击 Ctrl+C 来停止容器. 隔离的容器 以detached(隔离)模式启动容器: docker container run -d jboss/wildfly 254418caddb1e260e8489f872f51af4422bc4801d17746967d9777f565714600 这次使用-d来替换-it,以隔离模式来运行容器. 输出是一个唯一的id 分配给容器.通过docker container logs &lt;CONTAINER_ID&gt;命令可以查看容器的日志记录,&lt;CONTAINER_ID&gt; 代表容器的id. docker container ls 命令能够查看容器的状态: CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 254418caddb1 jboss/wildfly &quot;/opt/jboss/wildfl...&quot; 2 minutes ago Up 2 minutes 8080/tcp gifted_haibt docker container ls -a命令能够查看主机上的所有容器. 使用默认端口 如果你想要容器接受请求链接,那么你需要在调用docker run命令时提供特殊的参数选项.否则，启动的容器无法被我们的浏览器所访问.我们需要再次停止它并且以不同的选项重新启动. docker container stop `docker container ps | grep wildfly | awk &apos;{print $1}&apos;` 以如下命令重启容器: docker container run -d -P --name wildfly jboss/wildfly -P 代表在Docker host 上暴露 对应的端口.另外,--name一般用来给予这个容器一个名称.这个名称可以用来查询更多关于容器的信息或作为一个id来停止它.通过docker container ls命令来验证容器名称: CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 89fbfbceeb56 jboss/wildfly &quot;/opt/jboss/wildfl...&quot; 9 seconds ago Up 8 seconds 0.0.0.0:32768-&gt;8080/tcp wildfly 端口映射显示在 PORTS列.通过http://localhost:32768地址防卫 WildFly服务器.确保使用正确的端口来进行访问. 页面展示如下: 【我是图片】 使用指定的端口 停止并且移除最近运行的容器: docker container stop wildfly docker container rm wildfly 也可以用docker container rm -f wildfly命令来同时完成停止和移除容器的工作.需要谨慎小心，因为-f使用SIGKILL来kill容器. 重启容器: docker container run -d -p 8080:8080 --name wildfly jboss/wildfly 这种格式表示-p hostPort:containerPort.这允许我们访问主机上容器的特定端口. 现在通过http://localhost:8080 链接来测试.确认运行正常，接着如下同样停止并移除容器. 部署一个war文件到应用服务器 现在你的应用服务器正在运行,接下来展示如何部署war包到上面. 创建一个新目录hellojavaee.用如下内容创建Dockerfile文件: FROM jboss/wildfly:latest RUN curl -L https://github.com/javaee-samples/javaee7-simple-sample/releases/download/v1.10/javaee7-simple-sample-1.10.war -o /opt/jboss/wildfly/standalone/deployments/javaee-simple-sample.war 创建镜像: docker image build -t javaee-sample . 启动容器: docker container run -d -p 8080:8080 --name wildfly javaee-sample 访问网站路由： curl http://localhost:8080/javaee-simple-sample/resources/persons 输出如下: &lt;persons&gt; &lt;person&gt; &lt;name&gt; Penny &lt;/name&gt; &lt;/person&gt; &lt;/persons&gt; 可选的:brew install XML-Coreutils命令将会在Mac上安装xml格式的工具.这个输出能够通过xml-fmt选项来展示格式化结果. 停止容器 通过容器id或者名称来停止容器: docker container stop &lt;CONTAINER ID&gt; docker container stop &lt;NAME&gt; 停止所有正在运行的容器: docker container stop $(docker container ps -q) 只停止已经退出的容器: docker container ps -a -f &quot;exited=-1&quot; 移除容器 通过id或者名称移除指定的容器: docker container rm &lt;CONTAINER_ID&gt; docker container rm &lt;NAME&gt; 通过表达式匹配来移除容器: docker container ps -a | grep wildfly | awk &apos;{print $1}&apos; | xargs docker container rm 无条件移除所有容器: docker container rm $(docker container ps -aq) 端口映射的额外方式 确切的端口映射能够通过docker port命令进行设置: docker container port &lt;CONTAINER_ID&gt; or &lt;NAME&gt; 输出如下: 8080/tcp -&gt; 0.0.0.0:8080 端口映射情况能够通过docker inspect命令进行查看: docker container inspect --format=&apos;{{(index (index .NetworkSettings.Ports \"8080/tcp\") 0).HostPort}}&apos; &lt;CONTAINER ID&gt; 官网链接","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.zhz.gift/tags/docker/"}]},{"title":"Docker Java教程5:使用Docker Compose 实现多容器应用","slug":"Docker Java教程5_使用Docker Compose 实现多容器应用","date":"2018-05-10T15:09:42.000Z","updated":"2018-05-10T13:22:28.688Z","comments":true,"path":"2018/05/10/Docker Java教程5_使用Docker Compose 实现多容器应用/","link":"","permalink":"http://www.zhz.gift/2018/05/10/Docker Java教程5_使用Docker Compose 实现多容器应用/","excerpt":"什么是Docker Compose？ Docker Compose 是一个使用Docker来定义和运行复杂应用的工具.通过Compose,你能在一个单独的文件中定义一个多容器应用,通过一个命令就能完成所有事情，并使它们运行起来. — github.com/docker/compose","text":"什么是Docker Compose？ Docker Compose 是一个使用Docker来定义和运行复杂应用的工具.通过Compose,你能在一个单独的文件中定义一个多容器应用,通过一个命令就能完成所有事情，并使它们运行起来. — github.com/docker/compose 什么是Docker Compose配置文件启动应用验证应用停止应用 一个使用Docker容器技术的应用一般都会包含多个容器.通过Docker Compose,没有必要去写shell 脚本来启动你的容器.所有的容器都通过services定义在一个配置文件当中,然后docker-compose 脚本就可以用来启动，停止，或者重启应用，这样一来，所有的容器就集成在service当中，而所有的services则被包含在应用当中.完整的命令列表如下所示: Command Purpose build Build or rebuild services help Get help on a command kill Kill containers logs View output from containers port Print the public port for a port binding ps List containers pull Pulls service images restart Restart services rm Remove stopped containers run Run a one-off command scale Set number of containers for a service start Start services stop Stop services up Create and start containers 这个章节使用的应用是一个与数据库交互的Java EE应用.这个应用发布一个REST节点，可以通过curl调用.它通过WildFly Swarm部署，并且与MySQL数据库进行交互. WildFly Swarm 和 MySQL 将会在两个隔离的容器当中运行,因此这是一个多容器应用. 配置文件 Docker Compose 的入口是一个Compose 文件,通常命名为docker-compose.yml.创建一个新目录javaee,在该目录创建一个docker-compose.yml文件，内容如下: version: &apos;3.3&apos; services: db: container_name: db image: mysql:8 environment: MYSQL_DATABASE: employees MYSQL_USER: mysql MYSQL_PASSWORD: mysql MYSQL_ROOT_PASSWORD: supersecret ports: - 3306:3306 web: image: arungupta/docker-javaee:dockerconeu17 ports: - 8080:8080 - 9990:9990 depends_on: - db 在这个Compose文件当中: 在这个Compose 文件当中定义了两个services，分别是 db 和 web. 每个service的镜像名称通过image 属性进行定义.MYSQL_ROOT_PASSWORD is mandatory and specifies the password that will be set for the MySQL root superuser account. mysql:8 镜像 启动 MySQL 服务器. 环境变量属性定义环境变量来初始化MySQL 服务器. MYSQL_DATABASE 允许你在镜像启动的时候指定被创建的数据库的名称. MYSQL_USER 和 MYSQL_PASSWORD 用来创建一个新用户并且赋予那个用户的密码.这个用户将会赋予MYSQL_DATABASE属性指定的数据库的超级管理员权限. MYSQL_ROOT_PASSWORD 是强制必填项,并且将会设置为MySQL root 超级用户账号的密码. Java EE 应用 使用的 db 服务通过 connection-url 进行指定https://github.com/arun-gupta/docker-javaee/blob/master/employees/src/main/resources/project-defaults.yml/. arungupta/docker-javaee:dockerconeu17 image 启动 WildFly Swarm 应用服务器. 它包含从 https://github.com/arun-gupta/docker-javaee 构建的Java EE 应用. 如果你想要构建自己的镜像可以Clone这个项目. 端口跳转通过ports属性来完成. depends_on 属性允许表达services之间的依赖关系.在这个例子中,MySQL将会在WildFly之前启动. 启动应用 在这个应用当中的所有services都能在detached模式被启动，通过以下命令: docker-compose up -d 一个可替代的Compose文件名称能通过-f标志来指定. 一个可选的compose文件存在的目录能够通过-p标志来指定. 输出如下: docker-compose up -d Creating network &quot;javaee_default&quot; with the default driver Creating db ... Creating db ... done Creating javaee_web_1 ... Creating javaee_web_1 ... done","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.zhz.gift/tags/docker/"}]},{"title":"Docker java教程2—— docker 基础概念","slug":"Docker java教程2_ docker 基础概念","date":"2018-03-15T15:09:42.000Z","updated":"2018-03-15T14:51:13.623Z","comments":true,"path":"2018/03/15/Docker java教程2_ docker 基础概念/","link":"","permalink":"http://www.zhz.gift/2018/03/15/Docker java教程2_ docker 基础概念/","excerpt":"**目的: 这个章节主要介绍一些关于Docker 的术语. Docker 是一个提供给开发人员以及系统管理员构建，部署和运行应用的平台. Docker 令你能够快速地从组件库装配应用,并且在发布代码时排除冲突. Docker 使你尽可能快地测试和部署你的代码到生产环境. — docs.docker.com/","text":"**目的: 这个章节主要介绍一些关于Docker 的术语. Docker 是一个提供给开发人员以及系统管理员构建，部署和运行应用的平台. Docker 令你能够快速地从组件库装配应用,并且在发布代码时排除冲突. Docker 使你尽可能快地测试和部署你的代码到生产环境. — docs.docker.com/ 主要组件Docker 镜像Docker 容器Docker EngineDocker 客户端 Docker 通过更便捷的构建和共享包含你整个应用环境或者应用的操作系统的镜像来简化软件的交付. 一个应用操作系统意味着什么? 你的应用一般需要一个特定版本的操作系统,应用服务器,JDK,和数据库服务器,还可能需要调整配置文件,并且同样需要多个其它的依赖.应用可能需要绑定到特定的端口和一定大小的内存.这些组件和配置组成运行你的应用的应用操作系统. 你可以提供一个将会下载和安装这些组件的安装脚本.同样Docker 允许创建包含你应用及其基础环境的镜像,它就像一个组件一样使用，大大简化了这个过程.这些镜像接着用来创建Docker 容器,Docker 容器运行在Docker提供的虚拟平台. 主要组件 Docker 包含三个主要组件: 镜像是Docker 的构建组件, 并且是一定了一个应用操作系统的只读模板. 容器是Docker的运行组件,它是基于镜像创建的.容器能够运行,启动,停止,移除,或者删除. 镜像能够被存储，共享在注册表中进行管理，属于Docker 的分布组件.Docker Store 是一个公共可用的注册表,可用网址为:http://store.docker.com. 为了这三个组件能够正常工作,Docker Daemon(Docker Engine)在一个主机机器上运行,并且完成构建,运行和分发Docker 容器的工作.另外,客户端是一个Docker binary,能够通过Engine响应用户的命令,完成交互. 关键点 1. Docker 架构Client 客户端与Engine交互可以是在本地同一个主机,也可以是其它任意一个.客户端使用pull命令请求Engine来从注册表拉取镜像.Engine接着从Docker Store下载镜像,或者任意一个配置的注册表.从注册表能够下载多个镜像并且安装到Engine上.客户端使用run命令来运行容器. Docker 镜像在Docerk 容器中运行的docker镜像是只读模板.每个镜像由一系列层次构成.Docker利用联合文件系统(Union file systems)来将这些层面结合到一个镜像当中.联合文件系统允许文件或者以目录为单位的独立文件系统,就像分支一样(branches),通过覆盖的方式，形成一个单一而连贯的文件系统.Docker 如此轻量级的原因之一就是因为这些分层.当你改变一个Docker镜像-比如,更新一个应用到新的版本-一个新的分层被构建.因此,并不是替换整个镜像或者完全地重新构建,就像你可能在虚拟机中做的那样,只有那个分层被添加或者更新.现在你不需要去分配一整个全新的镜像,只需要更新,这使得Docker 镜像的分配更加快速和便捷.每个镜像都是基于基础镜像(base image)构建的,例如 ubuntu,一个基础的Ubuntu镜像,或者 fedora,一个基础调的Fedora 镜像.你同样能使用自己的镜像作为基础镜像来构建一个新镜像,比如如果你有一个基础的Apache镜像你能将它作为你所有web应用镜像的基础镜像.|Note|Docker 默认从Docker Store获取这些基础镜像||:—-:|:—-:|Docker 镜像可以很简单的从这些基础镜像当中构建出来,我们将依次介绍相关指令,每个指令都会在我们的镜像当中创建一个新的分层.指令包含的动作： 运行一个命令 添加一个文件或者目录 创建一个环境变量 当容器运行时运行一个进程这些指令被存储在一个命名为Dockerfile的文件当中.Docker 会在你请求构建一个镜像时读取这个文件,执行这些指令,并且返回最终的镜像.Docker 容器 一个容器由一个操作系统,用户添加的文件，和元数据组成.就像我们看到的那样,每个容器都是从镜像中构建的.那个镜像会告诉Docker容器应该包含什么东西,当容器启动时运行什么进程,和一系列其它配置文件.Docker镜像是只读的.当Docker从一个镜像当中运行容器,它会在那个镜像的顶部添加一个读写层(使用一个联合文件系统),让你的应用能够顺利运行. Docker Engine Docker Host 作为安装在你机器上的Docker的一部分被创建.一旦你的Docker host已经被创建,它就允许你去管理镜像和容器.例如,这个镜像能够被下载，容器能够被启动,停止和重启. Docker 客户端 这个客户端与Docker Host进行交互并且让你能够对镜像和容器产生影响作用. 通过以下命令检查你的客户端是否正常工作: docker -v 它将展示以下输出: Docker version 17.09.0-ce-rc3, build 2357fb2 客户端和服务器的版本能够通过docker version命令来进行查看.它将展示以下输出: Client: Version: 17.09.0-ce-rc3 API version: 1.32 Go version: go1.8.3 Git commit: 2357fb2 Built: Thu Sep 21 02:31:18 2017 OS/Arch: darwin/amd64 Server: Version: 17.09.0-ce-rc3 API version: 1.32 (minimum version 1.12) Go version: go1.8.3 Git commit: 2357fb2 Built: Thu Sep 21 02:36:52 2017 OS/Arch: linux/amd64 Experimental: true 完整的命令说明能够通过使用docker --help命令进行查看. 官方参考链接","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.zhz.gift/tags/docker/"}]},{"title":"Docker java教程1—— docker java 环境设置","slug":"Docker java教程1_ docker java 环境设置","date":"2018-03-15T15:08:42.000Z","updated":"2018-03-15T14:51:45.110Z","comments":true,"path":"2018/03/15/Docker java教程1_ docker java 环境设置/","link":"","permalink":"http://www.zhz.gift/2018/03/15/Docker java教程1_ docker java 环境设置/","excerpt":"这个章节描述了在这个教程中所需的硬件和软件及其相关的配置方式.","text":"这个章节描述了在这个教程中所需的硬件和软件及其相关的配置方式. 硬件 &amp; 软件Docker安装下载镜像其它软件 硬件 &amp; 软件 内存: 至少 4 GB+, 推荐 8 GB 操作系统: Mac OS X (10.10.3+), Windows 10 Pro+ 64-bit, Ubuntu 12+, CentOS 7+. Amazon Web Services 凭证需要以下凭证. 这只在这个教程的部分地方需要用到. Note 如果使用老版本的操作系统，安装介绍将会有些许不同，这将在下一个章节里讲到. Docker安装Docker在Mac,Windows 和 Linux上运行十分顺畅.这个教程将使用Docker Community Edition (CE).从docker Store下载 Docker CE edition .Docker CE requires a fairly recent operating system version. If your machine does not meet the requirements, then you need to install Docker Toolbox.|Note|Docker CE 需要一个相当新的操作系统版本.如果你的机器不满足要求，那你需要安装Docker Toolbox.||:-:|:-:|下载镜像 这个教程使用到一些Docker 镜像和软件.让我们在开始教程前下载它们. 从 https://raw.githubusercontent.com/docker/labs/master/developer-tools/java/scripts/docker-compose-pull-images.yml 下载文件 并且使用以下命令拉取所需的镜像: docker-compose -f docker-compose-pull-images.yml pull --parallel Note 对于Linux来说,docker-compose和docker commands需要sudo访问权限.所以在所有命令前加上sudo前缀. 其它软件 这个小节介绍的软件只在教程的某些部分中使用到.如果你计划尝试它们的话再进行安装. 安装 git. 按照教程安装 Docker Cloud CLI . 下载 Java IDE . NetBeans 8.2 (“Java SE” version) IntelliJ IDEA Community or Ultimate Eclipse IDE for Java EE Developers 下载并且安装 Maven. 下载通过 JDK 9 for Linux x64构建的OpenJDK. (同样参照 OpenJDK JDK 9 download page.) 下载通过JDK 9 for Alpine Linux构建的先行版本Open JDK.","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.zhz.gift/tags/docker/"}]},{"title":"Docker for Java Developers","slug":"Docker for Java Developers","date":"2018-03-15T15:07:42.000Z","updated":"2018-03-15T14:46:32.728Z","comments":true,"path":"2018/03/15/Docker for Java Developers/","link":"","permalink":"http://www.zhz.gift/2018/03/15/Docker for Java Developers/","excerpt":"这个教程为java开发者提供了一门可以按照自己进度操作实践的入门级课程.","text":"这个教程为java开发者提供了一门可以按照自己进度操作实践的入门级课程. Setup Environments Docker Basic Concepts Building Build a Docker Image Build a Docker Image for Java 9 Run a Docker Container Multi-container application using Docker Compose Multi-container application using Compose and Swarm Mode Java IDEs Docker Tooling in NetBeans Docker Tooling in IntelliJ IDEA Docker Tooling in Eclipse Multi-container application on multi-host Docker for AWS Docker for Azure (coming) Docker Cloud CI/CD using Docker Monitoring Docker Containers with Prometheus and Grafana Big Data Processing with Docker and Hadoop Common Docker Commands Troubleshooting References","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.zhz.gift/tags/docker/"}]},{"title":"Docker Swarm 教程","slug":"Docker Swarm 教程","date":"2018-03-15T14:08:42.000Z","updated":"2018-03-15T14:47:06.592Z","comments":true,"path":"2018/03/15/Docker Swarm 教程/","link":"","permalink":"http://www.zhz.gift/2018/03/15/Docker Swarm 教程/","excerpt":"Note:这个教程使用Docker Machine 来模拟多台机器运行的情况.有一种更简单的方式来学习swarm mode,那就是通过Play with Docker.这个教程因为历史原因保留下来，并且同样因为当你真的想要使用自己的机器来学习swarm时.","text":"Note:这个教程使用Docker Machine 来模拟多台机器运行的情况.有一种更简单的方式来学习swarm mode,那就是通过Play with Docker.这个教程因为历史原因保留下来，并且同样因为当你真的想要使用自己的机器来学习swarm时. Docker 的swarm 模式是用来管理Docker Engines的集群,所以称之为swarm.你能使用Docker CLI 来创建swarm,部署应用服务到一个swarm,并且管理swarm的行为.这个教程使用Docker Machine来在你的桌面电脑上创建多个节点.你也可以选择在云上或者多台机器上创建多个节点. 重要提示: 你并不需要使用Docker CLI来执行这些操作.只需要使用docker stack deploy --compose-file STACKNAME.yml STACKNAME 命令即可.关于以compose 文件格式的stack文件来部署一个app,参考Deploying an app to a Swarm 准备你需要在你的系统上安装Docker 和Docker Machine.下载Docker并且安装. 提示: 如果你是使用Docker for Mac 或者Docker for Windows,Docker Machine已经默认安装.查看Download Docker for Mac和Download Docker for Windows来查询详细安装细节. 如果你是使用Docker for Windows 你还需要使用Hyper-V driver 来正常驱动Docker Machine.这可能需要更多一点设置.查看Microsoft Hyper-V driver documentation来获取设置指引. 如果你是直接在linux系统上使用Docker,你将需要安装Docker Machine(在安装Docker Engine之后). 创建nodes和SwarmDocker Machine可以用来: 在Mac或者Windows上安装和运行Docker 提供和管理多个远程Docker 主机 提供Swarm 集群 但它同样能用来在你本地的机器上创建多个节点.在这个仓库有一个bash脚本实现了这一点并且创建swarm.同样有一个powershell Hyper-V version.在这篇教程我们将贯穿这个脚本,步步深入，除了设置以外,与Hyper-V version基本相同. 首先创建3个machines,并且命名为manger1,manger2和manger3. #!/bin/bash # Swarm mode using Docker Machine #This configures the number of workers and managers in the swarm managers=3 workers=3 # This creates the manager machines echo &quot;======&gt; Creating $managers manager machines ...&quot;; for node in $(seq 1 $managers); do echo &quot;======&gt; Creating manager$node machine ...&quot;; docker-machine create -d virtualbox manager$node; done 第二个步骤是创建三个及以上的machines,并且命名为worker1,worker2,和worker3 # This create worker machines echo &quot;======&gt; Creating $workers worker machines ...&quot;; for node in $(seq 1 $workers); do echo &quot;======&gt; Creating worker$node machine ...&quot;; docker-machine create -d virtualbox worker$node; done # This lists all machines created docker-machine ls 接下来你创建一个swarm通过在首个manger上初始化它.通过docker-machine ssh来运行docker-machine ssh命令. # initialize swarm mode and create a manager echo &quot;======&gt; Initializing first swarm manager ...&quot; docker-machine ssh manager1 &quot;docker swarm init --listen-addr $(docker-machine ip manager1) --advertise-addr $(docker-machine ip manager1)&quot; 接下来为mangers和workers获取tokens. # get manager and worker tokens export manager_token=`docker-machine ssh manager1 &quot;docker swarm join-token manager -q&quot;` export worker_token=`docker-machine ssh manager1 &quot;docker swarm join-token worker -q&quot;` 然后把其他managers加入到Swarm for node in $(seq 2 $managers); do echo &quot;======&gt; manager$node joining swarm as manager ...&quot; docker-machine ssh manager$node \\ &quot;docker swarm join \\ --token $manager_token \\ --listen-addr $(docker-machine ip manager$node) \\ --advertise-addr $(docker-machine ip manager$node) \\ $(docker-machine ip manager1)&quot; done 最后，添加worker machines并且加入swarm # workers join swarm for node in $(seq 1 $workers); do echo &quot;======&gt; worker$node joining swarm as worker ...&quot; docker-machine ssh worker$node \\ &quot;docker swarm join \\ --token $worker_token \\ --listen-addr $(docker-machine ip worker$node) \\ --advertise-addr $(docker-machine ip worker$node) \\ $(docker-machine ip manager1):2377&quot; done # show members of swarm docker-machine ssh manager1 &quot;docker node ls&quot; 最后一行将向你展示所有的节点,就像这样: ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS 3cq6idpysa53n6a21nqe0924h manager3 Ready Active Reachable 64swze471iu5silg83ls0bdip * manager1 Ready Active Leader 7eljvvg0icxlw20od5f51oq8t manager2 Ready Active Reachable 8awcmkj3sd9nv1pi77i6mdb1i worker1 Ready Active avu80ol573rzepx8ov80ygzxz worker2 Ready Active bxn1iivy8w7faeugpep76w50j worker3 Ready Active 也可以运行以下命令: $ docker-machine ls NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORS manager1 - virtualbox Running tcp://192.168.99.100:2376 v17.03.0-ce manager2 - virtualbox Running tcp://192.168.99.101:2376 v17.03.0-ce manager3 - virtualbox Running tcp://192.168.99.102:2376 v17.03.0-ce worker1 - virtualbox Running tcp://192.168.99.103:2376 v17.03.0-ce worker2 - virtualbox Running tcp://192.168.99.104:2376 v17.03.0-ce worker3 - virtualbox Running tcp://192.168.99.105:2376 v17.03.0-ce 下一步是创建一个service并且进行展示.这里创建单个命名为web的service并且运行最新的nginx: $ docker-machine ssh manager1 &quot;docker service create -p 80:80 --name web nginx:latest&quot; $ docker-machine ssh manager1 &quot;docker service ls&quot; ID NAME REPLICAS IMAGE COMMAND 2x4jsk6313az web 1/1 nginx:latest 现在在你的浏览器上通过对应ip地址进行访问.在这个实例中manger1有一个ip地址为192.168.99.100. 你可以使用任意其它节点的ip地址进行访问都将得到同样的结果,因为Swarm Mode’s Routing Mesh. 现在检查service: $ docker-machine ssh manager1 &quot;docker service inspect web&quot; [ { &quot;ID&quot;: &quot;2x4jsk6313azr6g1dwoi47z8u&quot;, &quot;Version&quot;: { &quot;Index&quot;: 104 }, &quot;CreatedAt&quot;: &quot;2016-08-23T22:43:23.573253682Z&quot;, &quot;UpdatedAt&quot;: &quot;2016-08-23T22:43:23.576157266Z&quot;, &quot;Spec&quot;: { &quot;Name&quot;: &quot;web&quot;, &quot;TaskTemplate&quot;: { &quot;ContainerSpec&quot;: { &quot;Image&quot;: &quot;nginx:latest&quot; }, &quot;Resources&quot;: { &quot;Limits&quot;: {}, &quot;Reservations&quot;: {} }, &quot;RestartPolicy&quot;: { &quot;Condition&quot;: &quot;any&quot;, &quot;MaxAttempts&quot;: 0 }, &quot;Placement&quot;: {} }, &quot;Mode&quot;: { &quot;Replicated&quot;: { &quot;Replicas&quot;: 1 } }, &quot;UpdateConfig&quot;: { &quot;Parallelism&quot;: 1, &quot;FailureAction&quot;: &quot;pause&quot; }, &quot;EndpointSpec&quot;: { &quot;Mode&quot;: &quot;vip&quot;, &quot;Ports&quot;: [ { &quot;Protocol&quot;: &quot;tcp&quot;, &quot;TargetPort&quot;: 80, &quot;PublishedPort&quot;: 80 } ] } }, &quot;Endpoint&quot;: { &quot;Spec&quot;: { &quot;Mode&quot;: &quot;vip&quot;, &quot;Ports&quot;: [ { &quot;Protocol&quot;: &quot;tcp&quot;, &quot;TargetPort&quot;: 80, &quot;PublishedPort&quot;: 80 } ] }, &quot;Ports&quot;: [ { &quot;Protocol&quot;: &quot;tcp&quot;, &quot;TargetPort&quot;: 80, &quot;PublishedPort&quot;: 80 } ], &quot;VirtualIPs&quot;: [ { &quot;NetworkID&quot;: &quot;24r1loluvdohuzltspkwbhsc8&quot;, &quot;Addr&quot;: &quot;10.255.0.9/16&quot; } ] }, &quot;UpdateStatus&quot;: { &quot;StartedAt&quot;: &quot;0001-01-01T00:00:00Z&quot;, &quot;CompletedAt&quot;: &quot;0001-01-01T00:00:00Z&quot; } } ] 规模化service(运行多个相同service): $ docker-machine ssh manager1 &quot;docker service scale web=15&quot; web scaled to 15 $ docker-machine ssh manager1 &quot;docker service ls&quot; ID NAME REPLICAS IMAGE COMMAND 2x4jsk6313az web 15/15 nginx:latest Docker会将15个服务均匀地分配到所有节点上: $ docker-machine ssh manager1 &quot;docker service ps web&quot; ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR 61wjx0zaovwtzywwbomnvjo4q web.1 nginx:latest worker3 Running Running 13 minutes ago bkkujhpbtqab8fyhah06apvca web.2 nginx:latest manager1 Running Running 2 minutes ago 09zkslrkgrvbscv0vfqn2j5dw web.3 nginx:latest manager1 Running Running 2 minutes ago 4dlmy8k72eoza9t4yp9c9pq0w web.4 nginx:latest manager2 Running Running 2 minutes ago 6yqabr8kajx5em2auvfzvi8wi web.5 nginx:latest manager3 Running Running 2 minutes ago 21x7sn82883e7oymz57j75q4q web.6 nginx:latest manager2 Running Running 2 minutes ago 14555mvu3zee6aek4dwonxz3f web.7 nginx:latest worker1 Running Running 2 minutes ago 1q8imt07i564bm90at3r2w198 web.8 nginx:latest manager1 Running Running 2 minutes ago encwziari9h78ue32v5pjq9jv web.9 nginx:latest worker3 Running Running 2 minutes ago aivwszsjhhpky43t3x7o8ezz9 web.10 nginx:latest worker2 Running Running 2 minutes ago 457fsqomatl1lgd9qbz2dcqsb web.11 nginx:latest worker1 Running Running 2 minutes ago 7chhofuj4shhqdkwu67512h1b web.12 nginx:latest worker2 Running Running 2 minutes ago 7dynic159wyouch05fyiskrd0 web.13 nginx:latest worker1 Running Running 2 minutes ago 7zg9eki4610maigr1xwrx7zqk web.14 nginx:latest manager3 Running Running 2 minutes ago 4z2c9j20gwsasosvj7mkzlyhc web.15 nginx:latest manager2 Running Running 2 minutes ago 你同样能排除一个特定的节点，通过从那个节点移除所有的服务.这些服务会自动重新安排到其它节点上. $ docker-machine ssh manager1 &quot;docker node update --availability drain worker1&quot; worker1 $ docker-machine ssh manager1 &quot;docker service ps web&quot; ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR 61wjx0zaovwtzywwbomnvjo4q web.1 nginx:latest worker3 Running Running 15 minutes ago bkkujhpbtqab8fyhah06apvca web.2 nginx:latest manager1 Running Running 4 minutes ago 09zkslrkgrvbscv0vfqn2j5dw web.3 nginx:latest manager1 Running Running 4 minutes ago 4dlmy8k72eoza9t4yp9c9pq0w web.4 nginx:latest manager2 Running Running 4 minutes ago 6yqabr8kajx5em2auvfzvi8wi web.5 nginx:latest manager3 Running Running 4 minutes ago 21x7sn82883e7oymz57j75q4q web.6 nginx:latest manager2 Running Running 4 minutes ago 8so0xi55kqimch2jojfdr13qk web.7 nginx:latest worker3 Running Running 3 seconds ago 14555mvu3zee6aek4dwonxz3f \\_ web.7 nginx:latest worker1 Shutdown Shutdown 4 seconds ago 1q8imt07i564bm90at3r2w198 web.8 nginx:latest manager1 Running Running 4 minutes ago encwziari9h78ue32v5pjq9jv web.9 nginx:latest worker3 Running Running 4 minutes ago aivwszsjhhpky43t3x7o8ezz9 web.10 nginx:latest worker2 Running Running 4 minutes ago 738jlmoo6tvrkxxar4gbdogzf web.11 nginx:latest worker2 Running Running 3 seconds ago 457fsqomatl1lgd9qbz2dcqsb \\_ web.11 nginx:latest worker1 Shutdown Shutdown 3 seconds ago 7chhofuj4shhqdkwu67512h1b web.12 nginx:latest worker2 Running Running 4 minutes ago 4h7zcsktbku7peh4o32mw4948 web.13 nginx:latest manager3 Running Running 3 seconds ago 7dynic159wyouch05fyiskrd0 \\_ web.13 nginx:latest worker1 Shutdown Shutdown 4 seconds ago 7zg9eki4610maigr1xwrx7zqk web.14 nginx:latest manager3 Running Running 4 minutes ago 4z2c9j20gwsasosvj7mkzlyhc web.15 nginx:latest manager2 Running Running 4 minutes ago worker1节点仍然存活但是被标记为drain 状态. $ docker-machine ssh manager1 &quot;docker node ls&quot; ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS 3cq6idpysa53n6a21nqe0924h manager3 Ready Active Reachable 64swze471iu5silg83ls0bdip * manager1 Ready Active Leader 7eljvvg0icxlw20od5f51oq8t manager2 Ready Active Reachable 8awcmkj3sd9nv1pi77i6mdb1i worker1 Ready Drain avu80ol573rzepx8ov80ygzxz worker2 Ready Active bxn1iivy8w7faeugpep76w50j worker3 Ready Active 降低服务的规模: $ docker-machine ssh manager1 &quot;docker service scale web=10&quot; web scaled to 10 $ docker-machine ssh manager1 &quot;docker service ps web&quot; ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR 61wjx0zaovwtzywwbomnvjo4q web.1 nginx:latest worker3 Running Running 22 minutes ago bkkujhpbtqab8fyhah06apvca web.2 nginx:latest manager1 Shutdown Shutdown 54 seconds ago 09zkslrkgrvbscv0vfqn2j5dw web.3 nginx:latest manager1 Running Running 11 minutes ago 4dlmy8k72eoza9t4yp9c9pq0w web.4 nginx:latest manager2 Running Running 11 minutes ago 6yqabr8kajx5em2auvfzvi8wi web.5 nginx:latest manager3 Running Running 11 minutes ago 21x7sn82883e7oymz57j75q4q web.6 nginx:latest manager2 Running Running 11 minutes ago 8so0xi55kqimch2jojfdr13qk web.7 nginx:latest worker3 Running Running 7 minutes ago 14555mvu3zee6aek4dwonxz3f \\_ web.7 nginx:latest worker1 Shutdown Shutdown 7 minutes ago 1q8imt07i564bm90at3r2w198 web.8 nginx:latest manager1 Running Running 11 minutes ago encwziari9h78ue32v5pjq9jv web.9 nginx:latest worker3 Shutdown Shutdown 54 seconds ago aivwszsjhhpky43t3x7o8ezz9 web.10 nginx:latest worker2 Shutdown Shutdown 54 seconds ago 738jlmoo6tvrkxxar4gbdogzf web.11 nginx:latest worker2 Running Running 7 minutes ago 457fsqomatl1lgd9qbz2dcqsb \\_ web.11 nginx:latest worker1 Shutdown Shutdown 7 minutes ago 7chhofuj4shhqdkwu67512h1b web.12 nginx:latest worker2 Running Running 11 minutes ago 4h7zcsktbku7peh4o32mw4948 web.13 nginx:latest manager3 Running Running 7 minutes ago 7dynic159wyouch05fyiskrd0 \\_ web.13 nginx:latest worker1 Shutdown Shutdown 7 minutes ago 7zg9eki4610maigr1xwrx7zqk web.14 nginx:latest manager3 Shutdown Shutdown 54 seconds ago 4z2c9j20gwsasosvj7mkzlyhc web.15 nginx:latest manager2 Shutdown Shutdown 54 seconds ago 现在重新把worker1 恢复为在线状态并且显示它的状态: $ docker-machine ssh manager1 &quot;docker node update --availability active worker1&quot; worker1 $ docker-machine ssh manager1 &quot;docker node inspect worker1 --pretty&quot; ID: 8awcmkj3sd9nv1pi77i6mdb1i Hostname: worker1 Joined at: 2016-08-23 22:30:15.556517377 +0000 utc Status: State: Ready Availability: Active Platform: Operating System: linux Architecture: x86_64 Resources: CPUs: 1 Memory: 995.9 MiB Plugins: Network: bridge, host, null, overlay Volume: local Engine Version: 17.03.0-ce Engine Labels: - provider = virtualbox 现在把manager1 leader节点,从Swarm中移除: $ docker-machine ssh manager1 &quot;docker swarm leave --force&quot; Node left the swarm. 等待30秒来确定生效.Swarm仍然可用,但是必须重新选举一个新的leader.这会自动发生. $ docker-machine ssh manager2 &quot;docker node ls&quot; ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS 3cq6idpysa53n6a21nqe0924h manager3 Ready Active Reachable 64swze471iu5silg83ls0bdip manager1 Down Active Unreachable 7eljvvg0icxlw20od5f51oq8t * manager2 Ready Active Leader 8awcmkj3sd9nv1pi77i6mdb1i worker1 Ready Active avu80ol573rzepx8ov80ygzxz worker2 Ready Active bxn1iivy8w7faeugpep76w50j worker3 Ready Active 可以看到manager1变为Down 并且 Unreachable ,并且manager2已经被选举为leader.同样简单的方式移除一个service: $ docker-machine ssh manager2 &quot;docker service rm web&quot; web Cleanup$ ./swarm-node-vbox-teardown.sh Stopping &quot;manager3&quot;... Stopping &quot;manager2&quot;... Stopping &quot;worker1&quot;... Stopping &quot;manager1&quot;... Stopping &quot;worker3&quot;... Stopping &quot;worker2&quot;... Machine &quot;manager3&quot; was stopped. Machine &quot;manager1&quot; was stopped. Machine &quot;manager2&quot; was stopped. Machine &quot;worker2&quot; was stopped. Machine &quot;worker1&quot; was stopped. Machine &quot;worker3&quot; was stopped. About to remove worker1, worker2, worker3, manager1, manager2, manager3 Are you sure? (y/n): y Successfully removed worker1 Successfully removed worker2 Successfully removed worker3 Successfully removed manager1 Successfully removed manager2 Successfully removed manager3 Next Steps更多详细信息查看Docker Swarm Mode 文档","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.zhz.gift/tags/docker/"}]},{"title":"3.0部署一个app到Swarm上","slug":"部署一个app到Swarm上","date":"2018-02-12T03:07:42.000Z","updated":"2018-02-12T03:04:02.610Z","comments":true,"path":"2018/02/12/部署一个app到Swarm上/","link":"","permalink":"http://www.zhz.gift/2018/02/12/部署一个app到Swarm上/","excerpt":"这个教程将会通过创建和定制一个投票app来知道你关于swarm上面的部署.按步骤完成教程至关重要，并且确保定制的部分是开放了定制功能的. 注意：完成这个章节的教程，你需要先完成Docker和git的安装.","text":"这个教程将会通过创建和定制一个投票app来知道你关于swarm上面的部署.按步骤完成教程至关重要，并且确保定制的部分是开放了定制功能的. 注意：完成这个章节的教程，你需要先完成Docker和git的安装. Voting app应用源代码路径Docker Example Voting App.这个app包含5个组件: Python webapp 组件，实现在两个选项之间投票的功能 Redis queue 收集新的投票 .NET worker 消费投票并且保存它们在… Postgres database 通过Docker volume 来支持 Node.js webapp 即时展示投票结果 克隆仓库到你的机器上并且通过cd命令到对应目录下: git clone https://github.com/docker/example-voting-app.git cd example-voting-app 部署app在这首个阶段，我们将会使用在Docker Store中的首个镜像. 这个app依赖Docker Swarm模式.Swarm mode是嵌入在Docker engine中的集群管理和编排特性.你可以用一个描述你app期望状态的文件来轻松部署到swarm.Swarm允许你运行你的容器在多台机器上.在这个教程中，你可以使用一台机器，或者使用一些像Docker for AWS或者Docker for Azure来快速的创建多个节点的机器.另外，你还可以使用Docker Machine 在你的部署机器上创建多个本地节点.查看Swarm Mode lab查询更多相关信息 首先,创建一个Swarm. docker swarm init 接下来，你将需要一个Docker Compose文件.你并不需要安装Docker Compose,尽管如果你使用的是Docker for Mac 或者 Docker for Windows的话默认是已经安装的了.然而docker stack deploy接受一个Docker Compose 格式的文件.你需要的文件就在Docker Example Voting App的根目录.文件名为docker-stack.yml.你也可以直接复制和粘贴以下内容: version: &quot;3&quot; services: redis: image: redis:alpine ports: - &quot;6379&quot; networks: - frontend deploy: replicas: 2 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure db: image: postgres:9.4 volumes: - db-data:/var/lib/postgresql/data networks: - backend deploy: placement: constraints: [node.role == manager] vote: image: dockersamples/examplevotingapp_vote:before ports: - 5000:80 networks: - frontend depends_on: - redis deploy: replicas: 2 update_config: parallelism: 2 restart_policy: condition: on-failure result: image: dockersamples/examplevotingapp_result:before ports: - 5001:80 networks: - backend depends_on: - db deploy: replicas: 1 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure worker: image: dockersamples/examplevotingapp_worker networks: - frontend - backend deploy: mode: replicated replicas: 1 labels: [APP=VOTING] restart_policy: condition: on-failure delay: 10s max_attempts: 3 window: 120s placement: constraints: [node.role == manager] visualizer: image: dockersamples/visualizer ports: - &quot;8080:8080&quot; stop_grace_period: 1m30s volumes: - /var/run/docker.sock:/var/run/docker.sock deploy: placement: constraints: [node.role == manager] networks: frontend: backend: volumes: db-data: 首先部署它，然后我们将会深入了解更多细节: docker stack deploy --compose-file docker-stack.yml vote Creating network vote_frontend Creating network vote_backend Creating network vote_default Creating service vote_vote Creating service vote_result Creating service vote_worker Creating service vote_redis Creating service vote_db 验证已经成功部署的堆栈,使用docker stack services vote docker stack services vote ID NAME MODE REPLICAS IMAGE 25wo6p7fltyn vote_db replicated 1/1 postgres:9.4 2ot4sz0cgvw3 vote_worker replicated 1/1 dockersamples/examplevotingapp_worker:latest 9faz4wbvxpck vote_redis replicated 2/2 redis:alpine ocm8x2ijtt88 vote_vote replicated 2/2 dockersamples/examplevotingapp_vote:before p1dcwi0fkcbb vote_result replicated 2/2 dockersamples/examplevotingapp_result:before 如果你查看docker-stack.yml文件,你将会看到文件定义 基于Python image的vote container 基于Node.js image的 result container 基于redis image的redis container,用以临时存储数据. 基于.NET image的.NET based worker app 基于postgres image 的Postgres 容器. Compose文件同样定义两个networks,front-tier 和back-tier .每个容器都是被放置在一个或者两个networks.一旦在那些networks中,它们就可以在那个network中以使用service名称的方式在代码中访问其它处于这个network的services.Services可以处于任意数量的networks.Services被它们各自的network所隔离.即使Services处于同一个network中,Services也只能通过name名称去发现彼此.想了解更多networking,点击Networking Lab. 再看一下Compose文件，你会发现它是以: version: &quot;3&quot; version 3 这个版本号对compose 文件来说非常重要,因为docker stack deploy 命令不支持更早版本的.你将会看到那里同样有个serviceskey,在下面的是一个分割键(不就是一个yml文件么..这么啰嗦)，用来隔离每个services,例如: vote: image: dockersamples/examplevotingapp_vote:before ports: - 5000:80 networks: - frontend depends_on: - redis deploy: replicas: 2 update_config: parallelism: 2 restart_policy: condition: on-failure image键 指定了你能使用哪个镜像,在这个例子中就是dockersamples/examplevotingapp_vote:before，如果你对Compose足够熟悉,你可能知道有一个build键,用来基于Dockerfile进行构建.然而,docker stack deploy不支持build，所以你需要使用预构建镜像. 与docker run很相似,你能够定义ports 和 networks.depends_on键用来指定一个service只在另一个service之后才进行部署.在这个例子中vote只在redis之后进行部署. deploy键是version3 版本新增的.它允许你在部署到Swarm时指定不同的属性.在这个例子中,你指定了需要两个 replicas(复制品),也就是在Swarm上部署两个容器.你可以指定其它属性,像什么时候去重启(restart),使用什么样的healthcheck,配置约束(placement constraints),资源(resources)等等. 测试运行现在app已经开始运行了,你可以通过http://localhost:5000来进行访问. 点击其中一个进行投票.你可以通过http://localhost:5001来查看结果. NOTE: 如果你是在云环境运行这个教程，像AWS,Azure,Digital Ocean,或者GCE 你将不能直接通过localhost或者127.0.0.1来进行访问.一个变通的手段是利用ssh port forwarding.下面是Mac OS的一个例子.这同样适用于Windows 和Putty 用户. $ ssh -L 5000:localhost:5000 &lt;ssh-user&gt;@&lt;CLOUD_INSTANCE_IP_ADDRESS&gt; 定做app在这个步骤，你将会定制app并且重新部署它。我们将会使用相同的图片，但是通过使用after标签将投票选项cats和dogs换成Java和.NET. 改变使用的图片重新修改docker-stack.yml文件,将vote和result 图片修改为after标签,如下: vote: image: dockersamples/examplevotingapp_vote:after ports: - 5000:80 networks: - frontend depends_on: - redis deploy: replicas: 2 update_config: parallelism: 2 restart_policy: condition: on-failure result: image: dockersamples/examplevotingapp_result:after ports: - 5001:80 networks: - backend depends_on: - db deploy: replicas: 2 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure 重新部署重新部署跟之前的操作一样. docker stack deploy --compose-file docker-stack.yml vote 测试运行再次查看app运行界面结果. 移除堆栈从swarm移除堆栈. docker stack rm vote 后续现在你已经构建了一些镜像并且把它们推送到Docker Cloud，并且学习到基础的Swarm mode,你可以通过查看the documentation文档了解更多信息.并且如果你需要任何帮助的话，可以访问Docker Forums或者StackOverflow.","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.zhz.gift/tags/docker/"}]},{"title":"2.0用Docker运行web项目","slug":"2.0用Docker运行web项目","date":"2018-02-12T03:07:42.000Z","updated":"2018-02-12T03:03:44.796Z","comments":true,"path":"2018/02/12/2.0用Docker运行web项目/","link":"","permalink":"http://www.zhz.gift/2018/02/12/2.0用Docker运行web项目/","excerpt":"在1.0运行你的第一个容器中我们已经顺利让docker运行起来，并且熟悉了一些术语的含义.通过这些基础，我们终于可以实践一些更有意义的东西——用Docker部署web项目.","text":"在1.0运行你的第一个容器中我们已经顺利让docker运行起来，并且熟悉了一些术语的含义.通过这些基础，我们终于可以实践一些更有意义的东西——用Docker部署web项目. 在容器中运行静态web网站Note: 本节示例网站文件请点击这里. 让我们从初始步骤开始.首先,我们使用Docker在容器中运行一个静态网站.这个网站是基于一个已存在的镜像.我们将从Docker Store拉取Docker镜像，运行容器，并且看到它是怎么建立 web server的. 你将要使用的镜像是一个单页网站，并且为了这个demo示范，已经创建完毕并且在Docker Store中可用，存储路径为dockersamples/static-site.你可以直接使用docker run命令下载并且运行这个镜像.如下: $ docker run -d dockersamples/static-site Note: 这个当前版本的镜像必须添加-d 标识符才能运行.-d 标识符能够开启detached模式,它能从terminal/shell 终端 分派运行中的容器并且在容器启动后返回提示.我们正在调试这个镜像，至于现在，使用-d，即使它是你的第一个例子..(好屌) 该命令运行后,首先由于该镜像并不存在于你的主机上,所以Docker守护进程首先会从registry(Docker store)尝试拉取它然后再让它以容器的方式运行起来. 服务器运行起来后，如何访问网站？网站在哪个端口上运行？更重要的是,如何在我们的主机机器上面直接访问容器. 事实上，你可能还回答不了其中任意一个问题:)(好想打死你),在这种情况下,客户端并未告诉Docker Engine 去发布任何端口,所以你需要重新运行docker run命令去添加这个命令. 让我们重新运行命令，并添加一些新标识符去发布端口并且传递你的名字给容器，以自定义展示的信息.我们将会再次使用-d 选项在detached mode下运行容器. 首先，通过container ID停止你正在运行的容器. 因为之前我们已经在detached mode下运行容器,所以我们不需要开启其它的terminal来完成终止操作.运行docker ps命令来查看运行中的容器. $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a7a0e504ca3e dockersamples/static-site &quot;/bin/sh -c &apos;cd /usr/&quot; 28 seconds ago Up 26 seconds 80/tcp, 443/tcp stupefied_mahavira 检查CONTAINER ID那一列.接下来通过CONTAINER ID来停止运行中的容器,并且移除掉它. $ docker stop a7a0e504ca3e $ docker rm a7a0e504ca3e Note: 一个很cool的特性是你不需要指定整个CONTAINER ID.你可以只指定CONTAINER ID初始的几个字符，并且如果这几个字符在所有你运行的容器当中是唯一的话，那么Docker 客户端会自动获取到该容器. $ docker run --name static-site -e AUTHOR=&quot;Your Name&quot; -d -P dockersamples/static-site e61d12292d69556eabe2a44c16cbd54486b2527e2ce4f95438e504afb7b02810 在上面的命令当中: -d 将会从我们的terminal以detached模式创建容器. -P 将会发布所有暴露的容器端口到Docker主机的随机端口上. -e 是你传递环境变量(environment variables)给容器的方式 –name 允许你指定一个容器的名字 AUTHOR 是环境变量的名字并且”Your Name” 可以由你进行自定义. 现在你可以通过docker port命令看到端口了. $ docker port static-site 443/tcp -&gt; 0.0.0.0:32772 80/tcp -&gt; 0.0.0.0:32773 如果你正在运行的是Docker for Mac,Docker for Windows,或者Docker on Linux,你可以打开 http://localhost:[YOUR_PORT_FOR 80/tcp].在我们的例子中就是http://localhost:32773. 如果你是在Mac或者Windows上面使用Docker机器，你可以通过docker-machine命令行找到hostname.如下(假设你使用的是默认机器) $ docker-machine ip default 192.168.99.100 你可以打开 http://:[YOUR_PORT_FOR 80/tcp] 去访问的网站.在我们的例子中就是:http://192.168.99.100:32773. 你可以在同一时间运行第二个web服务器，制定一个自定义的host端口去映射你的对应容器的webserver. $ docker run --name static-site-2 -e AUTHOR=&quot;Your Name&quot; -d -p 8888:80 dockersamples/static-site 部署它在一个真正的服务器上，你只需要安装Docker，并且通过上述docker命令运行(就像在这个例子中你可以看到AUTHOR是你传递给Docker的那个环境变量) 现在你已经知道了如何在一个Docker容器当中运行webserver，如何创建你自己的Docker镜像？这将是我们在下一小节当中探索的问题. 但现在首先停止并移除容器. $ docker stop static-site $ docker rm static-site 使用简略语法移除第二个网站: $ docker rm -f static-site-2 运行docker ps命令确认容器已经正确停止了. Docker 镜像在这个小节中，让我们更加深入的了解Docker images究竟是什么东西.你将会建立自己的镜像，使用这个镜像在你的本地运行一个应用，然后最终，推送一些你自己的镜像到Docker Cloud. Docker images 是容器的基础.在上一个例子中,你从registry(docker store)拉取 dockersamples/static-site 镜像并且让Docker 客户端基于这个镜像运行一个容器.通过运行docker images命令来查看你系统上本地可用的镜像列表. $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE dockersamples/static-site latest 92a386b6e686 2 hours ago 190.5 MB nginx latest af4b3d7d5401 3 hours ago 190.5 MB python 2.7 1c32174fd534 14 hours ago 676.8 MB postgres 9.4 88d845ac7a88 14 hours ago 263.6 MB containous/traefik latest 27b4e0c6b2fd 4 days ago 20.75 MB node 0.10 42426a5cba5f 6 days ago 633.7 MB redis latest 4f5f397d4b7c 7 days ago 177.5 MB mongo latest 467eb21035a8 7 days ago 309.7 MB alpine 3.3 70c557e50ed6 8 days ago 4.794 MB java 7 21f6ce84e43c 8 days ago 587.7 MB 上述是我从registry拉取的一系列镜像,以及一些我自己创建的(我们很快会看到如何做的).在你的机器上可能是一个不同的镜像列表.TAG 指的是这个镜像特别的snapshot 快照版本，ID则是这个镜像唯一的标识. 简单地说，你可以把一个镜像理解为类似git仓库的东西，镜像可以像git一样提交commit并且有多个版本.当你没有提供一个指定的版本，客户端默认会是最新的. 例如，你可以指定一个特定版本的ubuntu镜像如下所示: $ docker pull ubuntu:12.04 如果你没有指定一个特定版本的镜像,就像提到的那样,Dcoker 客户端将会默认选择最新版本的. 如例子所示,docker 将会拉取一个命名为: ubuntu:latest 的镜像: $ docker pull ubuntu 获取Docker image的途径，一是从registry(就比如Docker Store),二是自己创建.在Docker Store中有成百上千的镜像等你临幸.或者你也可以直接通过docker search命令来搜索镜像. 镜像之间的一个重要区别是关于 base images(基础镜像)和child images(子镜像). Base images 没有父级镜像,通常是操作系统的镜像，像ubuntu,alpine 或者debian. Child images 是在base images的基础上构建起来的，通常添加了一些额外的功能. 另一个关键概念是 official images (官方镜像) 和 user images(用户镜像).(它们都可以是基础镜像或者子镜像) Official images 是Docker 官方审核认可的 镜像.Docker,一个负责审核和发布所有官方仓库内容的团队.上述的一系列镜像,python,node,alpine 和 nginx镜像都是官方(base)镜像.通过查看官方镜像文档来了解更多官方镜像.(official Images Documentation) User images 是由用户创建和共享的镜像.它们是在base images的基础上构建并添加额外的功能.典型的它们都是以 user/image-name格式来命名.用户名一般是你的Docker Store用户名或者组织名. 创建你的首个镜像Note: 这个小节的示例代码在flask-app 路径下的仓库. 现在你已经对镜像有了进一步的理解了，是时候创建你自己的镜像了.我们的目标是创建一个镜像并在沙盒中运行一个Flash应用. 这个练习的目的是创建一个Docker镜像并运行一个Flask app. 我们首先一次性领取一个用Python Flask构建的随机生成猫图片的组件，然后通过编写一个Dockerfile 来dockerizing它.最后,我们构建镜像,然后运行它. 具体步骤如下: 创建一个展示随机猫图片的Python Flask app. 编写一个Dockerfile文件 构建镜像 运行镜像 Dockerfile 命令总结 创建一个展示随机猫图片的Python Flask app创建一个flask-app目录,然后在该目录下创建以下文件: app.py requirements.txt templates/index.html Dockerfile app.py用以下内容创建app.py: from flask import Flask, render_template import random app = Flask(__name__) # list of cat images images = [ &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr05/15/9/anigif_enhanced-buzz-26388-1381844103-11.gif&quot;, &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr01/15/9/anigif_enhanced-buzz-31540-1381844535-8.gif&quot;, &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr05/15/9/anigif_enhanced-buzz-26390-1381844163-18.gif&quot;, &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr06/15/10/anigif_enhanced-buzz-1376-1381846217-0.gif&quot;, &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr03/15/9/anigif_enhanced-buzz-3391-1381844336-26.gif&quot;, &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr06/15/10/anigif_enhanced-buzz-29111-1381845968-0.gif&quot;, &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr03/15/9/anigif_enhanced-buzz-3409-1381844582-13.gif&quot;, &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr02/15/9/anigif_enhanced-buzz-19667-1381844937-10.gif&quot;, &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr05/15/9/anigif_enhanced-buzz-26358-1381845043-13.gif&quot;, &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr06/15/9/anigif_enhanced-buzz-18774-1381844645-6.gif&quot;, &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr06/15/9/anigif_enhanced-buzz-25158-1381844793-0.gif&quot;, &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr03/15/10/anigif_enhanced-buzz-11980-1381846269-1.gif&quot; ] @app.route(&apos;/&apos;) def index(): url = random.choice(images) return render_template(&apos;index.html&apos;, url=url) if __name__ == &quot;__main__&quot;: app.run(host=&quot;0.0.0.0&quot;) requirements.txt为了为我们的app安装所需的Python模块,我们需要创建一个requirements.txt文件并且添加如下内容: Flask==0.10.1 templates/index.html创建一个命名为templates的目录并且在其中创建一个index.html 文件，具体内容如下: &lt;html&gt; &lt;head&gt; &lt;style type=&quot;text/css&quot;&gt; body { background: black; color: white; } div.container { max-width: 500px; margin: 100px auto; border: 20px solid white; padding: 10px; text-align: center; } h4 { text-transform: uppercase; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;container&quot;&gt; &lt;h4&gt;Cat Gif of the day&lt;/h4&gt; &lt;img src=&quot;{{url}}&quot; /&gt; &lt;p&gt;&lt;small&gt;Courtesy: &lt;a href=&quot;http://www.buzzfeed.com/copyranter/the-best-cat-gif-post-in-the-history-of-cat-gifs&quot;&gt;Buzzfeed&lt;/a&gt;&lt;/small&gt;&lt;/p&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 编写一个Dockerfile文件我们想要为这个web app创建一个Docker镜像.就像上述提到的,所有的用户镜像都是基于基础镜像.因为我们的应用是用Python编写的,我们将会在Alpine的基础上构建我们的Python镜像.完成这一点我们需要使用一个Dockerfile. Dockerfile实际上只是一个包含了一系列docker指令的text文件,当创建镜像的时候,docker 守护进程会从后台调用.Dockerfile包含了所有Docker应该如何去运行这个app的所有信息 - 一个基础Docker 镜像从哪里运行,你项目代码的路径,它拥有的所有依赖 和启动是运行的命令.这是一个镜像创建过程自动化的最普遍方式.这种方式最大的优点是你在Dockerfile编写的命令完全等同于它们的linux命令.这意味着你不用去学习新的语法来创建你的Dockerfile文件. 1.创建一个命名为Dockerfile的文件,并添加如下描述内容. 我们将通过From关键字指令指定我们的基础镜像: FROM alpine:3.5 2.下一步骤通常是编写复制文件和安装依赖的指令.但首先我们需要安装Python pip 包 到alpine linux发布版本.其它依赖安装也是同样，包括python interpreter 解释器.添加如下RUN命令: RUN apk add --update py2-pip 3.添加 Flask Application的组成文件 安装所有我们app运行所需的Python requirements.通过以下命令完成: COPY requirements.txt /usr/src/app/ RUN pip install --no-cache-dir -r /usr/src/app/requirements.txt 通过COPY 命令复制你早期创建的文件到我们的镜像当中. COPY app.py /usr/src/app/ COPY templates/index.html /usr/src/app/templates/ 4.指定需要暴露的接口.flask app运行的端口是5000. EXPOSE 5000 5.最后的步骤是运行我们的应用-python ./app.py.使用CMD指令: CMD [&quot;python&quot;, &quot;/usr/src/app/app.py&quot;] CMD命令的主要目的是告诉容器当它启动时默认应该运行哪些指令. 6.验证你的Dockerfile文件. 我们的Dockerfile文件终于准备好了.内容汇总如下: # our base image FROM alpine:3.5 # Install python and pip RUN apk add --update py2-pip # install Python modules needed by the Python app COPY requirements.txt /usr/src/app/ RUN pip install --no-cache-dir -r /usr/src/app/requirements.txt # copy files required for the app to run COPY app.py /usr/src/app/ COPY templates/index.html /usr/src/app/templates/ # tell the port number the container should expose EXPOSE 5000 # run the application CMD [&quot;python&quot;, &quot;/usr/src/app/app.py&quot;] 构建镜像现在你已经有了自己的Dockerfile,你可以构建自己的镜像.docker build命令依据Dockerfile完成创建docker image的一系列复杂任务. 当你运行以下的docker build命令,确保用你的用户名去替换 .这个用户名必须跟你在Docker Cloud注册创建的用户名保持一致.如果你还没有完成这一步,请先到Docker Cloud创建一个账户. docker build 命令相当简单 - 它提供一个可选的-t 参数 和包含Dockerfile文件的路径 - . 表明当前路径: $ docker build -t &lt;YOUR_USERNAME&gt;/myfirstapp . Sending build context to Docker daemon 9.728 kB Step 1 : FROM alpine:latest ---&gt; 0d81fc72e790 Step 2 : RUN apk add --update py-pip ---&gt; Running in 8abd4091b5f5 fetch http://dl-4.alpinelinux.org/alpine/v3.3/main/x86_64/APKINDEX.tar.gz fetch http://dl-4.alpinelinux.org/alpine/v3.3/community/x86_64/APKINDEX.tar.gz (1/12) Installing libbz2 (1.0.6-r4) (2/12) Installing expat (2.1.0-r2) (3/12) Installing libffi (3.2.1-r2) (4/12) Installing gdbm (1.11-r1) (5/12) Installing ncurses-terminfo-base (6.0-r6) (6/12) Installing ncurses-terminfo (6.0-r6) (7/12) Installing ncurses-libs (6.0-r6) (8/12) Installing readline (6.3.008-r4) (9/12) Installing sqlite-libs (3.9.2-r0) (10/12) Installing python (2.7.11-r3) (11/12) Installing py-setuptools (18.8-r0) (12/12) Installing py-pip (7.1.2-r0) Executing busybox-1.24.1-r7.trigger OK: 59 MiB in 23 packages ---&gt; 976a232ac4ad Removing intermediate container 8abd4091b5f5 Step 3 : COPY requirements.txt /usr/src/app/ ---&gt; 65b4be05340c Removing intermediate container 29ef53b58e0f Step 4 : RUN pip install --no-cache-dir -r /usr/src/app/requirements.txt ---&gt; Running in a1f26ded28e7 Collecting Flask==0.10.1 (from -r /usr/src/app/requirements.txt (line 1)) Downloading Flask-0.10.1.tar.gz (544kB) Collecting Werkzeug&gt;=0.7 (from Flask==0.10.1-&gt;-r /usr/src/app/requirements.txt (line 1)) Downloading Werkzeug-0.11.4-py2.py3-none-any.whl (305kB) Collecting Jinja2&gt;=2.4 (from Flask==0.10.1-&gt;-r /usr/src/app/requirements.txt (line 1)) Downloading Jinja2-2.8-py2.py3-none-any.whl (263kB) Collecting itsdangerous&gt;=0.21 (from Flask==0.10.1-&gt;-r /usr/src/app/requirements.txt (line 1)) Downloading itsdangerous-0.24.tar.gz (46kB) Collecting MarkupSafe (from Jinja2&gt;=2.4-&gt;Flask==0.10.1-&gt;-r /usr/src/app/requirements.txt (line 1)) Downloading MarkupSafe-0.23.tar.gz Installing collected packages: Werkzeug, MarkupSafe, Jinja2, itsdangerous, Flask Running setup.py install for MarkupSafe Running setup.py install for itsdangerous Running setup.py install for Flask Successfully installed Flask-0.10.1 Jinja2-2.8 MarkupSafe-0.23 Werkzeug-0.11.4 itsdangerous-0.24 You are using pip version 7.1.2, however version 8.1.1 is available. You should consider upgrading via the &apos;pip install --upgrade pip&apos; command. ---&gt; 8de73b0730c2 Removing intermediate container a1f26ded28e7 Step 5 : COPY app.py /usr/src/app/ ---&gt; 6a3436fca83e Removing intermediate container d51b81a8b698 Step 6 : COPY templates/index.html /usr/src/app/templates/ ---&gt; 8098386bee99 Removing intermediate container b783d7646f83 Step 7 : EXPOSE 5000 ---&gt; Running in 31401b7dea40 ---&gt; 5e9988d87da7 Removing intermediate container 31401b7dea40 Step 8 : CMD python /usr/src/app/app.py ---&gt; Running in 78e324d26576 ---&gt; 2f7357a0805d Removing intermediate container 78e324d26576 Successfully built 2f7357a0805d 如果你并没有alpine:3.5的镜像,客户端将会首先拉取这个镜像，然后再创建你的镜像.因此,你运行命令之后的输出可能会稍有不同.如果一切运行正常,你的镜像就应该创建准备完毕.运行docker images 命令查看你的镜像(/myfirstapp)是否展示. 运行你的镜像下一步骤是运行你的镜像并且查看它是否正常工作. $ docker run -p 8888:5000 --name myfirstapp YOUR_USERNAME/myfirstapp * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit) 访问 http://localhost:8888 确认你的app是否存活.注意: 如果你使用Docker Machine,你可能需要打开另一个终端并且使用docker-machine ip default命令来决定容器的ip地址. 点击在web浏览器的刷新按钮来查看更多猫的图片. 推送你的镜像(push your image)现在你已经创建并且测试了你的镜像,你可以把它推送到Docker Cloud. 首先你必须登录到你的Docker Cloud 账户: docker login 输入你的用户名和密码然后执行如下命令: docker push YOUR_USERNAME/myfirstapp 现在你这个容器的工作以及完成了,停止并且移除它因为你不再需要再次使用它了. 打开另一个终端窗口并且执行如下命令: $ docker stop myfirstapp $ docker rm myfirstapp 或者 $ docker rm -f myfirstapp Dockerfile 命令总结这是一个我们在Dockerfile中使用的基础命令的快速总结. FROM 是Dockerfile的开头.Dockerfile必须以FROM命令开头.镜像是在layers中创建,这意味着你可以使用另一个镜像作为base镜像.FROM命令定义你的base layer.它将镜像的名称作为参数.你可以选择是否添加维护者的Docker Cloud用户名和镜像版本，以 username/imagename:version的格式. RUN是用来构建你创建的镜像.对于每个RUN命令来说，Docker将会运行这个命令然后为这个镜像创建新的layer.这种方式你可以你可以轻松回滚你的镜像到邻近的状态.RUN指令的语法是在RUN命令后放置shell命令(eg.,RUN mkdir /user/local/foo).这将会自动在一个 /bin/sh shell环境中运行.你可以像这样定义一个不同的shell:RUN /bin/bash -c ‘mkdir /user/local/foo’ COPY 复制本地文件到容器当中. CMD 定义在镜像启动阶段将会运行的命令.不同于RUN，这个命令不会为镜像创建新的layer,只是单纯的运行命令.每个Dockerfille/Image只能有一个CMD.如果你需要运行多个指令,最好的方式是用CMD运行一个script脚本.CMD需要你告诉它去哪里运行命令,不像RUN.示例如下: CMD [&quot;python&quot;, &quot;./app.py&quot;] CMD [&quot;/bin/bash&quot;, &quot;echo&quot;, &quot;Hello World&quot;] EXPOSE 为用户的镜像创建线索，比如ports提供服务.它包含了可以经由$ docker inspect 命令恢复的所有信息. Note: EXPOSE命令实际上并不是让主机上的任何端口变得可访问!相反,这意味着需要通过使用 $ docker run -p命令在发布端口 PUSH 推送你的镜像到Docker Cloud,或一个私人的registry. Note: 如果你想要了解更多关于Dockerfiles的内容,查看Best practices for writing Dockerfiles","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.zhz.gift/tags/docker/"}]},{"title":"1.0 运行你的第一个容器","slug":"运行你的第一个容器","date":"2018-02-03T16:07:42.000Z","updated":"2018-03-15T14:41:40.282Z","comments":true,"path":"2018/02/04/运行你的第一个容器/","link":"","permalink":"http://www.zhz.gift/2018/02/04/运行你的第一个容器/","excerpt":"运行你的第一个容器现在你已经准备好了所有的东西,是时候开始实践了.在这个章节,我们将要运行一个 Alpine Linux 容器(一个轻量级的linux 发布版本)在你的系统上并且尝试一下docker的运行命令.","text":"运行你的第一个容器现在你已经准备好了所有的东西,是时候开始实践了.在这个章节,我们将要运行一个 Alpine Linux 容器(一个轻量级的linux 发布版本)在你的系统上并且尝试一下docker的运行命令. 首先运行以下命令: $ docker pull alpine Note:根据你在系统中安装docker的方式,在运行以上命令后你可能会看到一个ermission denied的错误.尝试在安装教程中的命令去验证你的安装.如果你是Linux系统,你可能需要在你的命令前面加上sudo.或者你可以创建一个docker group来拜托这个问题. pull命令从Dcoker仓库获取 alpine 镜像并且保存在我们的系统中.你可以使用docker images 命令来查看在你系统中的所有镜像. $ docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE alpine latest c51f86c28340 4 weeks ago 1.109 MB hello-world latest 690ed74de00f 5 months ago 960 B Docker Run接下来基于这个镜像运行一个Docker 容器.只需要通过 docker run命令我们就能做到这一点. $ docker run alpine ls -l total 48 drwxr-xr-x 2 root root 4096 Mar 2 16:20 bin drwxr-xr-x 5 root root 360 Mar 18 09:47 dev drwxr-xr-x 13 root root 4096 Mar 18 09:47 etc drwxr-xr-x 2 root root 4096 Mar 2 16:20 home drwxr-xr-x 5 root root 4096 Mar 2 16:20 lib ...... ...... 当你运行 docker run命令的时候,Docker 客户端联系Docker守护进程. Docker 守护进程会首先检查所有本地存储,确定镜像(本例是alpine)在本地可用,如果不可用的话，从Docker Store 下载.(直到我们发布docker pull alpine 之前,下载步骤不是必须的) Docker 守护进程创建容器接下来在容器内运行一个命令. Docker守护进程将该命令的输出以流的形式返回给客户端. 接下来运行如下命令: $ docker run alpine echo &quot;hello from alpine&quot; hello from alpine “hello from alpine”就是实际的输出.在这个场景,Docker 客户端忠实地在我们的alpine容器运行echo命令然后自动退出.如果你多加注意的话，你会发现所有的一切发生的相当快.镜像在虚拟机中启动,运行一个命令然后销毁它.现在你知道为什么容器运行速度如此之快！ 接下来运行另一个命令: $ docker run alpine /bin/sh 什么都没有发生,这些交互式shell会在运行任意scripted命令之后退出.除非它们是在一个交互式终端中运行 - 所以为了让它不自动退出，你需要用docker run -it alpine /bin/sh命令来代替. 你现在便处于容器 shell 当中 ,并且可以尝试使用一些命令比如:ls -l,uname -a 或者其它等等.通过exit命令来退出容器. docker ps命令向你展示所有正确运行的容器. $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 因为没有运行中的容器,所以展示列表是空的.接下来尝试使用一个有用的变量,运行 docker ps -a命令 $ docker ps -a $ docker ps -a|CONTAINER ID |IMAGE |COMMAND |CREATED |STATUS | PORTS |NAMES||:—-:|:—-:|:—-:|:—-:|:—-:|:—-:|:—-:||36171a5da744 |alpine | “/bin/sh” | 5 minutes ago |Exited (0) 2 minutes ago | |fervent_newton||a6a9d46d0b2f | alpine | “echo ‘hello from alp” |6 minutes ago |Exited (0) 6 minutes ago | |lonely_kilby|ff0a5c3750b9 | alpine | “ls -l” |8 minutes ago | Exited (0) 8 minutes ago | |elated_ramanujan|c317d0a9e3d2 | hello-world | “/hello” |34 seconds ago |Exited (0) 12 minutes ago | |stupefied_mcclintock 上面是所有你能够运行的容器.可以注意到STATUS列展示了容器是在几分钟前推出的.接下来尝试在一个容器中运行多条命令. $ docker run -it alpine /bin/sh / # ls bin dev etc home lib linuxrc media mnt proc root run sbin sys tmp usr var / # uname -a Linux 97916e8cb5dc 4.4.27-moby #1 SMP Wed Oct 26 14:01:48 UTC 2016 x86_64 Linux 通过运行run命令附加-it标志的方式使我们能在容器中以交互式终端的方式进行交互.现在你能在容器运行任意数量的命令. 如上述我们已经展示了你可能使用最频繁的命令,你可以通过使用docker run –help来展示该命令所有支持的附加选项.随着你继续深入的学习,我们也将会看到docker run命令支持的更多变量. Terminology(术语)在上一小节,你已经看到了许多Docker 特殊的术语,你可能会对其中一些感到困惑.所以在我们继续深入之前,先阐述一下一些我们在Docker 生态系统(ecosystem)中经常性使用的术语. Images - 用来创建容器的属于我们应用的文件系统和相关配置.想要知道更多关于Docker镜像,运行docker inspect alpine命令.在上面的demo中,我们通过docker pull命令来下载alpine镜像.当你执行docker run hello-world命令,它同样会在后台运行docker pull命令以下载hello-world镜像. Containers - 用以运行Docker镜像的实例 - 容器会运行实际的应用.一个容器包含一个应用和它的所有依赖.它和其它容器共享内核,并且在宿主操作系统上面的用户空间以一个隔离进程运行.你通过docker run命令创建一个容器以运行alpine image 的实例.通过docker ps命令来展示一系列正在运行的容器. Docker daemon - Docker 守护进程是一个运行在主机上的后台服务,它用于提供管理构建,运行和分配Docker容器. Docker client - Docker 客户端,这是一个命令行工具，允许用户和Docker守护进程进行交互. Docker Store - Docker 商店,一个Docker镜像的登记处,在这个平台上你可以查询找到可信以及可供企业使用的容器,插件以及 其它Docker的特别版本.在这个教程中你将在之后使用到它. 参考链接","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.zhz.gift/tags/docker/"}]},{"title":"Ubuntu docker 安装","slug":"Ubuntu docker 安装","date":"2018-02-03T16:07:42.000Z","updated":"2018-02-03T16:24:48.814Z","comments":true,"path":"2018/02/04/Ubuntu docker 安装/","link":"","permalink":"http://www.zhz.gift/2018/02/04/Ubuntu docker 安装/","excerpt":"Docker是什么?Docker是一种容器技术.Docker容器技术已在云计算市场上风靡一时了，使docker容器技术如此受欢迎的原因是，容器技术可实现不同云计算之间应用程序的可移植性，以及提供了一个把应用程序拆分为分布式组件的方法，此外，用户还可以管理和扩展这些组件成为集群.","text":"Docker是什么?Docker是一种容器技术.Docker容器技术已在云计算市场上风靡一时了，使docker容器技术如此受欢迎的原因是，容器技术可实现不同云计算之间应用程序的可移植性，以及提供了一个把应用程序拆分为分布式组件的方法，此外，用户还可以管理和扩展这些组件成为集群. 官网链接 一旦你完成docker的安装后,可以用如下命令对你的docker进行测试: $ docker run hello-world Unable to find image &apos;hello-world:latest&apos; locally latest: Pulling from library/hello-world 03f4658f8b78: Pull complete a3ed95caeb02: Pull complete Digest: sha256:8be990ef2aeb16dbcb9271ddfe2610fa6658d13f6dfb8bc72074cc1ca36966a7 Status: Downloaded newer image for hello-world:latest Hello from Docker. This message shows that your installation appears to be working correctly. ... 卸载老版本老版本的Docker一般命名为 docker 或者 docker-engine.在安装新版本前需要对他们进行卸载. $ sudo apt-get remove docker docker-engine docker.io 即时apt-get命令提示没有上述的任意包被安装也没有影响./var/lib/docker/ 文件夹一般包含images, containers, volumes, and networks等. Docker CE包现在被命名为: docker-ce 安装Docker CE你可以根据需要选择以下合适的方式来安装Docker CE： 通过repository进行安装在你第一次在一台新主机上安装docker之前,你需要先设置Docker仓库,之后,你就可以直接通过仓库安装和更新Docker.设置仓库 更新apt命令的包索引 1sudo apt-get update 安装仓库使用所需的https依赖包 12345sudo apt-get install \\apt-transport-https \\ca-certificates \\curl \\software-properties-common 添加Docker的官方GPG key 12$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 验证你现在拥有的指纹秘钥:(eg:)9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88搜索最后八个长度的指纹: 123456789 $ sudo apt-key fingerprint 0EBFCD88 pub 4096R/0EBFCD88 2017-02-22 Key fingerprint = 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 uid Docker Release (CE deb) &lt;docker@docker.com&gt; sub 4096R/F273FCD8 2017-02-22 ``` 4. 使用以下命令来设置你的stable repository(稳定仓库).你总是需要stable repository,即使你想要从edge或者test仓库安装构建也一样.想要添加edge或者test仓库,只需在以下命令的stable后面添加相应的edge或者test即可. 提示：lsb_release -cs 子命令返回你Ubuntu发布版本的名称,例如xenial.有时候,一些发布版本,比如Linux Mint,你可能需要把 $(lsb_release -cs)命令换成你对应的父级 Ubuntu 发布版本比如,如果你正在使用Linux Mint Rafaela,你可能要使用 trusty. 1**x86_64 / amd64** $ sudo add-apt-repository \\ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable&quot; 1234567 **提示:从17.06版本开始,stable 发布时会同样推送到edge和test仓库.** [Learn about stable and edge channels.](https://docs.docker.com/install/) **Docker CE安装步骤** 1. 更新apt包索引... $ sudo apt-get update 123 2. 安装最新版本的Docker CE或者直接到下一步安装特定版本的Docker CE. 任何当前的版本会被替换为安装的版本. $ sudo apt-get install docker-ce 1 获取多个Docker仓库? 如果你有多个可用的Docker仓库,安装或者更新操作没有指定特定的版本,apt-get install 或者apt-get update 命令总是会按照最高的可用版本,可能并不满足你稳定性的需要. 12345678910111213141516171819202122232425262728293031 3. 在生产环境,你需要使用特定版本的Docker CE版本而不是一直使用最新的. 以下命令会列出所有可用版本(输出只展示了一部分): ``` $ apt-cache madison docker-ce docker-ce | 17.12.0~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages ``` 该列表数据依赖于你可用的仓库.选择一个特定的版本去安装.第二列是版本字符串.第三列是仓库名,用来表明该仓库的来源地址和稳定性等级,stable,edge或者test.想要安装特定的版本,只需在包名后面添加(=)后和版本字符串即可. ``` $ sudo apt-get install docker-ce=&lt;VERSION&gt; ``` Docker守护进程在安装完成后会自动启动.4. 通过运行hello-world image 来验证Docker CE是否已经正确安装.``` $ sudo docker run hello-world ``` 这个命令会下载一个测试镜像并且在容器中运行它.当容器运行,它会打印提示信息并且退出.Dcoker CE 已经安装并且运行.docker group 已经创建但是没有用户添加到它上面.你需要通过使用sudo命令去运行Docker命令.继续到[Linux postinstall](https://docs.docker.com/install/linux/linux-postinstall/)去允许未授权的用户能够运行Docker命令和一些可选的配置步骤.**升级 DOCKER CE**升级Docker CE,首先同样通过sudo命令更新包索引apt-get update,然后按照按照指令,选择新的版本直接进行安装即可.**卸载Docker CE**1. 卸载Docker CE包: $ sudo apt-get purge docker-ce 12. 手动删除镜像，容器等文件(Images, containers, volumes, or customized configuration files) $ sudo rm -rf /var/lib/docker ``` 你必须删除所有已编辑的配置文件.","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.zhz.gift/tags/docker/"}]},{"title":"HikariCP 配置说明","slug":"HikariCP 配置说明","date":"2018-01-29T16:07:42.000Z","updated":"2018-01-30T14:37:52.602Z","comments":true,"path":"2018/01/30/HikariCP 配置说明/","link":"","permalink":"http://www.zhz.gift/2018/01/30/HikariCP 配置说明/","excerpt":"Fast, simple, reliable. HikariCP is a “zero-overhead” production ready JDBC connection pool. At roughly 130Kb, the library is very light.","text":"Fast, simple, reliable. HikariCP is a “zero-overhead” production ready JDBC connection pool. At roughly 130Kb, the library is very light. 官网连接 必要配置 dataSourceClassName 数据源驱动名 jdbcUrl jdbc数据库连接 username 用户名 password 密码 其中dataSourceClassName和jdbcUrl二选一，当使用比较老版本的驱动时，需要同时设置jdbcUrl和driverClassName，dataSourceClassName则不用进行设置 可选配置 常用属性 connectionTimeout 连接超时时间,最小时间为250 ms，默认为30000ms(30秒) idleTimeout 空闲超时时间，这个属性用来控制空闲连接允许保留在连接池中的最大时间，这个属性只有在minimumIdle（最小空闲连接数）小于maximumPoolSize(最大连接数)时才会生效,空闲连接断开会有15s-30s的延迟变动时间.在这个超时时间之前空闲连接永远不会断开,当连接池达到minimumIdle,连接将永远不会断开，即使处于闲置状态.值为0表示空闲连接将永远不会从连接池中移除，最小值为10000ms （10s),默认值为600000(10min) maxLifetime 最大生命周期.这个属性用来控制连接池中连接的最大生命周期,一个使用中的连接永远不会被断开,只有当它处于关闭状态然后才会被移除.推荐设置比任何数据库或基础设施规定的连接时间限制少至少30秒。 值为0表示没有最大寿命（无限寿命）， 默认：1800000（30分钟）,由于HikariCP的housekeeper默认每30s运行一次,以维护minimumIdle最小空闲连接数，它可能添加新连接或者断开空闲连接，所以你必须设置maxLifetime属性比（mysql)wait_timeout时间少一些来避免 broken connection / exceptions.意思就是说比如mysql wait_timeout为10min,此时有一个连接由于达到超时时间，mysql主动断开了连接，而HakariCP仍然持有此连接，如果再使用此连接去请求数据库则会发生异常,设置maxLifetime最大生命周期比wait_timeout少30s后,就能确保再housekeeper运行期间提前断开此连接，避免发生异常. connectionTestQuery 连接测试查询,如果你的驱动支持jdbc4，则不需要设置此属性，这个属性是为那些不支持Connection.isValid() API的古董级驱动准备的，这是一个查询，用来确保所有请求得到的连接都是alive有效的，尝试不设置这个属性运行连接池，如果你的驱动不支持jdbc4，HikariCP会有错误日志提示.Default:None minimumIdle 最小空闲连接，当空闲连接小于这个值并且总连接数小于maximumPoolSize（最大连接数)HikariCP会尽可能快速有效率地创建额外的连接，然而为了最大限度地提高性能和响应能力，不建议设置这个值，而是用固定大小的连接池取代.Default:与maximumPoolSize相同 maximumPoolSize 最大连接池数量，包括使用中和空闲的连接，当达到最大连接池数量时，再尝试获取连接，只能得到connectionTimeout 超时信息.Default:10. metricRegistry 度量注册, Default: none 参考链接 healthCheckRegistry 健康检查注册 Default: none poolName 连接池名字,一般用于日志输出 Default: auto-generated 不常使用 initializationFailTimeout 初始化失败超时时间 Default: 1 isolateInternalQueries 是否隔离默认查询 Default: 1 allowPoolSuspension 是否允许连接池暂停 Default: false readOnly 连接是否只读 Default: false registerMbeans 是否注册JMX Management Beans Default: false catalog 目录服务 connectionInitSql 连接初始化sql Default: none driverClassName 驱动名称 Default: none transactionIsolation 事务隔离 Default: driver default validationTimeout 验证超时时间 Default: 5000 leakDetectionThreshold 最低发现阈值 Default: 0 dataSource 数据源 Default: none schema 架构 Default: driver default threadFactory 线程工厂 Default: none scheduledExecutor 计划执行器 Default: none Statement CacheMany connection pools, including Apache DBCP, Vibur, c3p0 and others offer PreparedStatement caching. HikariCP does not. Why?许多连接池，包括Aache DBCP,Vibur,c3p0 等都是提供PreparedStatement caching.HikariCP并不这样做，为什么？ At the connection pool layer PreparedStatements can only be cached per connection. If your application has 250 commonly executed queries and a pool of 20 connections you are asking your database to hold on to 5000 query execution plans – and similarly the pool must cache this many PreparedStatements and their related graph of objects. 在连接池中每个连接只能缓存各自的PreparedStatements对象.如果你的应用有250个要执行的普通查询和一个20个连接的连接池，然后你需要不间断地请求你的数据库去完成一个5000查询的执行计划，显然你的连接池必须缓存这所有的PreparedStatements对象和它们相关联的表对象. Most major database JDBC drivers already have a Statement cache that can be configured, including PostgreSQL, Oracle, Derby, MySQL, DB2, and many others. JDBC drivers are in a unique position to exploit database specific features, and nearly all of the caching implementations are capable of sharing execution plans across connections. This means that instead of 5000 statements in memory and associated execution plans, your 250 commonly executed queries result in exactly 250 execution plans in the database. Clever implementations do not even retain PreparedStatement objects in memory at the driver-level but instead merely attach new instances to existing plan IDs. 许多主流的数据库，它们的jdbc驱动已经有了一个可配置的Statement缓存，包括PostgreSQL, Oracle, Derby, MySQL, DB2等等.JDBC驱动是唯一能利用数据库特定属性的方式，并且近乎所有的缓存实现都可以通过连接共享执行计划.这意味着你的250个普通查询结果在数据库中就是250个执行计划，而不是存储在内存中的5000个statements及其相关联的执行计划.聪明的缓存实现在驱动这一级别并不保持PreparedStatement对象在内存当中，而是为已存在的计划创建新的PreparedStatement实例. Using a statement cache at the pooling layer is an anti-pattern, and will negatively impact your application performance compared to driver-provided caches. 在连接池层使用statement缓存是一个反面教材,并且相较驱动提供的缓存会对你的应用性能造成更大的消极影响. Log Statement Text / Slow Query LoggingLike Statement caching, most major database vendors support statement logging through properties of their own driver. This includes Oracle, MySQL, Derby, MSSQL, and others. Some even support slow query logging. For those few databases that do not support it, several options are available. We have received a report that p6spy works well, and also note the availability of log4jdbc and jdbcdslog-exp. 就像Statement缓存，许多主流数据库供应商支持通过它们驱动的属性配置来添加statement logging的日志功能.这些数据库包括racle, MySQL, Derby, MSSQL等等.一些甚至支持慢查询日志记录功能.对于那些少数不支持的数据库,还有许多可用的其它方式.比如,p6spy,log4jdbc以及jdbcdslog-exp等等. mysql推荐配置Statement和PreparedStatement对象的区别","categories":[],"tags":[{"name":"pool","slug":"pool","permalink":"http://www.zhz.gift/tags/pool/"}]},{"title":"git 换行符LF与CRLF转换问题","slug":"git 换行符LF与CRLF转换问题","date":"2018-01-28T16:07:42.000Z","updated":"2018-01-29T14:04:28.319Z","comments":true,"path":"2018/01/29/git 换行符LF与CRLF转换问题/","link":"","permalink":"http://www.zhz.gift/2018/01/29/git 换行符LF与CRLF转换问题/","excerpt":"一、背景在各操作系统下，文本文件所使用的换行符是不一样的。UNIX/Linux 使用的是 0x0A（LF），早期的 Mac OS 使用的是0x0D（CR），后来的 OS X 在更换内核后与 UNIX 保持一致了。但 DOS/Windows 一直使用 0x0D0A（CRLF）作为换行符。Git提供了一个“换行符自动转换”功能。这个功能默认处于“自动模式”，当你在签出文件时，它试图将 UNIX 换行符（LF）替换为 Windows 的换行符（CRLF）；当你在提交文件时，它又试图将 CRLF 替换为 LF。Git 的“换行符自动转换”功能听起来似乎很智能、很贴心，因为它试图一方面保持仓库内文件的一致性（UNIX 风格），一方面又保证本地文件的兼容性（Windows 风格）。但遗憾的是，这个功能是有 bug 的，而且在短期内都不太可能会修正。","text":"一、背景在各操作系统下，文本文件所使用的换行符是不一样的。UNIX/Linux 使用的是 0x0A（LF），早期的 Mac OS 使用的是0x0D（CR），后来的 OS X 在更换内核后与 UNIX 保持一致了。但 DOS/Windows 一直使用 0x0D0A（CRLF）作为换行符。Git提供了一个“换行符自动转换”功能。这个功能默认处于“自动模式”，当你在签出文件时，它试图将 UNIX 换行符（LF）替换为 Windows 的换行符（CRLF）；当你在提交文件时，它又试图将 CRLF 替换为 LF。Git 的“换行符自动转换”功能听起来似乎很智能、很贴心，因为它试图一方面保持仓库内文件的一致性（UNIX 风格），一方面又保证本地文件的兼容性（Windows 风格）。但遗憾的是，这个功能是有 bug 的，而且在短期内都不太可能会修正。 二、解决方案1.Git设置 git config –global core.autocrlf falsegit config –global core.safecrlf true含义：AutoCRLF提交时转换为LF，检出时转换为CRLFgit config –global core.autocrlf true 提交时转换为LF，检出时不转换git config –global core.autocrlf input 提交检出均不转换git config –global core.autocrlf falseSafeCRLF拒绝提交包含混合换行符的文件git config –global core.safecrlf true 允许提交包含混合换行符的文件git config –global core.safecrlf false 提交包含混合换行符的文件时给出警告git config –global core.safecrlf warn 一般在开发中为了保持项目换行符转换不出错，将autocrlf设置为false,然后重新clone项目。 也可以直接修改git全局配置文件，windows配置路径:C:\\Users\\Administrator.gitconfig [filter &quot;lfs&quot;] required = true clean = git-lfs clean %f smudge = git-lfs smudge %f [user] name = zhonghanzhong [user] email = yyesnnovv@aliyun.com [credential] helper = manager [http] sslVerify = false [core] autocrlf = false","categories":[],"tags":[{"name":"DevelopNote","slug":"DevelopNote","permalink":"http://www.zhz.gift/tags/DevelopNote/"},{"name":"git","slug":"git","permalink":"http://www.zhz.gift/tags/git/"}]},{"title":"jooq介绍","slug":"jooq介绍","date":"2018-01-14T16:07:42.000Z","updated":"2018-01-15T14:05:22.807Z","comments":true,"path":"2018/01/15/jooq介绍/","link":"","permalink":"http://www.zhz.gift/2018/01/15/jooq介绍/","excerpt":"jooq是什么jOOQ（Java Object Oriented Querying，即面向Java对象查询）是基于Java访问关系型数据库的工具包，轻量，简单，并且足够灵活，可以轻松的使用Java面向对象语法来实现各种复杂的sql;是一个高效地合并了复杂SQL、类型安全、源码生成、ActiveRecord、存储过程以及高级数据类型的Java API的类库.","text":"jooq是什么jOOQ（Java Object Oriented Querying，即面向Java对象查询）是基于Java访问关系型数据库的工具包，轻量，简单，并且足够灵活，可以轻松的使用Java面向对象语法来实现各种复杂的sql;是一个高效地合并了复杂SQL、类型安全、源码生成、ActiveRecord、存储过程以及高级数据类型的Java API的类库. jooq的特点 类型安全(TypeSafe SQL)jooq使用内部的DSL(domain specific language领域专用语言)对sql进行模块化，并且使用java编译器去编译你的sql语法，元数据以及数据类型. 映射代码生成jooq可以从你的数据库元数据生成对应的java映射类，生成的实体类按照数据库字段以驼峰命名法重新命名，同时用户可以通过继承实体类的方式来添加自定义属性及方法. ActiveRecords我们jooq通过代码生成器生成的ActiveReocrds可以直接对POJO(Plain Old Java Object)映射对象进行CRUD(Create Retrieve Update Delete)操作 多架构(多模式Schema)jooq允许你在运行时环境动态配置数据库模式和表并且支持行级别的安全性,即通过不同的jooq Configuration配置得到对应的DSLContext上下文再对数据库进行CRUD操作. 标准化jooq可以通过配置数据库方言来支持不同的数据库:mysql,oracle等等,比如通过spring配置spring.jooq.sql-dialect = mysql 来支持mysql数据库 查询生命周期jooq通过一些接口开放SQL生成的生命周期，包括日志，事务处理，id生成，sql转换等等。 存储过程jooq允许你在模块化sql语句中嵌入存储过程调用. 强大的Fluent API和完善文档,使用方便流畅 参考链接https://www.jianshu.com/p/46164f9ba53chttps://www.jooq.org/","categories":[],"tags":[{"name":"jooq","slug":"jooq","permalink":"http://www.zhz.gift/tags/jooq/"}]},{"title":"Pom.xml详解","slug":"Pom.xml详解","date":"2018-01-10T16:07:42.000Z","updated":"2018-01-11T15:29:33.547Z","comments":true,"path":"2018/01/11/Pom.xml详解/","link":"","permalink":"http://www.zhz.gift/2018/01/11/Pom.xml详解/","excerpt":"Maven pom.xml详细配置说明","text":"Maven pom.xml详细配置说明 1.概述pom中节点如下分布 &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 基本配置 --&gt; &lt;groupId&gt;...&lt;/groupId&gt; &lt;artifactId&gt;...&lt;/artifactId&gt; &lt;version&gt;...&lt;/version&gt; &lt;packaging&gt;...&lt;/packaging&gt; &lt;!-- 依赖配置 --&gt; &lt;dependencies&gt;...&lt;/dependencies&gt; &lt;parent&gt;...&lt;/parent&gt; &lt;dependencyManagement&gt;...&lt;/dependencyManagement&gt; &lt;modules&gt;...&lt;/modules&gt; &lt;properties&gt;...&lt;/properties&gt; &lt;!-- 构建配置 --&gt; &lt;build&gt;...&lt;/build&gt; &lt;reporting&gt;...&lt;/reporting&gt; &lt;!-- 项目信息 --&gt; &lt;name&gt;...&lt;/name&gt; &lt;description&gt;...&lt;/description&gt; &lt;url&gt;...&lt;/url&gt; &lt;inceptionYear&gt;...&lt;/inceptionYear&gt; &lt;licenses&gt;...&lt;/licenses&gt; &lt;organization&gt;...&lt;/organization&gt; &lt;developers&gt;...&lt;/developers&gt; &lt;contributors&gt;...&lt;/contributors&gt; &lt;!-- 环境设置 --&gt; &lt;issueManagement&gt;...&lt;/issueManagement&gt; &lt;ciManagement&gt;...&lt;/ciManagement&gt; &lt;mailingLists&gt;...&lt;/mailingLists&gt; &lt;scm&gt;...&lt;/scm&gt; &lt;prerequisites&gt;...&lt;/prerequisites&gt; &lt;repositories&gt;...&lt;/repositories&gt; &lt;pluginRepositories&gt;...&lt;/pluginRepositories&gt; &lt;distributionManagement&gt;...&lt;/distributionManagement&gt; &lt;profiles&gt;...&lt;/profiles&gt; &lt;/project&gt; 2.基本配置 modelVersion：pom模型版本，maven2和3只能为4.0.0 groupId：组ID，maven用于定位 artifactId：在组中的唯一ID用于定位 version：项目版本 packaging：项目打包方式，有以下值：pom, jar, maven-plugin, ejb, war, ear, rar, par 3.依赖配置parent 用于确定父项目的坐标。 &lt;parent&gt; &lt;groupId&gt;com.learnPro&lt;/groupId&gt; &lt;artifactId&gt;SIP-parent&lt;/artifactId&gt; &lt;relativePath&gt;&lt;/relativePath&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; groupId：父项目的构件标识符 artifactId：父项目的唯一标识符 relativePath：Maven首先在当前项目的找父项目的pom，然后在文件系统的这个位置（relativePath），然后在本地仓库，再在远程仓库找。 version：父项目的版本 modules 有些maven项目会做成多模块的，这个标签用于指定当前项目所包含的所有模块。之后对这个项目进行的maven操作，会让所有子模块也进行相同操作。 &lt;modules&gt; &lt;module&gt;com-a&lt;/module&gt; &lt;module&gt;com-b&lt;/module&gt; &lt;module&gt;com-c&lt;/module&gt; &lt;/modules&gt; properties 用于定义pom常量 &lt;properties&gt; &lt;java.version&gt;1.7&lt;/java.version&gt; &lt;/properties&gt; 上面这个常量可以在pom文件的任意地方通过${java.version}来引用 dependencies 项目相关依赖配置，如果在父项目写的依赖，会被子项目引用，一般父项目会将子项目公用的依赖引入（将在之后详细讲解） &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 这边依赖和中央仓库中的一致，就可以引入对应的jar dependencyManagement 配置写法同dependencies &lt;dependencyManagement&gt; &lt;dependencies&gt; ..... &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 在父模块中定义后，子模块不会直接使用对应依赖，但是在使用相同依赖的时候可以不加版本号： 父项目： &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 子项目： &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; 这样的好处是，父项目统一了版本，而且子项目可以在需要的时候才引用对应的依赖 4.构建配置build 用于配置项目构建相关信息 &lt;build&gt; &lt;!--该元素设置了项目源码目录，当构建项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。--&gt; &lt;sourceDirectory/&gt; &lt;!--该元素设置了项目脚本源码目录，该目录和源码目录不同：绝大多数情况下，该目录下的内容 会被拷贝到输出目录(因为脚本是被解释的，而不是被编译的)。--&gt; &lt;scriptSourceDirectory/&gt; &lt;!--该元素设置了项目单元测试使用的源码目录，当测试项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。--&gt; &lt;testSourceDirectory/&gt; &lt;!--被编译过的应用程序class文件存放的目录。--&gt; &lt;outputDirectory/&gt; &lt;!--被编译过的测试class文件存放的目录。--&gt; &lt;testOutputDirectory/&gt; &lt;!--使用来自该项目的一系列构建扩展--&gt; &lt;extensions&gt; &lt;!--描述使用到的构建扩展。--&gt; &lt;extension&gt; &lt;!--构建扩展的groupId--&gt; &lt;groupId/&gt; &lt;!--构建扩展的artifactId--&gt; &lt;artifactId/&gt; &lt;!--构建扩展的版本--&gt; &lt;version/&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;!--当项目没有规定目标（Maven2 叫做阶段）时的默认值--&gt; &lt;defaultGoal/&gt; &lt;!--这个元素描述了项目相关的所有资源路径列表，例如和项目相关的属性文件，这些资源被包含在最终的打包文件里。--&gt; &lt;resources&gt; &lt;!--这个元素描述了项目相关或测试相关的所有资源路径--&gt; &lt;resource&gt; &lt;!-- 描述了资源的目标路径。该路径相对target/classes目录（例如${project.build.outputDirectory}）。举个例 子，如果你想资源在特定的包里(org.apache.maven.messages)，你就必须该元素设置为org/apache/maven /messages。然而，如果你只是想把资源放到源码目录结构里，就不需要该配置。--&gt; &lt;targetPath/&gt; &lt;!--是否使用参数值代替参数名。参数值取自properties元素或者文件里配置的属性，文件在filters元素里列出。--&gt; &lt;filtering/&gt; &lt;!--描述存放资源的目录，该路径相对POM路径--&gt; &lt;directory/&gt; &lt;!--包含的模式列表，例如**/*.xml.--&gt; &lt;includes/&gt; &lt;!--排除的模式列表，例如**/*.xml--&gt; &lt;excludes/&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!--这个元素描述了单元测试相关的所有资源路径，例如和单元测试相关的属性文件。--&gt; &lt;testResources&gt; &lt;!--这个元素描述了测试相关的所有资源路径，参见build/resources/resource元素的说明--&gt; &lt;testResource&gt; &lt;targetPath/&gt;&lt;filtering/&gt;&lt;directory/&gt;&lt;includes/&gt;&lt;excludes/&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;!--构建产生的所有文件存放的目录--&gt; &lt;directory/&gt; &lt;!--产生的构件的文件名，默认值是${artifactId}-${version}。--&gt; &lt;finalName/&gt; &lt;!--当filtering开关打开时，使用到的过滤器属性文件列表--&gt; &lt;filters/&gt; &lt;!--子项目可以引用的默认插件信息。该插件配置项直到被引用时才会被解析或绑定到生命周期。给定插件的任何本地配置都会覆盖这里的配置--&gt; &lt;pluginManagement&gt; &lt;!--使用的插件列表 。--&gt; &lt;plugins&gt; &lt;!--plugin元素包含描述插件所需要的信息。--&gt; &lt;plugin&gt; &lt;!--插件在仓库里的group ID--&gt; &lt;groupId/&gt; &lt;!--插件在仓库里的artifact ID--&gt; &lt;artifactId/&gt; &lt;!--被使用的插件的版本（或版本范围）--&gt; &lt;version/&gt; &lt;!--是否从该插件下载Maven扩展（例如打包和类型处理器），由于性能原因，只有在真需要下载时，该元素才被设置成enabled。--&gt; &lt;extensions/&gt; &lt;!--在构建生命周期中执行一组目标的配置。每个目标可能有不同的配置。--&gt; &lt;executions&gt; &lt;!--execution元素包含了插件执行需要的信息--&gt; &lt;execution&gt; &lt;!--执行目标的标识符，用于标识构建过程中的目标，或者匹配继承过程中需要合并的执行目标--&gt; &lt;id/&gt; &lt;!--绑定了目标的构建生命周期阶段，如果省略，目标会被绑定到源数据里配置的默认阶段--&gt; &lt;phase/&gt; &lt;!--配置的执行目标--&gt; &lt;goals/&gt; &lt;!--配置是否被传播到子POM--&gt; &lt;inherited/&gt; &lt;!--作为DOM对象的配置--&gt; &lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;!--项目引入插件所需要的额外依赖--&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!--任何配置是否被传播到子项目--&gt; &lt;inherited/&gt; &lt;!--作为DOM对象的配置--&gt; &lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!--使用的插件列表--&gt; &lt;plugins&gt; &lt;!--参见build/pluginManagement/plugins/plugin元素--&gt; &lt;plugin&gt; &lt;groupId/&gt;&lt;artifactId/&gt;&lt;version/&gt;&lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt;&lt;phase/&gt;&lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; reporting 该元素描述使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。 &lt;reporting&gt; &lt;!--true，则，网站不包括默认的报表。这包括“项目信息”菜单中的报表。--&gt; &lt;excludeDefaults/&gt; &lt;!--所有产生的报表存放到哪里。默认值是${project.build.directory}/site。--&gt; &lt;outputDirectory/&gt; &lt;!--使用的报表插件和他们的配置。--&gt; &lt;plugins&gt; &lt;!--plugin元素包含描述报表插件需要的信息--&gt; &lt;plugin&gt; &lt;!--报表插件在仓库里的group ID--&gt; &lt;groupId/&gt; &lt;!--报表插件在仓库里的artifact ID--&gt; &lt;artifactId/&gt; &lt;!--被使用的报表插件的版本（或版本范围）--&gt; &lt;version/&gt; &lt;!--任何配置是否被传播到子项目--&gt; &lt;inherited/&gt; &lt;!--报表插件的配置--&gt; &lt;configuration/&gt; &lt;!--一组报表的多重规范，每个规范可能有不同的配置。一个规范（报表集）对应一个执行目标 。例如，有1，2，3，4，5，6，7，8，9个报表。1，2，5构成A报表集，对应一个执行目标。2，5，8构成B报表集，对应另一个执行目标--&gt; &lt;reportSets&gt; &lt;!--表示报表的一个集合，以及产生该集合的配置--&gt; &lt;reportSet&gt; &lt;!--报表集合的唯一标识符，POM继承时用到--&gt; &lt;id/&gt; &lt;!--产生报表集合时，被使用的报表的配置--&gt; &lt;configuration/&gt; &lt;!--配置是否被继承到子POMs--&gt; &lt;inherited/&gt; &lt;!--这个集合里使用到哪些报表--&gt; &lt;reports/&gt; &lt;/reportSet&gt; &lt;/reportSets&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt; 5.项目信息 name：给用户提供更为友好的项目名 description：项目描述，maven文档中保存 url：主页的URL，maven文档中保存 inceptionYear：项目创建年份，4位数字。当产生版权信息时需要使用这个值 licenses：该元素描述了项目所有License列表。 应该只列出该项目的license列表，不要列出依赖项目的 license列表。如果列出多个license，用户可以选择它们中的一个而不是接受所有license。（如下） &lt;license&gt; &lt;!--license用于法律上的名称--&gt; &lt;name&gt;...&lt;/name&gt; &lt;!--官方的license正文页面的URL--&gt; &lt;url&gt;....&lt;/url&gt; &lt;!--项目分发的主要方式：repo，可以从Maven库下载 manual， 用户必须手动下载和安装依赖--&gt; &lt;distribution&gt;repo&lt;/distribution&gt; &lt;!--关于license的补充信息--&gt; &lt;comments&gt;....&lt;/comments&gt; &lt;/license&gt; organization：1.name 组织名 2.url 组织主页url developers：项目开发人员列表（如下） contributors：项目其他贡献者列表，同developers &lt;developers&gt; &lt;!--某个开发者信息--&gt; &lt;developer&gt; &lt;!--开发者的唯一标识符--&gt; &lt;id&gt;....&lt;/id&gt; &lt;!--开发者的全名--&gt; &lt;name&gt;...&lt;/name&gt; &lt;!--开发者的email--&gt; &lt;email&gt;...&lt;/email&gt; &lt;!--开发者的主页--&gt; &lt;url&gt;...&lt;url/&gt; &lt;!--开发者在项目中的角色--&gt; &lt;roles&gt; &lt;role&gt;Java Dev&lt;/role&gt; &lt;role&gt;Web UI&lt;/role&gt; &lt;/roles&gt; &lt;!--开发者所属组织--&gt; &lt;organization&gt;sun&lt;/organization&gt; &lt;!--开发者所属组织的URL--&gt; &lt;organizationUrl&gt;...&lt;/organizationUrl&gt; &lt;!--开发者属性，如即时消息如何处理等--&gt; &lt;properties&gt; &lt;!-- 和主标签中的properties一样，可以随意定义子标签 --&gt; &lt;/properties&gt; &lt;!--开发者所在时区， -11到12范围内的整数。--&gt; &lt;timezone&gt;-5&lt;/timezone&gt; &lt;/developer&gt; &lt;/developers&gt; 6.环境设置issueManagement 目的问题管理系统(Bugzilla, Jira, Scarab)的名称和URL &lt;issueManagement&gt; &lt;system&gt;Bugzilla&lt;/system&gt; &lt;url&gt;http://127.0.0.1/bugzilla/&lt;/url&gt; &lt;/issueManagement&gt; system：系统类型 url：路径 ciManagement 项目的持续集成信息 &lt;ciManagement&gt; &lt;system&gt;continuum&lt;/system&gt; &lt;url&gt;http://127.0.0.1:8080/continuum&lt;/url&gt; &lt;notifiers&gt; &lt;notifier&gt; &lt;type&gt;mail&lt;/type&gt; &lt;sendOnError&gt;true&lt;/sendOnError&gt; &lt;sendOnFailure&gt;true&lt;/sendOnFailure&gt; &lt;sendOnSuccess&gt;false&lt;/sendOnSuccess&gt; &lt;sendOnWarning&gt;false&lt;/sendOnWarning&gt; &lt;address&gt;continuum@127.0.0.1&lt;/address&gt; &lt;configuration&gt;&lt;/configuration&gt; &lt;/notifier&gt; &lt;/notifiers&gt; &lt;/ciManagement&gt; system：持续集成系统的名字 url：持续集成系统的URL notifiers：构建完成时，需要通知的开发者/用户的配置项。包括被通知者信息和通知条件（错误，失败，成功，警告） type：通知方式 sendOnError：错误时是否通知 sendOnFailure：失败时是否通知 sendOnSuccess：成功时是否通知 sendOnWarning：警告时是否通知 address：通知发送到的地址 configuration：扩展项 mailingLists 项目相关邮件列表信息 &lt;mailingLists&gt; &lt;mailingList&gt; &lt;name&gt;User List&lt;/name&gt; &lt;subscribe&gt;user-subscribe@127.0.0.1&lt;/subscribe&gt; &lt;unsubscribe&gt;user-unsubscribe@127.0.0.1&lt;/unsubscribe&gt; &lt;post&gt;user@127.0.0.1&lt;/post&gt; &lt;archive&gt;http://127.0.0.1/user/&lt;/archive&gt; &lt;otherArchives&gt; &lt;otherArchive&gt;http://base.google.com/base/1/127.0.0.1&lt;/otherArchive&gt; &lt;/otherArchives&gt; &lt;/mailingList&gt; ..... &lt;/mailingLists&gt; subscribe, unsubscribe: 订阅邮件（取消订阅）的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 archive：浏览邮件信息的URL post：接收邮件的地址 scm 允许你配置你的代码库，供Maven web站点和其它插件使用 &lt;scm&gt; &lt;connection&gt;scm:svn:http://127.0.0.1/svn/my-project&lt;/connection&gt; &lt;developerConnection&gt;scm:svn:https://127.0.0.1/svn/my-project&lt;/developerConnection&gt; &lt;tag&gt;HEAD&lt;/tag&gt; &lt;url&gt;http://127.0.0.1/websvn/my-project&lt;/url&gt; &lt;/scm&gt; connection, developerConnection：这两个表示我们如何连接到maven的版本库。connection只提供读，developerConnection将提供写的请求 写法如：scm:[provider]:[provider_specific] 如果连接到CVS仓库，可以配置如下：scm:cvs:pserver:127.0.0.1:/cvs/root:my-project tag：项目标签，默认HEAD url：共有仓库路径 prerequisites 项目构建的前提 &lt;prerequisites&gt; &lt;maven&gt;2.0.6&lt;/maven&gt; &lt;/prerequisites&gt; repositories,pluginRepositories 依赖和扩展的远程仓库列表，同上篇文章，setting.xml配置中介绍的。 &lt;repositories&gt; &lt;repository&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;checksumPolicy&gt;warn&lt;/checksumPolicy&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;never&lt;/updatePolicy&gt; &lt;checksumPolicy&gt;fail&lt;/checksumPolicy&gt; &lt;/snapshots&gt; &lt;id&gt;codehausSnapshots&lt;/id&gt; &lt;name&gt;Codehaus Snapshots&lt;/name&gt; &lt;url&gt;http://snapshots.maven.codehaus.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; ... &lt;/pluginRepositories&gt; releases, snapshots:这是各种构件的策略，release或者snapshot。这两个集合，POM就可以根据独立仓库任意类型的依赖改变策略。如：一个人可能只激活下载snapshot用来开发。 enable：true或者false，决定仓库是否对于各自的类型激活(release 或者 snapshot)。 updatePolicy: 这个元素决定更新频率。maven将比较本地pom的时间戳（存储在仓库的maven数据文件中）和远程的. 有以下选择: always, daily (默认), interval:X (x是代表分钟的整型) ， never. checksumPolicy：当Maven向仓库部署文件的时候，它也部署了相应的校验和文件。可选的为：ignore，fail，warn，或者不正确的校验和。 layout：在上面描述仓库的时候，提到他们有统一的布局。Maven 2有它仓库默认布局。然而，Maven 1.x有不同布局。使用这个元素来表明它是default还是legacy。 distributionManagement 它管理的分布在整个构建过程生成的工件和支持文件 &lt;distributionManagement&gt; ... &lt;downloadUrl&gt;http://mojo.codehaus.org/my-project&lt;/downloadUrl&gt; &lt;status&gt;deployed&lt;/status&gt; &lt;/distributionManagement&gt; downloadUrl: 其他pom可以通过此url的仓库抓取组件 status：给出该构件在远程仓库的状态 none: 默认 converted: 将被早期Maven 2 POM转换过来 partner: 这个项目会从合作者仓库同步过来 deployed: 从Maven 2或3实例部署 verified: 被核实时正确的和最终的 Repository 指定Maven pom从远程下载控件到当前项目的位置和方式，如果snapshotRepository没有被定义则使用repository相关的配置 &lt;distributionManagement&gt; &lt;repository&gt; &lt;uniqueVersion&gt;false&lt;/uniqueVersion&gt; &lt;id&gt;corp1&lt;/id&gt; &lt;name&gt;Corporate Repository&lt;/name&gt; &lt;url&gt;scp://repo/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;uniqueVersion&gt;true&lt;/uniqueVersion&gt; &lt;id&gt;propSnap&lt;/id&gt; &lt;name&gt;Propellors Snapshots&lt;/name&gt; &lt;url&gt;sftp://propellers.net/maven&lt;/url&gt; &lt;layout&gt;legacy&lt;/layout&gt; &lt;/snapshotRepository&gt; ... &lt;/distributionManagement&gt; id, name：仓库的唯一标识 uniqueVersion：true或false，指明控件部署的时候是否获取独立的版本号。 url：repository元素的核心。指定位置和部署协议发布控件到仓库。 layout：布局，default或legacy Site Distribution 多分布存储库,distributionManagement负责定义如何部署项目的网站和文档。 &lt;distributionManagement&gt; ... &lt;site&gt; &lt;id&gt;mojo.website&lt;/id&gt; &lt;name&gt;Mojo Website&lt;/name&gt; &lt;url&gt;scp://beaver.codehaus.org/home/projects/mojo/public_html/&lt;/url&gt; &lt;/site&gt; ... &lt;/distributionManagement&gt; id, name, url: 这些元素与distributionManagement repository中的相同 Relocation 重新部署-项目不是静态的，是活的。他们需要被搬到更合适的地方。如：当你的下个成功的开源项目移到Apache下，重命名为org.apache:my-project:1.0 对你项目更有好处。 &lt;distributionManagement&gt; ... &lt;relocation&gt; &lt;groupId&gt;org.apache&lt;/groupId&gt; &lt;artifactId&gt;my-project&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;message&gt;We have moved the Project under Apache&lt;/message&gt; &lt;/relocation&gt; ... &lt;/distributionManagement&gt; 原文链接: http://blog.csdn.net/oDeviloo/article/details/52050277参考官方文档： http://maven.apache.org/pom.html","categories":[],"tags":[{"name":"Maven","slug":"Maven","permalink":"http://www.zhz.gift/tags/Maven/"}]},{"title":"setting.xml详解","slug":"setting.xml详解","date":"2018-01-10T16:07:42.000Z","updated":"2018-01-11T15:27:17.915Z","comments":true,"path":"2018/01/11/setting.xml详解/","link":"","permalink":"http://www.zhz.gift/2018/01/11/setting.xml详解/","excerpt":"Maven setting.xml详细配置说明","text":"Maven setting.xml详细配置说明 1.文件概览&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; &lt;localRepository/&gt; &lt;interactiveMode/&gt; &lt;offline/&gt; &lt;pluginGroups/&gt; &lt;servers/&gt; &lt;mirrors/&gt; &lt;proxies/&gt; &lt;profiles/&gt; &lt;activeProfiles/&gt; &lt;/settings&gt; 通过配置文件中的注释，我们可以看到，有两种配置此文件的方法 1.用户级别 ${user.home}/.m2/settings.xml 可以通过指令 -s /path/to/user/settings.xml 2.全局级别 ${maven.home}/conf/settings.xml. 可以通过指令 -gs /path/to/global/settings.xml 2.localRepositorylocalRepository用于构建系统的本地仓库的路径。默认的值是${user.home}/.m2/repository。 Default: ${user.home}/.m2/repository &lt;localRepository&gt;/path/to/local/repo&lt;/localRepository&gt; 3.interactiveModeinteractiveMode 用于决定maven是否在需要输出的时候提示你，默认true。如果是false，它将使用合理的默认值，或者基于一些设置。 4.offline决定maven是否在构建的时候进行网络传输。默认false，表示联网状态，true为取消联网。在某些情况下设置为true是很有用的，比如jar无法从网上下载等 5.pluginGroupspluginGroups 插件组 &lt;pluginGroups&gt; &lt;pluginGroup&gt;org.mortbay.jetty&lt;/pluginGroup&gt; &lt;/pluginGroups&gt; 这样Maven可以使用简单的命令执行org.morbay.jetty:jetty-maven-plugin:run mvn jetty run 我们同样可以在pom文件中看到相似的配置，只是在这配置了就起到全局的作用，而不用每个项目中pom配置jetty 6.proxies此项用于设置http代理有时候由于安全问题，需要配置http代理，通过代理服务才能正常访问外部仓库下载资源可以ping repo1.maven.org来访问中央仓库telnet 218.14.227.197 3128 来查看代理地址以及端口是否畅通 &lt;proxies&gt; &lt;proxy&gt; &lt;id&gt;optional&lt;/id&gt; &lt;active&gt;true&lt;/active&gt; &lt;protocol&gt;http&lt;/protocol&gt;&lt;!--代理协议--&gt; &lt;username&gt;proxyuser&lt;/username&gt; &lt;password&gt;proxypass&lt;/password&gt; &lt;host&gt;proxy.host.net&lt;/host&gt; &lt;port&gt;80&lt;/port&gt; &lt;nonProxyHosts&gt;local.net|some.host.com&lt;/nonProxyHosts&gt; &lt;/proxy&gt; &lt;/proxies&gt; id：proxy的唯一标识，用来区别proxy元素。 active：表示是否激活代理，如果配置多个，默认是第一个生效 username，password：提供连接代理服务器时的认证。 host，port：主机地址，端口号 nonProxyHosts：用来表示哪些主机名不需要代理，可以用|来分割多个，此外也支持通配符，如：*.goole.com表示所有以goole.com结尾的都不需要通过代理 7.servers这是一个认证配置的列表,根据系统中使用的server-id控制。认证配置在maven连接到远程服务时使用。 &lt;servers&gt; &lt;!--使用登录方式--&gt; &lt;server&gt; &lt;id&gt;deploymentRepo&lt;/id&gt; &lt;username&gt;repouser&lt;/username&gt; &lt;password&gt;repopwd&lt;/password&gt; &lt;/server&gt; &lt;!-- 使用秘钥认证 --&gt; &lt;server&gt; &lt;id&gt;siteServer&lt;/id&gt; &lt;privateKey&gt;/path/to/private/key&lt;/privateKey&gt; &lt;passphrase&gt;可空&lt;/passphrase&gt; &lt;/server&gt; &lt;/servers&gt; 8.mirrors指定镜像仓库位置用于从远程仓库下载资源 &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;mirrorId&lt;/id&gt; &lt;mirrorOf&gt;repositoryId&lt;/mirrorOf&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://my.repository.com/repo/path&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; id：用于继承和直接查找，唯一 mirrorOf：镜像所包含的仓库的Id name：唯一标识，用于区分镜像站 url：镜像路径 9.profiles settings.xml中时意味着该profile是全局的，所以只能配置范围宽泛一点配置信息，比如远程仓库等。而一些比较细致一点的需要定义在项目的pom.xml中。 profile可以让我们定义一系列的配置信息，然后指定其激活条件。根据每个profile对应不同的激活条件和配置信息，从而达到不同环境使用不同配置。 例子：通过profile定义jdk1.5以上使用一套配置，jdk1.5以下使用另外一套配置；或者通过操作系统来使用不同的配置信息。 settings.xml中的信息有repositories、pluginRepositories和properties。定义在properties的值可以在pom.xml中使用。 Activation &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;test&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;jdk&gt;1.5&lt;/jdk&gt; &lt;os&gt; &lt;name&gt;Windows XP&lt;/name&gt; &lt;family&gt;Windows&lt;/family&gt; &lt;arch&gt;x86&lt;/arch&gt; &lt;version&gt;5.1.2600&lt;/version&gt; &lt;/os&gt; &lt;property&gt; &lt;name&gt;mavenVersion&lt;/name&gt; &lt;value&gt;2.0.3&lt;/value&gt; &lt;/property&gt; &lt;file&gt; &lt;exists&gt;${basedir}/file2.properties&lt;/exists&gt; &lt;missing&gt;${basedir}/file1.properties&lt;/missing&gt; &lt;/file&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;/profiles&gt; jdk：检测到对应jdk版本就激活 os：针对不同操作系统 property：当maven检测到property（pom中如${name}这样的）profile将被激活 file：如果存在文件，激活，不存在文件激活 通过以下命令查看哪些profile将生效 mvn help:active-profiles properites Maven的属性是值占位符，就像Ant中的一样。如果X是一个属性的话，在POM中可以使用${X}来进行任意地方的访问。他们来自于五种不同的风格，所有都可以从settings.xml文件中访问到。 1. env.x：“env.”前缀会返回当前的环境变量。如${env.PATH}就是使用了$path环境变量（windosws中的%PATH%）。 2. project.x：一个点“.”分割的路径，在POM中就是相关的元素的值。例如：&lt;project&gt;&lt;version&gt;1.0&lt;/version&gt;&lt;/project&gt;就可以通过${project.version}来访问。 3. settings.x：一个点“.”分割的路径，在settings.xml中就是相对应的元素的值，例如：&lt;settings&gt;&lt;offline&gt;false&lt;/offline&gt;&lt;/settings&gt;就可以通过${settings.offline}来访问。 4. Java系统属性：通过java.lang.System.getProperties()来访问的属性都可以像POM中的属性一样访问，例如：${java.home} x：被或者外部文件定义的属性，值可以这样访问${someVar} … ${user.home}/our-project … 上面这个profile如果被激活，那么在pom中${user.install}就可以被访问了。 Repositories Repositories是远程项目集合maven用来移植到本地仓库用于构建系统。如果来自本地仓库，Maven调用它的插件和依赖关系。不同的远程仓库可能包含不同的项目，当profile被激活，他们就会需找匹配的release或者snapshot构件。 &lt;profiles&gt; &lt;profile&gt; ... &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;codehausSnapshots&lt;/id&gt; &lt;name&gt;Codehaus Snapshots&lt;/name&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;checksumPolicy&gt;warn&lt;/checksumPolicy&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;never&lt;/updatePolicy&gt; &lt;checksumPolicy&gt;fail&lt;/checksumPolicy&gt; &lt;/snapshots&gt; &lt;url&gt;http://snapshots.maven.codehaus.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; ... &lt;/pluginRepositories&gt; ... &lt;/profile&gt; &lt;/profiles&gt; releases，snapshots：这是各种构件的策略，release或者snapshot。这两个集合，POM就可以根据独立仓库任意类型的依赖改变策略。如：一个人可能只激活下载snapshot用来开发。 enable：true或者false，决定仓库是否对于各自的类型激活(release 或者 snapshot)。 updatePolicy: 这个元素决定更新频率。maven将比较本地pom的时间戳（存储在仓库的maven数据文件中）和远程的. 有以下选择: always, daily (默认), interval:X (x是代表分钟的整型) ， never. checksumPolicy：当Maven向仓库部署文件的时候，它也部署了相应的校验和文件。可选的为：ignore，fail，warn，或者不正确的校验和。 layout：在上面描述仓库的时候，提到他们有统一的布局。Maven 2有它仓库默认布局。然而，Maven 1.x有不同布局。使用这个元素来表明它是default还是legacy。 10.activeProfiles&lt;activeProfiles&gt; &lt;activeProfile&gt;alwaysActiveProfile&lt;/activeProfile&gt; &lt;activeProfile&gt;anotherAlwaysActiveProfile&lt;/activeProfile&gt; &lt;/activeProfiles&gt; 每个activeProfile元素对应一个profile id的值，任何profile id被定义到activeProfile的profile将被激活。 原文:http://blog.csdn.net/odeviloo/article/details/51999878 参考：http://maven.apache.org/settings.html","categories":[],"tags":[{"name":"Maven","slug":"Maven","permalink":"http://www.zhz.gift/tags/Maven/"}]},{"title":"jooq基本操作介绍","slug":"jooq基本操作介绍","date":"2018-01-08T16:07:42.000Z","updated":"2018-01-09T13:45:00.293Z","comments":true,"path":"2018/01/09/jooq基本操作介绍/","link":"","permalink":"http://www.zhz.gift/2018/01/09/jooq基本操作介绍/","excerpt":"jooq基本操作介绍","text":"jooq基本操作介绍 1.1jooq select查询select方法接受一个SelectField查询字段集合,org.jooq.Field可以通过生成的任意jooq.tables.*(eg:AudienceItem extends TableImpl)的Fields方法获取该Table的所有Field字段或者通过该Table的公共成员变量获取部分字段(eg: AUDIENCE_ITEM.ID). select方法返回一个SelectSelectStep 查询步骤对象,一般通过该对象调用from方法完成接下来的表拼接.eg:.from(AUDIENCE_OBJECT). from方法接受一个TableLike&lt;?&gt;对象，该对象可以是表也可以是视图,最后返回一个SelectJoinStep对象. SelectJoinStep对象继承自SelectWhereStep对象,通过该对象我们既可以直接后接where方法条件，也可以通过SelectJoinStep对象的join,innerjoin等方法继续关联表进行查询. SelectJoinStep对象调用join等方法后(eg:.leftJoin(AUDIENCE_ITEM))返回SelectJoinPartitionByStep对象,该对象继承自SelectOnStep对象. SelectOnStep对象的主要方法是on,通过on方法来完成join之后的条件拼装(eg:.on(AUDIENCE_OBJECT.ITEM_ID.eq(AUDIENCE_ITEM.ID)),调用完成之后返回SelectOnConditionStep对象. 通过SelectOnConditionStep对象,可以继续接join,where或者直接调用fetch方法结束sql拼接. fetch方法返回一个泛型结果集Result,一般通过该结果集的into方法直接转化得到实体列表,具体实例如下: DSLContext dsl = DSL.using(configuration); dsl.select(Fields.start().add(AUDIENCE_ITEM).end()) .from(AUDIENCE_OBJECT).leftJoin(AUDIENCE_ITEM) .on(AUDIENCE_OBJECT.ITEM_ID.eq(AUDIENCE_ITEM.ID).and(AUDIENCE_OBJECT.BUSINESS_TYPE.eq(businessType))) .where(AUDIENCE_OBJECT.BUSINESS_ID.eq(id).and(AUDIENCE_ITEM.ID.isNotNull())).fetch() .into(AudienceItem.class) 另:on方法和where方法都是接受一个Condition可变数组为入参,Condition条件对象可由TableImpl对象的TableField字段调用and,eq等条件方法得到. 1.2 使用DSLContext进行新增,修改,删除//新增 DSL.using(conf).insertInto(AUDIENCE_OBJECT,AUDIENCE_OBJECT.ID).values(&quot;1&quot;).execute(); //更新 DSL.using(conf).update(AUDIENCE_OBJECT).set(AUDIENCE_OBJECT.BUSINESS_ID, AUDIENCE_OBJECT.BUSINESS_ID.add(1)).execute(); //删除 DSL.using(conf).delete(AUDIENCE_OBJECT).where(AUDIENCE_OBJECT.BUSINESS_ID.eq(&quot;1&quot;)).execute(); 2.1 使用UpdatableRecord完成新增,修改,删除jooq的新增，修改，删除方法都可以通过UpdatableRecord对象完成,示例如下: DSLContext dsl = DSL.using(conf); UpdatableRecord r = (UpdatableRecord) dsl.newRecord(AUDIENCE_OBJECT, objects.get(0)); //只有不为空的才进行更新 int size = r.size(); for (int i = 0; i &lt; size; ++i) { if (r.getValue(i) != null || r.field(i).getDataType().nullable()) continue; r.changed(i, false);//标记该字段不更新 } r.update(); r.insert(); r.delete(); 2.2 批量方法新增,修改,删除批量方法都是接受一个UpdatableRecord对象集合来进行批量新增或批量修改. //批量添加 DSL.using(conf).batchInsert(rs).execute(); //批量修改 DSL.using(conf).batchUpdate(rs).execute(); //批量删除 DSL.using(conf).batchDelete(rs).execute();","categories":[],"tags":[{"name":"jooq","slug":"jooq","permalink":"http://www.zhz.gift/tags/jooq/"}]},{"title":"WEB环境下进行单元测试","slug":"WEB环境下进行单元测试","date":"2017-12-16T16:07:42.000Z","updated":"2017-12-17T12:11:06.369Z","comments":true,"path":"2017/12/17/WEB环境下进行单元测试/","link":"","permalink":"http://www.zhz.gift/2017/12/17/WEB环境下进行单元测试/","excerpt":"WEB环境下进行单元测试","text":"WEB环境下进行单元测试 SpringApplication 将尝试为你创建正确类型的 ApplicationContext ，默认情况下，根据你开发的是否为web应用决定使用 AnnotationConfigApplicationContext 或 AnnotationConfigEmbeddedWebApplicationContext 。用于确定是否为web环境的算法相当简单（判断是否存在某些类），你可以使用 setWebEnvironment(boolean webEnvironment) 覆盖默认行为。通过调用 setApplicationContextClass(…) ，你可以完全控制 ApplicationContext 的类型。注 在Junit测试中使用 SpringApplication ，调用 setWebEnvironment(false) 是很有意义的。","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.zhz.gift/tags/SpringBoot/"}]},{"title":"Spring WebMVC框架","slug":"Spring_Web_MVC框架","date":"2017-12-16T16:07:42.000Z","updated":"2017-12-17T12:11:43.347Z","comments":true,"path":"2017/12/17/Spring_Web_MVC框架/","link":"","permalink":"http://www.zhz.gift/2017/12/17/Spring_Web_MVC框架/","excerpt":"Spring WebMVC框架","text":"Spring WebMVC框架 Spring Web MVC框架（通常简称为”SpringMVC”）是一个富“模型，视图，控制器”web框架， 允许用户创建特定的 @Controller 或 @RestController beans来处理传入的HTTP请求，通过@RequestMapping注解可以将控制器中的方法映射到相应的HTTP请求。示例： @RestController @RequestMapping(value=&quot;/users&quot;) public class MyRestController { @RequestMapping(value=&quot;/{user}&quot;, method=RequestMethod.GET) public User getUser(@PathVariable Long user) { // ... } @RequestMapping(value=&quot;/{user}/customers&quot;, method=RequestMet hod.GET) List&lt;Customer&gt; getUserCustomers(@PathVariable Long user) { // ... } @RequestMapping(value=&quot;/{user}&quot;, method=RequestMethod.DELETE ) public User deleteUser(@PathVariable Long user) { // ... } } Spring MVC是Spring框架的核心部分，详细信息可以参考referencedocumentation，spring.io/guides也有一些可用的指导覆盖Spring MVC。 Spring MVC自动配置Spring Boot为Spring MVC提供的auto-configuration适用于大多数应用，并在Spring默认功能上添加了以下特性： 引入 ContentNegotiatingViewResolver 和 BeanNameViewResolverbeans。 对静态资源的支持，包括对WebJars的支持。 自动注册 Converter ， GenericConverter ， Formatter beans。 对 HttpMessageConverters 的支持。 自动注册 MessageCodeResolver 。 对静态 index.html 的支持。 对自定义 Favicon 的支持。 自动使用 ConfigurableWebBindingInitializer bean。 如果保留Spring Boot MVC特性，你只需添加其他的MVC配置（拦截器，格式化处理器，视图控制器等）。你可以添加自己的 WebMvcConfigurerAdapter 类型的@Configuration类，而不需要注解@EnableWebMvc。如果希望使用自定义的 RequestMappingHandlerMapping ，RequestMappingHandlerAdapter ，或 ExceptionHandlerExceptionResolver，你可以声明一个WebMvcRegistrationsAdapter 实例提供这些组件。 如果想全面控制Spring MVC，你可以添加自己的 @Configuration ，并使用 @EnableWebMvc 注解。 ##HttpMessageConverters## Spring MVC使用 HttpMessageConverter 接口转换HTTP请求和响应，合适的默认配置可以开箱即用，例如对象自动转换为JSON（使用Jackson库）或XML（如果Jackson XML扩展可用，否则使用JAXB），字符串默认使用 UTF-8 编码。可以使用Spring Boot的 HttpMessageConverters 类添加或自定义转换类： import org.springframework.boot.autoconfigure.web.HttpMessageCon verters; import org.springframework.context.annotation.*; import org.springframework.http.converter.*; @Configuration public class MyConfiguration { @Bean public HttpMessageConverters customConverters() { HttpMessageConverter&lt;?&gt; additional = ... HttpMessageConverter&lt;?&gt; another = ... return new HttpMessageConverters(additional, another); } } 上下文中出现的所有 HttpMessageConverter bean都将添加到converters列表，你可以通过这种方式覆盖默认的转换器列表（converters）。 ##自定义JSON序列化器和反序列化器## 如果使用Jackson序列化，反序列化JSON数据，你可能想编写自己的 JsonSerializer 和 JsonDeserializer 类。自定义序列化器（serializers）通常通过Module注册到Jackson，但Spring Boot提供了 @JsonComponent 注解这一替代方式，它能轻松的将序列化器注册为Spring Beans。 ##MessageCodesResolver## Spring MVC有一个实现策略，用于从绑定的errors产生用来渲染错误信息的错误码： MessageCodesResolver 。SpringBoot会自动为你创建该实现，只要设置spring.mvc.message-codes-resolver.format 属性为 PREFIX_ERROR_CODE 或 POSTFIX_ERROR_CODE （具体查看 DefaultMessageCodesResolver.Format 枚举值）。 ##静态内容## 默认情况下，Spring Boot从classpath下的 /static （ /public ， /resources 或 /META-INF/resources ）文件夹，或从ServletContext 根目录提供静态内容。 这是通过Spring MVC的 ResourceHttpRequestHandler 实现的，你可以自定义WebMvcConfigurerAdapter 并覆写addResourceHandlers 方法来改变该行为（加载静态文件）。 在单机web应用中，容器会启动默认的servlet，并用它加载 ServletContext 根目录下的内容以响应那些Spring不处理的请求。大多数情况下这都不会发生（除非你修改默认的MVC配置），因为Spring总能够通过 DispatcherServlet 处理这些请求。 你可以设置 spring.resources.staticLocations 属性自定义静态资源的位置（配置一系列目录位置代替默认的值），如果你这样做，默认的欢迎页面将从自定义位置加载，所以只要这些路径中的任何地方有一个 index.html ，它都会成为应用的主页。 此外，除了上述标准的静态资源位置，有个例外情况是Webjars内容。任何在 /webjars/** 路径下的资源都将从jar文件中提供，只要它们以Webjars的格式打包。 注 如果你的应用将被打包成jar，那就不要使用 src/main/webapp文件夹。尽管该文件夹是通常的标准格式，但它仅在打包成war的情况下起作用，在打包成jar时，多数构建工具都会默认忽略它。 Spring Boot也支持SpringMVC提供的高级资源处理特性，可用于清除缓存的静态资源或对WebJar使用版本无感知的URLs。 如果想使用针对WebJars版本无感知的URLs（version agnostic），只需要添加 webjars-locator 依赖，然后声明你的Webjar。以jQuery为例， “/webjars/jquery/dist/jquery.min.js” 实际为 “/webjars/jquery/x.y.z/dist/jquery.min.js” ， x.y.z为Webjar的版本。 注 如果使用JBoss，你需要声明 webjars-locator-jboss-vfs 依赖而不是 webjars-locator ，否则所有的Webjars将解析为 404 。 以下的配置为所有的静态资源提供一种缓存清除（cache busting）方案，实际上是将内容hash添加到URLs中，比如 ： spring.resources.chain.strategy.content.enabled=true spring.resources.chain.strategy.content.paths=/** 注 实现该功能的是 ResourceUrlEncodingFilter ，它在模板运行期会重写资源链接，Thymeleaf，Velocity和FreeMarker会自动配置该filter，JSP需要手动配置。其他模板引擎还没自动支持，不过你可以使用ResourceUrlProvider自定义模块宏或帮助类。当使用比如JavaScript模块加载器动态加载资源时，重命名文件是不行的，这也是提供其他策略并能结合使用的原因。下面是一个”fixed”策略，在URL中添加一个静态version字符串而不需要改变文件名： spring.resources.chain.strategy.content.enabled=true spring.resources.chain.strategy.content.paths=/** spring.resources.chain.strategy.fixed.enabled=true spring.resources.chain.strategy.fixed.paths=/js/lib/ spring.resources.chain.strategy.fixed.version=v12 使用以上策略，JavaScript模块加载器加载 “/js/lib/“下的文件时会使用一个固定的版本策略 “/v12/js/lib/mymodule.js” ，其他资源仍旧使用内容hash的方式 。 查看ResourceProperties获取更多支持的选项。注 该特性在一个专门的博文和Spring框架参考文档中有透彻描述。 ##ConfigurableWebBindingInitializer## Spring MVC使用 WebBindingInitializer 为每个特殊的请求初始化相应的WebDataBinder ，如果你创建自己的 ConfigurableWebBindingInitializer @Bean ，Spring Boot会自动配置Spring MVC使用它。 ##模板引擎## 正如REST web服务，你也可以使用Spring MVC提供动态HTML内容。Spring MVC支持各种各样的模板技术，包括Velocity, FreeMarker和JSPs，很多其他的模板引擎也提供它们自己的Spring MVC集成。 Spring Boot为以下的模板引擎提供自动配置支持： FreeMarker Groovy Thymeleaf Velocity（1.4已不再支持） Mustache 注：由于在内嵌servlet容器中使用JSPs存在一些已知的限制，所以建议尽量不使用它们。 使用以上引擎中的任何一种，并采用默认配置，则模块会从src/main/resources/templates 自动加载。 注：IntelliJ IDEA根据你运行应用的方式会对classpath进行不同的排序。在IDE里通过main方法运行应用，跟从Maven，或Gradle，或打包好的jar中运行相比会导致不同的顺序，这可能导致SpringBoot不能从classpath下成功地找到模板。如果遇到这个问题，你可以在IDE里重新对classpath进行排序，将模块的类和资源放到第一位。或者，你可以配置模块的前缀为 classpath*:/templates/ ，这样会查找classpath下的所有模板目录。 ##错误处理## Spring Boot默认提供一个 /error 映射用来以合适的方式处理所有的错误，并将它注册为servlet容器中全局的 错误页面。对于机器客户端（相对于浏览器而言，浏览器偏重于人的行为），它会产生一个具有详细错误，HTTP状态，异常信息的JSON响应。对于浏览器客户端，它会产生一个白色标签样式（whitelabel）的错误视图，该视图将以HTML格式显示同样的数据（可以添加一个解析为’error’的View来自定义它）。为了完全替换默认的行为，你可以实现 ErrorController ，并注册一个该类型的bean定义，或简单地添加一个 ErrorAttributes 类型的bean以使用现存的机制，只是替换显示的内容。 注 BasicErrorController 可以作为自定义 ErrorController 的基类，如果你想添加对新context type的处理（默认处理 text/html ），这会很有帮助。你只需要继承 BasicErrorController，添加一个public方法，并注解带有 produces 属性的 @RequestMapping，然后创建该新类型的bean。你也可以定义一个@ControllerAdvice去自定义某个特殊controller或exception类型的JSON文档： @ControllerAdvice(basePackageClasses = FooController.class) public class FooControllerAdvice extends ResponseEntityException Handler { @ExceptionHandler(YourException.class) @ResponseBody ResponseEntity&lt;?&gt; handleControllerException(HttpServletReque st request, Throwable ex) { HttpStatus status = getStatus(request); return new ResponseEntity&lt;&gt;(new CustomErrorType(status.v alue(), ex.getMessage()), status); } private HttpStatus getStatus(HttpServletRequest request) { Integer statusCode = (Integer) request.getAttribute(&quot;jav ax.servlet.error.status_code&quot;); if (statusCode == null) { return HttpStatus.INTERNAL_SERVER_ERROR; } return HttpStatus.valueOf(statusCode); } } 在以上示例中，如果跟 FooController相同package的某个controller抛出 YourException ，一个 CustomerErrorType 类型的POJO的json展示将代替 ErrorAttributes 展示。 自定义错误页面 如果想为某个给定的状态码展示一个自定义的HTML错误页面，你需要将文件添加到 /error 文件夹下。错误页面既可以是静态HTML（比如，任何静态资源文件夹下添加的），也可以是使用模板构建的，文件名必须是明确的状态码或一系列标签。 例如，映射 404 到一个静态HTML文件，你的目录结构可能如下： src/ +- main/ +- java/ | + &lt;source code&gt; +- resources/ +- public/ +- error/ | +- 404.html +- &lt;other public assets&gt; 使用FreeMarker模板映射所有 5xx 错误，你需要如下的目录结构： src/ +- main/ +- java/ | + &lt;source code&gt; +- resources/ +- templates/ +- error/ | +- 5xx.ftl +- &lt;other templates&gt; 对于更复杂的映射，你可以添加实现 ErrorViewResolver接口的beans： public class MyErrorViewResolver implements ErrorViewResolver { @Override public ModelAndViewresolveErrorView(HttpServletRequest requ est,HttpStatus status,Map&lt;String, Object&gt; model) { // Use the request or status to optionally return a Mode lAndView return ... } } 你也可以使用Spring MVC特性，比如@ExceptionHandler方法和@ControllerAdvice，ErrorController 将处理所有未处理的异常。 映射Spring MVC以外的错误页面 对于不使用Spring MVC的应用，你可以通过 ErrorPageRegistrar 接口直接注册 ErrorPages。该抽象直接工作于底层内嵌servlet容器，即使你没有SpringMVC的DispatcherServlet ，它们仍旧可以工作。 @Bean public ErrorPageRegistrar errorPageRegistrar(){ return new MyErrorPageRegistrar(); } // ... private static class MyErrorPageRegistrar implements ErrorPageRegistrar { @Override public void registerErrorPages(ErrorPageRegistry registry) { registry.addErrorPages(new ErrorPage(HttpStatus.BAD_REQU EST, &quot;/400&quot;)); } } 注.如果你注册一个 ErrorPage ，该页面需要被一个 Filter 处理（在一些非Spring web框架中很常见，比如Jersey，Wicket），那么该 Filter 需要明确注册为一个 ERROR 分发器（dispatcher），例如： @Bean public FilterRegistrationBean myFilter() { FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(new MyFilter()); ... registration.setDispatcherTypes(EnumSet.allOf(DispatcherType .class)); return registration; } （默认的 FilterRegistrationBean 不包含 ERROR dispatcher类型）。 WebSphere应用服务器的错误处理当部署到一个servlet容器时，Spring Boot通过它的错误页面过滤器将带有错误状态的请求转发到恰当的错误页面。 request只有在response还没提交时才能转发（forwarded）到正确的错误页面，而WebSphere应用服务器8.0及后续版本默认情况会在servlet方法成功执行后提交response，你需要设置 com.ibm.ws.webcontainer.invokeFlushAfterService 属性为 false 来关闭该行为。 ##Spring HATEOAS## 如果正在开发基于超媒体的RESTful API，你可能需要Spring HATEOAS，而SpringBoot会为其提供自动配置，这在大多数应用中都运作良好。 自动配置取代了 @EnableHypermediaSupport ，只需注册一定数量的beans就能轻松构建基于超媒体的应用，这些beans包括 LinkDiscoverers （客户端支持）， ObjectMapper （用于将响应编排为想要的形式）。 ObjectMapper 可以根据 spring.jackson.* 属性或 Jackson2ObjectMapperBuilder bean进行自定义。 通过注解 @EnableHypermediaSupport ，你可以控制Spring HATEOAS的配置，但这会禁用上述 ObjectMapper 的自定义功能。 ##CORS支持## 跨域资源共享（CORS）是一个大多数浏览器都实现了的W3C标准，它允许你以灵活的方式指定跨域请求如何被授权，而不是采用那些不安全，性能低的方式，比如IFRAME或JSONP。 从4.2版本开始，Spring MVC对CORS提供开箱即用的支持。不用添加任何特殊配置，只需要在Spring Boot应用的controller方法上注解 @CrossOrigin ，并添加CORS配置。通过注册一个自定义 addCorsMappings(CorsRegistry) 方法的WebMvcConfigurer bean可以指定全局CORS配置： @Configuration public class MyConfiguration { @Bean public WebMvcConfigurer corsConfigurer() { return new WebMvcConfigurerAdapter() { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(&quot;/api/**&quot;); } }; } }","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.zhz.gift/tags/SpringBoot/"},{"name":"MVC","slug":"MVC","permalink":"http://www.zhz.gift/tags/MVC/"}]},{"title":"Application属性文件","slug":"Application属性文件","date":"2017-12-16T16:07:42.000Z","updated":"2017-12-17T12:10:39.804Z","comments":true,"path":"2017/12/17/Application属性文件/","link":"","permalink":"http://www.zhz.gift/2017/12/17/Application属性文件/","excerpt":"Application属性文件","text":"Application属性文件 SpringApplication 将从以下位置加载 application.properties 文件，并把它们添加到Spring Environment 中： 当前目录下的 /config 子目录。 当前目录。 classpath下的 /config 包。 classpath根路径（root）。 该列表是按优先级排序的（列表中位置高的路径下定义的属性将覆盖位置低的）。注 你可以使用YAML（’.yml’）文件替代’.properties’。 如果不喜欢将 application.properties 作为配置文件名，你可以通过指定 spring.config.name 环境属性来切换其他的名称，也可以使用 spring.config.location 环境属性引用一个明确的路径（目录位置或文件路径列表以逗号分割）。 $ java -jar myproject.jar --spring.config.name=myproject 或 $ java -jar myproject.jar --spring.config.location=classpath:/de fault.properties,classpath:/override.properties 注 在初期需要根据 spring.config.name 和 spring.config.location 决定加载哪个文件，所以它们必须定义为environment属性（通常为OS env，系统属性或命令行参数）。 如果 spring.config.location 包含目录（相对于文件），那它们应该以 / 结尾（在被加载前， spring.config.name 关联的名称将被追加到后面，包括profile-specific的文件名）。 spring.config.location 下定义的文件使用方法跟往常一样，没有profile-specific变量支持的属性，将被profile-specific的属性覆盖。 不管 spring.config.location 配置什么值，默认总会按照 classpath:,classpath:/config,file:,file:config/ 的顺序进行搜索，优先级由低到高，也就是 file:config/ 获胜。如果你指定自己的位置，它们会优先于所有的默认位置（locations），并使用相同的由低到高的优先级顺序。那样，你就可以在 application.properties 为应用设置默认值，然后在运行的时候使用不同的文件覆盖它，同时保留默认配置。 注 如果使用环境变量而不是系统属性，需要注意多数操作系统的key名称不允许以句号分割（period-separated），但你可以使用下划线（underscores）代替（比如，使用 SPRING_CONFIG_NAME 代替 spring.config.name ）。注 如果应用运行在容器中，那么JNDI属性（java:comp/env）或servlet上下文初始化参数可以用来代替环境变量或系统属性，当然也可以使用环境变量或系统属性。","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.zhz.gift/tags/SpringBoot/"}]},{"title":"使用CommandLineRunner或ApplicationRunner","slug":"使用CommandLineRunner或ApplicationRunner","date":"2017-12-16T16:07:42.000Z","updated":"2017-12-17T12:11:22.286Z","comments":true,"path":"2017/12/17/使用CommandLineRunner或ApplicationRunner/","link":"","permalink":"http://www.zhz.gift/2017/12/17/使用CommandLineRunner或ApplicationRunner/","excerpt":"使用CommandLineRunner或ApplicationRunner","text":"使用CommandLineRunner或ApplicationRunner 如果需要在 SpringApplication 启动后执行一些特殊的代码，你可以实现 ApplicationRunner 或 CommandLineRunner 接口，这两个接口工作方式相同，都只提供单一的 run 方法，该方法仅在 SpringApplication.run(…) 完成之前调用。 CommandLineRunner 接口能够访问string数组类型的应用参数，而 ApplicationRunner 使用的是上面描述过的 ApplicationArguments 接口： import org.springframework.boot.* import org.springframework.stereotype.* @Component public class MyBean implements CommandLineRunner { public void run(String... args) { // Do something... } } 如果某些定义的 CommandLineRunner 或 ApplicationRunner beans需要以特定的顺序调用，你可以实现 org.springframework.core.Ordered 接口或使用 org.springframework.core.annotation.Order 注解。","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.zhz.gift/tags/SpringBoot/"}]},{"title":"第三方配置","slug":"第三方配置","date":"2017-12-16T16:07:42.000Z","updated":"2017-12-17T12:12:37.019Z","comments":true,"path":"2017/12/17/第三方配置/","link":"","permalink":"http://www.zhz.gift/2017/12/17/第三方配置/","excerpt":"第三方配置","text":"第三方配置 @ConfigurationProperties 不仅可以注解在类上，也可以注解在public @Bean 方法上，当你需要为不受控的第三方组件绑定属性时，该方法将非常有用。为了从 Environment属性中配置一个bean，你需要使用@ConfigurationProperties 注解该bean： @ConfigurationProperties(prefix = &quot;foo&quot;) @Bean public FooComponent fooComponent() { ... } 和上面 ConnectionSettings 的示例方式相同，所有以foo为前缀的属性定义都会被映射到 FooComponent 上。 ##Relaxed绑定## Spring Boot将 Environment 属性绑定到 @ConfigurationProperties beans时会使用一些宽松的规则，所以 Environment属性名和bean属性名不需要精确匹配。常见的示例中有用的包括虚线分割（比如， context-path 绑定到 contextPath ），将environment属性转为大写字母（比如， PORT 绑定 port ）。例如，给定以下 @ConfigurationProperties 类： @ConfigurationProperties(prefix=&quot;person&quot;) public class OwnerProperties { private String firstName; public String getFirstName() { return this.firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } } 下面的属性名都能使用： 属性 说明 person.firstName 标准驼峰规则 person.first-name 虚线表示，推荐用于 .properties 和 .yml文件中 person.first_name 下划线表示，用于 .properties 和 .yml 文件的可选格式 PERSON_FIRST_NAME 大写形式，使用系统环境变量时推荐 ##属性转换## 将外部应用配置绑定到 @ConfigurationProperties beans时，Spring会尝试将属性强制转换为正确的类型。如果需要自定义类型转换器，你可以提供一个ConversionService bean（bean id为 conversionService ），或自定义属性编辑器（通过 CustomEditorConfigurer bean），或自定义 Converters （bean定义时需要注解 @ConfigurationPropertiesBinding ）。 注 由于该bean在应用程序生命周期的早期就需要使用，所以确保限制你的 ConversionService使用的依赖。通常，在创建时期任何你需要的依赖可能都没完全初始化。 ##@ConfigurationProperties校验## Spring Boot将尝试校验外部配置，默认使用JSR-303（如果在classpath路径中），你只需要将JSR-303 javax.validation 约束注解添加到 @ConfigurationProperties 类上： @ConfigurationProperties(prefix=&quot;connection&quot;) public class ConnectionProperties { @NotNull private InetAddress remoteAddress; // ... getters and setters } 为了校验内嵌属性的值，你需要使用 @Valid 注解关联的字段以触发它的校验，例如： @ConfigurationProperties(prefix=&quot;connection&quot;) public class ConnectionProperties { @NotNull @Valid private RemoteAddress remoteAddress; // ... getters and setters public static class RemoteAddress { @NotEmpty public String hostname; // ... getters and setters } } 你也可以通过创建一个叫做 configurationPropertiesValidator 的bean来添加自定义的Spring Validator 。 @Bean 方法需要声明为 static ，因为配置属性校验器在应用程序生命周期中创建的比较早，将 @Bean 方法声明为 static 允许该bean在创建时不需要实例化 @Configuration 类，从而避免了早期实例化（early instantiation）的所有问题。相关的示例可以看这里。 注 spring-boot-actuator 模块包含一个暴露所有 @ConfigurationProperties beans的端点（endpoint），通过浏览器打开 /configprops 进行浏览，或使用等效的JMX端点，具体参考Production readyfeatures。 @ConfigurationProperties vs. @Value@Value 是Spring容器的一个核心特性，它没有提供跟type-safe ConfigurationProperties相同的特性。下面的表格总结了 @ConfigurationProperties 和 @Value 支持的特性： 特性 @ConfigurationProperties @Value Relaxed绑定 Yes No Meta-data支持 Yes No SpEL表达式 No Yes 如果你为自己的组件定义了一系列的配置keys，我们建议你将它们以@ConfigurationProperties 注解的POJO进行分组。由于 @Value 不支持relaxed绑定，所以如果你使用环境变量提供属性值的话，它就不是很好的选择。最后，尽管 @Value 可以写 SpEL表达式，但这些表达式不会处理来自Application属性文件的属性。","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.zhz.gift/tags/SpringBoot/"},{"name":"config","slug":"config","permalink":"http://www.zhz.gift/tags/config/"}]},{"title":"使用YAML代替Properties","slug":"使用YAML代替Properties","date":"2017-12-16T16:07:42.000Z","updated":"2017-12-17T12:12:19.322Z","comments":true,"path":"2017/12/17/使用YAML代替Properties/","link":"","permalink":"http://www.zhz.gift/2017/12/17/使用YAML代替Properties/","excerpt":"使用YAML代替Properties","text":"使用YAML代替Properties ##SpringBoot支持YAML##YAML是JSON的一个超集，也是一种方便的定义层次配置数据的格式。只要你将SnakeYAML 库放到classpath下， SpringApplication 就会自动支持YAML，以作为properties的替换。注 如果你使用’Starters’，添加 spring-boot-starter 依赖会自动加载SnakeYAML。 ##加载YAML## Spring框架提供两个便利的类用于加载YAML文档，YamlPropertiesFactoryBean 会将YAML加载为 Properties ， YamlMapFactoryBean 会将YAML加载为 Map 。例如，下面的YAML文档： environments: dev: url: http://dev.bar.com name: Developer Setup prod: url: http://foo.bar.com name: My Cool App 会被转化到这些属性： environments.dev.url=http://dev.bar.com environments.dev.name=Developer Setup environments.prod.url=http://foo.bar.com environments.prod.name=My Cool App YAML列表被表示成使用[index]间接引用作为属性keys的形式，例如下面的YAML： my: servers: - dev.bar.com - foo.bar.com 将会转化到这些属性: my.servers[0]=dev.bar.com my.servers[1]=foo.bar.com 使用Spring DataBinder 工具集绑定这些属性（这是@ConfigurationProperties 做的事）时，你需要确保目标bean有个 java.util.List 或 Set 类型的属性，并且需要提供一个setter或使用可变的值初始化它，比如，下面的代码将绑定上面的属性： @ConfigurationProperties(prefix=&quot;my&quot;) public class Config { private List&lt;String&gt; servers = new ArrayList&lt;String&gt;(); public List&lt;String&gt; getServers(){ return this.servers; } } ##在Spring环境中使用YAML暴露属性## YamlPropertySourceLoader类能够将YAML作为PropertySource导出到SprigEnvironment ，这允许你使用常用的 @Value注解配合占位符语法访问YAML属性。 ##Multi-profile YAML文档## 你可以在单个文件中定义多个特定配置（profile-specific）的YAML文档，并通过 spring.profiles 标示生效的文档，例如： server: address: 192.168.1.100 --- spring: profiles: development server: address: 127.0.0.1 --- spring: profiles: production server: address: 192.168.1.120 在以上例子中，如果 development profile被激活， server.address 属性将是 127.0.0.1 ；如果 development 和 production profiles没有启用，则该属性的值将是 192.168.1.100 。在应用上下文启动时，如果没有明确指定激活的profiles，则默认的profiles将生效。所以，在下面的文档中我们为 security.user.password 设置了一个值，该值只在”default” profile中有效： server: port: 8000 --- spring: profiles: default security: user: password: weak 然而，在这个示例中，由于没有关联任何profile，密码总是会设置，并且如果有必要的话可以在其他profiles中显式重置： server: port: 8000 security: user: password: weak 通过 ! 可以对 spring.profiles指定的profiles进行取反（negated，跟java中的 ! 作用一样），如果negated和non-negated profiles都指定一个单一文件，至少需要匹配一个non-negated profile，可能不会匹配任何negated profiles。 ##YAML缺点## YAML文件不能通过 @PropertySource 注解加载，如果需要使用该方式，那就必须使用properties文件。 ##合并YAML列表## 正如上面看到的，所有YAML最终都转换为properties，在通过一个profile覆盖”list”属性时这个过程可能不够直观（counter intuitive）。例如，假设有一个 MyPojo 对象，默认它的 name 和 description 属性都为 null ，下面我们将从 FooProperties 暴露一个 MyPojo 对象列表（list）： @ConfigurationProperties(&quot;foo&quot;) public class FooProperties { private final List&lt;MyPojo&gt; list = new ArrayList&lt;&gt;(); public List&lt;MyPojo&gt; getList() { return this.list; } } 考虑如下配置： foo: list: - name: my name description: my description --- spring: profiles: dev foo: list: - name: my another name 如果 dev profile没有激活， FooProperties.list 将包括一个如上述定义的 MyPojo 实体，即使 dev 生效，该 list 仍旧只包含一个实体（ name 值为 my another name ，description 值为 null ）。此配置不会向该列表添加第二个 MyPojo 实例，也不会对该项进行合并。当一个集合定义在多个profiles时，只使用优先级最高的： foo: list: - name: my name description: my description - name: another name description: another description --- spring: profiles: dev foo: list: - name: my another name 在以上示例中，如果 dev profile激活， FooProperties.list将包含一个 MyPojo 实体（ name 值为 my another name ， description 值为 null ）。","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.zhz.gift/tags/SpringBoot/"},{"name":"YAML","slug":"YAML","permalink":"http://www.zhz.gift/tags/YAML/"}]},{"title":"SpringBoot日志","slug":"SpringBoot日志","date":"2017-12-16T16:07:42.000Z","updated":"2017-12-17T12:12:51.622Z","comments":true,"path":"2017/12/17/SpringBoot日志/","link":"","permalink":"http://www.zhz.gift/2017/12/17/SpringBoot日志/","excerpt":"SpringBoot日志","text":"SpringBoot日志 ##日志格式## Spring Boot默认的日志输出格式如下： 2014-03-05 10:57:51.112 INFO 45469 --- [main]org.apache.catalina.core.StandardEngine : Starting Servlet Engine: Apache Tomcat/7.0.522014-03-05 10:57:51.253 INFO 45469 --- [ost-startStop-1] o.a.c. c.C.[Tomcat].[localhost].[/] : Initializing Spring embedde d WebApplicationContext 2014-03-05 10:57:51.253 INFO 45469 --- [ost-startStop-1] o.s.we b.context.ContextLoader : Root WebApplicationContext: initialization completed in 1358 ms 2014-03-05 10:57:51.698 INFO 45469 --- [ost-startStop-1] o.s.b. c.e.ServletRegistrationBean : Mapping servlet: &apos;dispatche rServlet&apos; to [/] 2014-03-05 10:57:51.702 INFO 45469 --- [ost-startStop-1] o.s.b. c.embedded.FilterRegistrationBean : Mapping filter: &apos;hiddenHttp MethodFilter&apos; to: [/*] 输出的节点（items）如下： 日期和时间 - 精确到毫秒，且易于排序。 日志级别 - ERROR , WARN , INFO , DEBUG 或 TRACE 。 Process ID。 — 分隔符，用于区分实际日志信息开头。 线程名 - 包括在方括号中（控制台输出可能会被截断）。 日志名 - 通常是源class的类名（缩写）。 日志信息。注 Logback没有 FATAL 级别，它会映射到 ERROR 。 ##控制台输出## 默认的日志配置会在写日志消息时将它们回显到控制台，级别为 ERROR ,WARN 和 INFO 的消息会被记录。你可以在启动应用时，通过 –debug 标识开启控制台的DEBUG级别日志记录，也可以在application.properties 中指定 debug=true 。 $ java -jar myapp.jar --debug 当debug模式启用时，一系列核心loggers（内嵌容器，Hibernate，Spring Boot等）记录的日志会变多，但不会输出所有的信息。相应地，你可以在启动应用时，通过 –trace （或在 application.properties 设置 trace=true ）启用”trace”模式，该模式能够追踪核心loggers（内嵌容器，Hibernate生成的schema，Spring全部的portfolio）的所有日志信息。 ##文件输出## 默认情况下，SpringBoot只会将日志记录到控制台，而不写进日志文件，如果需要，你可以设置 logging.file 或 logging.path 属性（例如 application.properties ）。下表展示如何组合使用 logging.* ： logging.file logging.path 示例 描述 (none) (none) 只记录到控制台 Specific file (none) my.log 写到特定的日志文件，名称可以是精确的位置或相对于当前目录 (none) Specific directory /var/log 写到特定目录下的 spring.log 里，名称可以是精确的位置或相对于当前目录 日志文件每达到10M就会被分割，跟控制台一样，默认记录 ERROR ,WARN 和 INFO 级别的信息。 ##日志级别## 所有Spring Boot支持的日志系统都可以在Spring Environment 中设置级别（ application.properties 里也一样），设置格式为’logging.level.*=LEVEL’，其中 LEVEL 是 TRACE , DEBUG , INFO , WARN , ERROR , FATAL , OFF 之一：以下是 application.properties 示例： logging.level.root=WARN logging.level.org.springframework.web=DEBUG logging.level.org.hibernate=ERROR 注 默认情况，Spring Boot会重新映射Thymeleaf的 INFO 信息到 DEBUG 级别，这能减少标准日志输出的噪声。查看LevelRemappingAppender可以按自己的配置设置映射。","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.zhz.gift/tags/SpringBoot/"},{"name":"log","slug":"log","permalink":"http://www.zhz.gift/tags/log/"}]},{"title":"SpringBoot应用启动事件","slug":"SpringBoot应用启动事件","date":"2017-12-16T16:07:42.000Z","updated":"2017-12-17T12:10:53.646Z","comments":true,"path":"2017/12/17/SpringBoot应用启动事件/","link":"","permalink":"http://www.zhz.gift/2017/12/17/SpringBoot应用启动事件/","excerpt":"SpringBoot应用启动事件","text":"SpringBoot应用启动事件 监听Spring boot应用的事件只需实现ApplicationListener接口来监听对应事件. 有些事件实际上是在 ApplicationContext 创建前触发的，所以你不能在那些 事件（处理类）中通过 @Bean 注册监听器，只能通 过 SpringApplication.addListeners(…) 或 SpringApplicationBuilder.lis teners(…) 方法注册. 应用运行时，事件会以下面的次序发送： 在运行开始，但除了监听器注册和初始化以外的任何处理之前，会发送一 个 ApplicationStartedEvent 。 在Environment将被用于已知的上下文，但在上下文被创建前，会发送一 个 ApplicationEnvironmentPreparedEvent 。 在refresh开始前，但在bean定义已被加载后，会发送一 个 ApplicationPreparedEvent 。 在refresh之后，相关的回调处理完，会发送一个 ApplicationReadyEvent ， 表示应用准备好接收请求了。 启动过程中如果出现异常，会发送一个 ApplicationFailedEvent 。 注 通常不需要使用application事件，但知道它们的存在是有用的（在某些场合可能 会使用到），比如，在Spring Boot内部会使用事件处理各种任务。","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.zhz.gift/tags/SpringBoot/"},{"name":"event","slug":"event","permalink":"http://www.zhz.gift/tags/event/"}]},{"title":"spring boot简介","slug":"spring-boot简介","date":"2017-12-02T14:22:54.000Z","updated":"2017-12-03T10:38:50.690Z","comments":true,"path":"2017/12/02/spring-boot简介/","link":"","permalink":"http://www.zhz.gift/2017/12/02/spring-boot简介/","excerpt":"spring boot spring boot 为所有spring框架开发者提供一种更加易于理解，更加便捷高效的开发方式；通过提供更为直观的spring平台和第三方依赖库，只需要极其少量的spring配置，便能部署运行spring boot应用。","text":"spring boot spring boot 为所有spring框架开发者提供一种更加易于理解，更加便捷高效的开发方式；通过提供更为直观的spring平台和第三方依赖库，只需要极其少量的spring配置，便能部署运行spring boot应用。 1.环境要求 Spring Boot 2.0.0.BUILD-SNAPSHOT 需要 Java 8 以及 Spring Framework 5.0.2.RELEASE 或者以上版本.当使用maven或者gradle构建spring boot时需要 Maven 3.2+ 或者 Gradle 4及其以上版本. 2.spring boot安装 2.1使用maven 构建spring boot应用 pom.xml配置: &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;myproject&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!-- Inherit defaults from Spring Boot --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.0.BUILD-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;!-- Add typical dependencies for a web application --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- Package as an executable jar --&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!-- Add Spring repositories --&gt; &lt;!-- (you don&apos;t need this if you are using a .RELEASE version) --&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;url&gt;http://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;url&gt;http://repo.spring.io/milestone&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;url&gt;http://repo.spring.io/snapshot&lt;/url&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;url&gt;http://repo.spring.io/milestone&lt;/url&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/project&gt; 2.2安装Spring Boot CLI The Spring Boot CLI (Command Line Interface)是一个用于快速建立spring原型的命令行工具.通过它你能运行Groovy scripts,使用熟悉的类java语法。 使用CLI来运行spring boot不是必须的,但它是使spring应用运行起来的最快方法. 2.2.1 手动安装 你可以在spring 软件仓库下载Spring CLI spring-boot-cli-2.0.0.BUILD-SNAPSHOT-bin.zip spring-boot-cli-2.0.0.BUILD-SNAPSHOT-bin.tar.gz 2.2.2 通过SDKMAN安装 SDKMAN!(The Software Development Kit Manager)可以用来管理不同版本的二进制sdks,包括 Groovy和Spring Boot CLI.从sdkman.io获取SDKMAN!并且通过以下命令来安装Spring Boot $ sdk install springboot $ spring --version Spring Boot v2.0.0.BUILD-SNAPSHOT 上述的安装方式都会在本地建立一个名为dev的Spring实例,它指向你的安装路径,所以你每次重建Spring Boot时,spring 都会更新到最新. 你能通过以下命令看到它是如何进行的: $ sdk ls springboot ================================================================================ Available Springboot Versions ================================================================================ &gt; + dev * 2.0.0.BUILD-SNAPSHOT ================================================================================ + - local version * - installed &gt; - currently in use ================================================================================ 3.开发你首个Spring Boot 应用 这个章节描述了如何区开发一个\\”五脏俱全\\”的Spring Boot \\”Hello World!\\”应用.我们使用Maven来构建这个项目,因为大部分IDES都支持它. spring.ioweb网站包含很多”Getting Started”的spring boot教程,如果你需要解决一些特定的问题,首先查看这里. 开始之前首先检查jdk版本和maven版本是否满足要求 java -version mvn -v pom.xml 配置如下: &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;myproject&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.0.BUILD-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;!-- Additional lines to be added here... --&gt; &lt;!-- (you don&apos;t need this if you are using a .RELEASE version) --&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;url&gt;http://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;url&gt;http://repo.spring.io/milestone&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;url&gt;http://repo.spring.io/snapshot&lt;/url&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;url&gt;http://repo.spring.io/milestone&lt;/url&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/project&gt; 3.2 Spring Boot提供了大量的”Starters”开始器使你能在classpath路径添加jars.我们普通的例子应用已经在POM的父节点使用 spring-boot-starter-parent . spring-boot-starter-parent是一个提供了众多有用Maven默认配置的特殊启动器.它同样提供了dependency-management配置使你能够为一些dependencies依赖省略 version 配置. 但你开发其它特殊类型的应用时可能需要使用到其它启动器(Starters),例如,当我们开发一个web应用时,我们添加spring-boot-starter-web 依赖.在那之前,我们可以通过以下命令查看依赖树: mvn dependency:tree 通过mvn dependency:tree命令我们可以查看项目的依赖树结构,你可以看到 spring-boot-starter-parent 本身没有提供其它依赖.通过编辑pom.xml添加必要的依赖 org.springframework.boot spring-boot-starter-web 如果你再次运行 mvn dependency:tree 命令,你就能看到一系列新添加的依赖,包括tomcat 服务器以及spring boot本身. 3.3 代码编写 为了完成应用，我们首先需要创建一个java文件.在src/main/java下创建Example.java文件并添加以下代码: import org.springframework.boot.*; import org.springframework.boot.autoconfigure.*; import org.springframework.web.bind.annotation.*; @RestController @EnableAutoConfiguration public class Example { @RequestMapping(&quot;/&quot;) String home() { return &quot;Hello World!&quot;; } public static void main(String[] args) throws Exception { SpringApplication.run(Example.class, args); } } 3.3.1 @RestController 和 @RequestMapping 注解","categories":[],"tags":[{"name":"spring","slug":"spring","permalink":"http://www.zhz.gift/tags/spring/"},{"name":"框架","slug":"框架","permalink":"http://www.zhz.gift/tags/框架/"}]},{"title":"快速排序","slug":"快速排序","date":"2017-12-01T16:24:16.000Z","updated":"2017-12-01T16:24:49.088Z","comments":true,"path":"2017/12/02/快速排序/","link":"","permalink":"http://www.zhz.gift/2017/12/02/快速排序/","excerpt":"快速排序 堆排序是指利用堆这种数据结构所设计的一种排序算法.堆是一种特殊的二叉树,每个子节点的值总是小于(或大于)它的父节点,相应的分为最大堆或最小堆,通过最大堆或最小堆不断输出堆顶元素,直到全部元素都已输出,得到的输出元素序列即为有序序列.","text":"快速排序 堆排序是指利用堆这种数据结构所设计的一种排序算法.堆是一种特殊的二叉树,每个子节点的值总是小于(或大于)它的父节点,相应的分为最大堆或最小堆,通过最大堆或最小堆不断输出堆顶元素,直到全部元素都已输出,得到的输出元素序列即为有序序列.","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://www.zhz.gift/tags/java/"},{"name":"算法","slug":"算法","permalink":"http://www.zhz.gift/tags/算法/"}]},{"title":"堆排序","slug":"堆排序","date":"2017-11-30T16:07:42.000Z","updated":"2017-11-30T16:53:14.523Z","comments":true,"path":"2017/12/01/堆排序/","link":"","permalink":"http://www.zhz.gift/2017/12/01/堆排序/","excerpt":"堆排序 堆排序是指利用堆这种数据结构所设计的一种排序算法.堆是一种特殊的二叉树,每个子节点的值总是小于(或大于)它的父节点,相应的分为最大堆或最小堆,通过最大堆或最小堆不断输出堆顶元素,直到全部元素都已输出,得到的输出元素序列即为有序序列.","text":"堆排序 堆排序是指利用堆这种数据结构所设计的一种排序算法.堆是一种特殊的二叉树,每个子节点的值总是小于(或大于)它的父节点,相应的分为最大堆或最小堆,通过最大堆或最小堆不断输出堆顶元素,直到全部元素都已输出,得到的输出元素序列即为有序序列. import java.util.Arrays; public class HeapSort3 { public static void main(String[] args){ int[] test = new int[]{8,11,3,6,23,14,18,7,55,34}; System.out.println(&quot;初始数组:&quot; + Arrays.toString(test)); HeapSort3.heapSort(test); System.out.println(Arrays.toString(test)); } public static int leftChild(int child){ return child * 2 + 1; } public static void precDown(int[] a,int i,int n){ int child; int temp; for(temp = a[i];leftChild(i) &lt; n;i = child){ child = leftChild(i); if(i != n - 1 &amp;&amp; a[child] &lt; a[child + 1]){ child++; } if(a[i] &lt; a[child]){ a[i] = a[child]; } } a[i] = temp; } public static void swapReferences(int[] a,int index){ int temp = a[0]; a[0] = a[index]; a[index] = temp; } public static void heapSort(int[] a){ for(int i = a.length / 2;i &gt; 0;i--){ precDown(a,i,a.length - 1); } System.out.println(&quot;max二叉堆构建完毕:&quot; + Arrays.toString(a)); for(int k = a.length - 1;k &gt; 0;k--){ swapReferences(a,k); precDown(a,0,k); } } } 最差时间复杂度:O(N*logN),平均时间复杂度O(N*logN),空间复杂度:O(1),不稳定算法","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://www.zhz.gift/tags/java/"},{"name":"算法","slug":"算法","permalink":"http://www.zhz.gift/tags/算法/"}]},{"title":"归并排序","slug":"归并排序","date":"2017-11-20T16:15:34.000Z","updated":"2017-11-20T16:32:40.377Z","comments":true,"path":"2017/11/21/归并排序/","link":"","permalink":"http://www.zhz.gift/2017/11/21/归并排序/","excerpt":"归并排序 将一个无序序列进行折半递归,直到得到单个元素的有序序列,然后递归的将折半后左右两边的有序序列依次进行合并,最终得到有序序列.","text":"归并排序 将一个无序序列进行折半递归,直到得到单个元素的有序序列,然后递归的将折半后左右两边的有序序列依次进行合并,最终得到有序序列. import java.util.Arrays; public class MergeSort { public static void main(String[] args){ int[] a = new int[]{11,2,5,15,23,44,24,8}; mergeSort(a); System.out.println(Arrays.toString(a)); } private static void mergeSort(int[] a,int[] tmpArray,int left,int right){ if(left &lt; right){ int center = (left + right) / 2; mergeSort(a,tmpArray,left,center); mergeSort(a,tmpArray,center + 1,right); merge(a,tmpArray,left,center + 1,right); } System.out.println(&quot;left:&quot; + left + &quot;,right:&quot; + right); } public static void mergeSort(int[] a){ int[] tmpArray = new int[a.length]; mergeSort(a,tmpArray,0,a.length - 1); } private static void merge(int[] a,int[] tmpArray,int leftPos,int rightPos,int rightEnd){ System.out.println(&quot;leftPos:&quot; + leftPos + &quot;,rightPos:&quot; + rightPos + &quot;,rightEnd:&quot; + rightEnd); int leftEnd = rightPos - 1; int tmpPos = leftPos; int numElements = rightEnd - leftPos + 1; //Main loop while(leftPos &lt;= leftEnd &amp;&amp; rightPos &lt;= rightEnd){ if(a[leftPos] &lt; a[rightPos]){ tmpArray[tmpPos++] = a[leftPos++]; }else{ tmpArray[tmpPos++] = a[rightPos++]; } } while(leftPos &lt;= leftEnd){ tmpArray[tmpPos++] = a[leftPos++]; } while(rightPos &lt;= rightEnd){ tmpArray[tmpPos++] = a[rightPos++]; } for(int i = 0;i &lt; numElements;i++,rightEnd--){ a[rightEnd] = tmpArray[rightEnd]; } } } 最差时间复杂度:O(N^2) 平均时间复杂度O(N*logN) 空间复杂度:O(N) 稳定算法","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://www.zhz.gift/tags/java/"},{"name":"算法","slug":"算法","permalink":"http://www.zhz.gift/tags/算法/"}]},{"title":"希尔排序","slug":"希尔排序","date":"2017-11-20T15:57:35.000Z","updated":"2017-11-20T16:14:06.358Z","comments":true,"path":"2017/11/20/希尔排序/","link":"","permalink":"http://www.zhz.gift/2017/11/20/希尔排序/","excerpt":"希尔排序 希尔排序(ShellSort)的名称源于它的发明者Donald Shell.它通过比较相距一定间隔(h[k])的元素来工作,各躺比较所用的距离随着算法的进行而减小(h[k-1]),直到只比较相邻元素的最后一趟排序为止,因此希尔排序也称为缩减增量排序.希尔排序所使用的增量序列只要h[1]=1,任何增量序列都是可行的,但其时间复杂度会有所不同.","text":"希尔排序 希尔排序(ShellSort)的名称源于它的发明者Donald Shell.它通过比较相距一定间隔(h[k])的元素来工作,各躺比较所用的距离随着算法的进行而减小(h[k-1]),直到只比较相邻元素的最后一趟排序为止,因此希尔排序也称为缩减增量排序.希尔排序所使用的增量序列只要h[1]=1,任何增量序列都是可行的,但其时间复杂度会有所不同. import java.util.*; public class Test { public static void main(String[] args){ int[] test = new int[]{11,3,8,25,22}; Test.shellSort(test); } /** * 希尔排序,使用ht=N/2 hk=h(k+1)/2的增量序列 * @param a */ public static void shellSort(int[] a){ int hk; int j; for(hk = a.length / 2;hk &gt; 0 ;hk /= 2){ for(int k = hk;k &lt; a.length;k++){ int temp = a[k]; for(j = k;j &gt;= hk &amp;&amp; a[j - hk] &gt; temp;j -= hk){ a[j] = a[j- hk]; } a[j] = temp; } } System.out.println(Arrays.toString(a)); } } 不稳定算法 空间复杂度O(1)","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://www.zhz.gift/tags/java/"},{"name":"算法","slug":"算法","permalink":"http://www.zhz.gift/tags/算法/"}]},{"title":"插入排序","slug":"插入排序","date":"2017-11-20T15:52:15.000Z","updated":"2017-11-20T15:57:39.472Z","comments":true,"path":"2017/11/20/插入排序/","link":"","permalink":"http://www.zhz.gift/2017/11/20/插入排序/","excerpt":"插入排序 插入排序由N-1趟排序组成,对于p=1到N-1趟,插入排序保证从位置0到位置p上的元素为已排序状态.","text":"插入排序 插入排序由N-1趟排序组成,对于p=1到N-1趟,插入排序保证从位置0到位置p上的元素为已排序状态. import java.util.Arrays; public class InsertSort2 { public static void main(String[] args){ int[] a = new int[]{11,3,6,22,15}; sort(a); System.out.println(Arrays.toString(a)); } //插入排序： //将无序的元素插入到有序的元素序列中，插入后仍然有序 public static void sort(int[] a){ int k; for(int p = 1;p &lt; a.length;p++){ int temp = a[p]; for(k = p;k &gt; 0 &amp;&amp; a[k- 1] &gt; temp;k--){ a[k] = a[k- 1]; } a[k] = temp; } } } 最差时间复杂度:O(n^2) 平均时间复杂度O(n^2) 空间复杂度:O(1) 稳定算法","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://www.zhz.gift/tags/java/"},{"name":"算法","slug":"算法","permalink":"http://www.zhz.gift/tags/算法/"}]},{"title":"冒泡排序","slug":"冒泡排序","date":"2017-11-20T15:14:53.000Z","updated":"2017-11-20T15:51:10.068Z","comments":true,"path":"2017/11/20/冒泡排序/","link":"","permalink":"http://www.zhz.gift/2017/11/20/冒泡排序/","excerpt":"冒泡排序","text":"冒泡排序 import java.util.Arrays; public class MTest { //冒泡排序： //比较相邻元素，直到序列变为有序为止 public static void main(String[] args){ int[] a = new int[]{7,2,8,11,3,5,4}; //int[] a = new int[]{1,2,3,4,5,6}; for(int i = 0;i &lt; a.length - 1;i++){ boolean flag =false; for(int k = 0;k &lt; a.length - 1 -i;k++){ if(a[k] &gt; a[k + 1]){ int temp = a[k]; a[k] = a[k + 1]; a[k + 1] = temp; flag = true; } } if(!flag){ break; } } System.out.println(Arrays.toString(a)); } } 每次循环对每对相邻元素依次进行比较,比较过后最后的元素也是最大的元素,重复n-1次即可得到有序序列最差时间复杂度:O(n^2) 平均时间复杂度O(n^2) 空间复杂度:O(1) 稳定算法","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://www.zhz.gift/tags/java/"},{"name":"算法","slug":"算法","permalink":"http://www.zhz.gift/tags/算法/"}]}]}