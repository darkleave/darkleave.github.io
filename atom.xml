<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>静默的魔法书</title>
  
  <subtitle>零</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.zhz.gift/"/>
  <updated>2019-07-24T14:27:37.212Z</updated>
  <id>http://www.zhz.gift/</id>
  
  <author>
    <name>Hans Chung</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Unity 学习笔记01 - unity编辑器</title>
    <link href="http://www.zhz.gift/2019/07/14/Unity%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001/"/>
    <id>http://www.zhz.gift/2019/07/14/Unity学习笔记01/</id>
    <published>2019-07-14T07:09:42.000Z</published>
    <updated>2019-07-24T14:27:37.212Z</updated>
    
    <content type="html"><![CDATA[<h2 id="unity编辑器"><a href="#unity编辑器" class="headerlink" title="unity编辑器"></a>unity编辑器</h2><p>Unity编辑器拥有非常直观，明了的界面布局，熟悉Unity界面是学习Unity的基础</p><a id="more"></a><h2 id="界面布局"><a href="#界面布局" class="headerlink" title="界面布局"></a>界面布局</h2><p>Unity 主编辑器由若干个选项卡窗口组成，这些窗口统称为视图。每个视图都有其特定的作用：</p><ul><li>场景视图（Scene View):用于设置场景以及放置游戏对象,是构造游戏场景的地方。</li><li>游戏视图（Game View):由场景中相机所渲染的游戏画面，是游戏发布后玩家所能看到的内容。</li><li>层级视图（Hierarchy):用于显示当前场景中所有游戏对象的层级关系。</li><li>项目视图(Project):整个工程中所有可用的资源，例如模型，脚本等。</li><li>检视视图（Inspector):用于显示当前所选择游戏对象的相关属性与信息。</li></ul><p><strong>在实际工作中经常需要在各种不同的视图中切换，以下是常用的视图切换快捷键，熟练使用快捷键可以大大提高工作效率</strong></p><ul><li>Ctrl+1:切换到Scene视图</li><li>Ctrl+2:切换到Game视图。</li><li>Ctrl+3:切换到Inspector视图</li><li>Ctrl+4：切换到Hierarchy视图</li><li>Ctrl+5:切换到Project视图</li><li>Ctrl+6:切换到Animation视图</li><li>Ctrl+7:切换到Profiler视图.</li><li>Ctrl+8：切换到Audio Mixer视图</li><li>Ctrl+9:切换到Asset Store视图</li><li>Ctrl+0：切换到Version Control 视图</li><li>Ctrl+Shift+C: 切换到Console视图</li></ul><h2 id="工具栏"><a href="#工具栏" class="headerlink" title="工具栏"></a>工具栏</h2><p>Unity工具栏位于菜单栏的下方，主要有5个控制区域组成，它提供了常用功能的快捷访问方式，工具栏主要包括Transform Tools(变换工具),Transform Gizmo Tools(变换辅助工具),Play(播放控制),Layers(分层下拉列表）和Layout(布局下拉列表）。</p><h3 id="Transform-Tools-变换工具"><a href="#Transform-Tools-变换工具" class="headerlink" title="Transform Tools (变换工具)"></a>Transform Tools (变换工具)</h3><p>Transform Tools(变换工具): 主要针对Scene视图，用于实现所选择游戏对象的位移，旋转以及缩放等操作控制，变换工具从左到右依次是Hand（手形)工具，Translate(移动)工具，Rotate（旋转)工具，Scale(缩放）工具和Rect(矩形)工具。</p><h3 id="Transform-Gizmo-Tools-变换辅助工具"><a href="#Transform-Gizmo-Tools-变换辅助工具" class="headerlink" title="Transform Gizmo Tools (变换辅助工具)"></a>Transform Gizmo Tools (变换辅助工具)</h3><p>Pivot/Center | Global/Local:<br>Center 显示游戏对象的轴心参考点。Center为以所有选中物体所组成的轴心作为游戏对象的轴心参考点（常用于多物体的整体移动）；Pivot为以最后一个选中的游戏对象的轴心为参考点。<br>Global显示物体的坐标，Global为所选中游戏对象使用世界坐标；Local为该游戏对象使用自身坐标。</p><h3 id="Play（播放控制）"><a href="#Play（播放控制）" class="headerlink" title="Play（播放控制）"></a>Play（播放控制）</h3><p>Play（播放控制）：应用于Game视图，当单击播放按钮时，Game视图会被激活，实时显示游戏运行的画面效果，用户可在编辑和游戏状态之间随意切换，使游戏的调试和运行变得便捷，高效。</p><h3 id="Layers-分层下拉列表）"><a href="#Layers-分层下拉列表）" class="headerlink" title="Layers(分层下拉列表）"></a>Layers(分层下拉列表）</h3><p>Layers(分层下拉列表）：用来控制游戏对象在Scene视图中的显示，在下拉列表中显示状态为“睁眼”的物体将被显示在Scene视图中</p><h3 id="Layout-布局下拉列表"><a href="#Layout-布局下拉列表" class="headerlink" title="Layout(布局下拉列表)"></a>Layout(布局下拉列表)</h3><p>Layout (布局下拉列表):用来切换视图的布局，用户也可以存储自定义的界面布局.</p><h2 id="菜单栏"><a href="#菜单栏" class="headerlink" title="菜单栏"></a>菜单栏</h2><p>Unity 5.0默认情况下有7个菜单项，分别是File,Edit,Assets,GameObject,Component,Window和Help.</p><h3 id="File-文件-菜单"><a href="#File-文件-菜单" class="headerlink" title="File(文件)菜单"></a>File(文件)菜单</h3><p>File(文件)菜单主要包含工程与场景的创建，保存以及输出的功能，</p><h3 id="Edit-编辑菜单"><a href="#Edit-编辑菜单" class="headerlink" title="Edit(编辑菜单)"></a>Edit(编辑菜单)</h3><p>Edit(编辑)菜单主要用来实现场景内部相应编辑设置.</p><h3 id="Assets-资源-菜单"><a href="#Assets-资源-菜单" class="headerlink" title="Assets(资源)菜单"></a>Assets(资源)菜单</h3><p>Assets(资源)菜单提供了针对游戏资源管理的相关工具,通过Assets菜单的相关命令,用户不仅可以在场景内部创建相应的游戏对象，还可以导入和导出所需要的资源包.</p><h3 id="GameObject-游戏对象-菜单"><a href="#GameObject-游戏对象-菜单" class="headerlink" title="GameObject(游戏对象)菜单"></a>GameObject(游戏对象)菜单</h3><p>GameObject(游戏对象)菜单主要创建游戏对象，如灯光，粒子，模型，UI等，了解GameObject菜单可以更好地实现场景内部的管理与设计.</p><h3 id="Component-组件-菜单"><a href="#Component-组件-菜单" class="headerlink" title="Component(组件)菜单"></a>Component(组件)菜单</h3><p>Component(组件)可以实现GameObject的特定属性,本质上每个组件是一个类的实例。在Component菜单中，Unity为用户提供了多种常用的组件资源。</p><h3 id="Windows-窗口-菜单"><a href="#Windows-窗口-菜单" class="headerlink" title="Windows(窗口)菜单"></a>Windows(窗口)菜单</h3><p>Window(窗口) 菜单可以控制编辑器的界面布局,还能打开各种视图以及访问Unity的Asset Store在线资源商店.</p><h3 id="Help-帮助-菜单"><a href="#Help-帮助-菜单" class="headerlink" title="Help(帮助)菜单"></a>Help(帮助)菜单</h3><p>Help(帮助)菜单汇聚了Unity的相关资源链接,例如Unity手册，脚本参考,论坛等，同时也可以对软件的授权许可进行相应的管理.</p><h2 id="常用工作视图"><a href="#常用工作视图" class="headerlink" title="常用工作视图"></a>常用工作视图</h2><h3 id="Project-项目-视图"><a href="#Project-项目-视图" class="headerlink" title="Project(项目)视图"></a>Project(项目)视图</h3><p>Project(项目)视图是Unity整个项目工程的资源汇总,保存了游戏场景中用到的脚本，材质，字体，贴图，外部导入的网络模型等资源文件.</p><h3 id="Scene-场景-视图"><a href="#Scene-场景-视图" class="headerlink" title="Scene(场景)视图"></a>Scene(场景)视图</h3><p>Scene(场景)视图是Unity最常用的视图之一，该视图用来构造游戏场景，用户可以在这个视图中对游戏对象进行操作.</p><p><strong>Scene视图常用的操作方法</strong></p><ul><li>旋转操作：按Alt+鼠标左键,可以在场景中沿所注视的位置旋转视角.</li><li>移动操作: 按住鼠标的滚轮键,或者按键盘上的【Q】键，可移动场景视图下的观看位置。。</li><li>缩放操作：使用滚轮键，按Alt+鼠标右键可以放大和缩小视图的视角</li><li>居中显示所选择的物体：按【F】键可以将选择的游戏对象剧中显示</li><li>Flythrough(飞行浏览）模式：鼠标右键+W/A/S/D键可以切换Flythrough模式下加按【Shift】键会使移动加速。</li></ul><h3 id="Game-游戏-视图"><a href="#Game-游戏-视图" class="headerlink" title="Game (游戏)视图"></a>Game (游戏)视图</h3><p>Game(游戏)视图是显示游戏最终运行效果的预览窗口.通过单机工具栏的“播放”按钮即可在Game窗口进行游戏的实时预览,方便游戏的调试和开发.</p><h3 id="Inspector-检视-视图"><a href="#Inspector-检视-视图" class="headerlink" title="Inspector(检视)视图"></a>Inspector(检视)视图</h3><p>Inspector(检视)视图用于显示游戏场景中当前所选择游戏对象的详细信息和属性设置,包括对象的名称，标签，位置坐标，旋转角度，缩放，组件等信息.</p><ul><li>Transform: 用户可以通过Transform组件对游戏对象的Position(位置),Rotation(旋转)和Scale(缩放)这三个属性进行修改.Transform组件是个基础组件，每个游戏对象都有这个组件.</li><li>Mesh Filter:网格过滤器用于从对象中获取网格信息(Mesh)并将其传递到用于渲染至屏幕的网格渲染器当中.</li><li>Mesh Collider: Mesh 碰撞体，为了防止物体被穿透,需要给对象添加碰撞体.</li><li>Mesh Renderer:网格渲染器是从网格过滤器获得几何形状，并且根据游戏对象的Transform组件所定义的位置进行渲染.</li><li>Materials:设置游戏对象的颜色，贴图等信息。</li></ul><h3 id="Hierarchy-层级-视图"><a href="#Hierarchy-层级-视图" class="headerlink" title="Hierarchy(层级) 视图"></a>Hierarchy(层级) 视图</h3><p>Hierarchy(层级) 视图用于显示当前场景中每个游戏对象.<br>在Hierarchy视图中提供了parenting（父子化)关系,通过为游戏对象建立Parenting关系，可以使多个对象的移动和编辑变得更为方便和准确.</p><p>任何游戏对象都可以有多个子对象，但只能有一个父对象,用户对父对象进行的操作，都会影响到其下所有的子对象，即子对象继承了父对象的数据。子对象还可以对自身进行独立的编辑操作。</p><p>虽然通过Scene视图可以非常直观地对场景资源进行编辑和管理，但是在Scene视图中游戏对象容易重叠和遮挡,这时候就需要在Hierarchy视图中进行操作，文件显示方式，更易于用户对游戏对象的管理.</p><h3 id="Console-控制台-视图"><a href="#Console-控制台-视图" class="headerlink" title="Console(控制台)视图"></a>Console(控制台)视图</h3><p>Console(控制台) 是Unity的调试工具, 用户可以编写脚本在Console视图输出调试信息.</p><p>快捷键：Window-&gt;Console命令或按【Ctrl+Shift+C】</p><h3 id="Animation（动画-视图"><a href="#Animation（动画-视图" class="headerlink" title="Animation（动画)视图"></a>Animation（动画)视图</h3><p>Animation(动画)视图用于在Unity中创建和编辑游戏对象的动画剪辑(Animation Clips),用户可以依次选择菜单栏中的Window-&gt;Animation命令或按【Ctrl+6】组合键弹出Animation视图.</p><h3 id="Animator-动画控制器-视图"><a href="#Animator-动画控制器-视图" class="headerlink" title="Animator(动画控制器)视图"></a>Animator(动画控制器)视图</h3><p>Animator(动画控制器)视图可以预览和设置角色行为，用户可以依次选择菜单栏中的Window-&gt;Animator 命令打开Animator视图.</p><h3 id="Sprite-Editor-Sprite编辑器"><a href="#Sprite-Editor-Sprite编辑器" class="headerlink" title="Sprite Editor(Sprite编辑器)"></a>Sprite Editor(Sprite编辑器)</h3><p>Sprite Editor (Sprite编辑器)是用于建立Sprite的工具,使用它可以提取复杂图片中的元素,并风别建立Sprite精灵.</p><h3 id="Sprite-Packer-Sprite打包工具"><a href="#Sprite-Packer-Sprite打包工具" class="headerlink" title="Sprite Packer(Sprite打包工具)"></a>Sprite Packer(Sprite打包工具)</h3><p>Sprite Packer(Sprite打包工具) 是用于制作Sprite图集的工具,可以将各个Sprite制作成图集,这样可以把图片的空间利用率提高,减少资源的浪费.</p><h3 id="Lightmaps-光照贴图烘培-视图"><a href="#Lightmaps-光照贴图烘培-视图" class="headerlink" title="Lightmaps(光照贴图烘培) 视图"></a>Lightmaps(光照贴图烘培) 视图</h3><p>Unity内置了光照贴图烘培工具Beast.使用Beast 可以根据场景的网格物体,材质贴图和灯光属性的设置来烘培场景，从而得到完美的光照贴图.</p><h3 id="Occlusion-遮挡剔除-视图"><a href="#Occlusion-遮挡剔除-视图" class="headerlink" title="Occlusion(遮挡剔除) 视图"></a>Occlusion(遮挡剔除) 视图</h3><p>Occlusion(遮挡剔除) 视图技术是指当一个物体被其他物体遮挡住,而不在摄像机的可视范围内时不对其进行渲染.</p><h3 id="Navigation-导航寻路-视图"><a href="#Navigation-导航寻路-视图" class="headerlink" title="Navigation(导航寻路)视图"></a>Navigation(导航寻路)视图</h3><p>导航寻路是游戏中常用的技术,通过点击场景上的一个位置,游戏角色就会自动寻路过去,行走过程中角色会自动绕过障碍物,最终到达终点.</p><h3 id="Version-Control-版本控制-视图"><a href="#Version-Control-版本控制-视图" class="headerlink" title="Version Control(版本控制)视图"></a>Version Control(版本控制)视图</h3><p>使用版本控制可以轻松回到某一个时间点的版本.<br>默认情况下Unity的版本控制是关闭的，可依次选择菜单栏中的Edit-&gt;Project Setting-&gt; Editor 命令，然后在Inspector视图中将Version Control 的Mode设置为Asset Server,接着按[Ctrl + 0]组合键即可打开Version Control视图.</p><h3 id="Asset-Store（资源商店"><a href="#Asset-Store（资源商店" class="headerlink" title="Asset Store（资源商店)"></a>Asset Store（资源商店)</h3><p>Unity的在线资源商店Asset Store拥有丰富的资源素材库,全球各地的开发者都在这里分享自己的工作成果,涵盖了材质，模型，动画，插件到完整的项目实例，可以在Unity编辑器里下载并直接导入项目工程.</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;unity编辑器&quot;&gt;&lt;a href=&quot;#unity编辑器&quot; class=&quot;headerlink&quot; title=&quot;unity编辑器&quot;&gt;&lt;/a&gt;unity编辑器&lt;/h2&gt;&lt;p&gt;Unity编辑器拥有非常直观，明了的界面布局，熟悉Unity界面是学习Unity的基础&lt;/p&gt;
    
    </summary>
    
    
      <category term="unity" scheme="http://www.zhz.gift/tags/unity/"/>
    
  </entry>
  
  <entry>
    <title>Scrapy 教程</title>
    <link href="http://www.zhz.gift/2018/05/23/Scrapy%20%E6%95%99%E7%A8%8B/"/>
    <id>http://www.zhz.gift/2018/05/23/Scrapy 教程/</id>
    <published>2018-05-23T15:09:42.000Z</published>
    <updated>2018-06-01T14:31:50.830Z</updated>
    
    <content type="html"><![CDATA[<p>在这个教程里面, 我们会假设Scrapy 已经安装在你的系统里面,如果还没安装的话，查看<a href="https://docs.scrapy.org/en/latest/intro/install.html#intro-install" target="_blank" rel="external">安装教程</a></p><a id="more"></a><p>我们准备爬取 <a href="">quotes.toscrape.com</a>，这个网站引用了许多知名作者的名言.</p><p>这个教程将通过下述任务带领你学习:</p><ol><li>创建一个新的Scrapy(爬虫)项目</li><li>编写一个<a href="https://docs.scrapy.org/en/latest/topics/spiders.html#topics-spiders" target="_blank" rel="external">spider</a> 来爬取网站和解析数据</li><li>使用命令行导出爬取的数据</li><li>使用spider 去递归超链接</li><li>使用spider 参数</li></ol><p>Scrapy 是使用<a href="https://www.python.org/" target="_blank" rel="external">Python</a>写的.</p><p>如果你已经熟悉其它语言，并且想要快速地学习Python,我们推荐你阅读<a href="http://www.diveintopython3.net/" target="_blank" rel="external">Dive Into Python3</a>.或者阅读<a href="https://docs.python.org/3/tutorial" target="_blank" rel="external">Python 教程</a>.</p><p>如果你是编程新手并且想要开始学习Python,你可能需要找到有用的网络书籍 <a href="https://learnpythonthehardway.org/book/" target="_blank" rel="external">Learn Python The Hard Way</a>. 你也可以同样看看<a href="https://wiki.python.org/moin/BeginnersGuide/NonProgrammers" target="_blank" rel="external"> this list of Python resources for non-programmers</a>.</p><h2 id="创建一个项目"><a href="#创建一个项目" class="headerlink" title="创建一个项目"></a>创建一个项目</h2><p>在你开始爬取数据之前，你必须去创建一个新的Scrpay 爬虫项目.进入到你想要存储代码的目录并且运行:</p><pre><code>scrapy startproject tutorial</code></pre><p>这将会创建一个<code>tutorial</code>目录并且包含以下内容:</p><pre><code>tutorial/    scrapy.cfg         #deploy configuration file    tutorial/          #project&apos;s Python module,you&apos;ll import your code from here        __init__.py        items.py       #project items definition file        middlewares.py #project middlewares file        piplines.py    #project pipelines file        settings.py       #project settings file        spiders/       #a directory where you&apos;ll later put your spiders            __init__.py</code></pre><h2 id="我们的第一只Spider-蜘蛛"><a href="#我们的第一只Spider-蜘蛛" class="headerlink" title="我们的第一只Spider 蜘蛛"></a>我们的第一只Spider 蜘蛛</h2><p>Spiders 是你定义的类，Scrapy 使用它们来从网站爬取信息(或者一系列的网站).它们必须是<code>scrapy.Spider</code>的子类, 并且定义初始化的请求, 比如怎样追踪页面的一些超链接, 还有怎样转换解析下载页面的内容数据.</p><p>如下是我们第一只Spider的代码. 保存到你项目路径下的<code>tutorial/spiders</code>目录下的<code>quotes_spider.py</code>文件中：</p><pre><code>import scrapyclass QuotesSpider(scrapy.Spider):    name = &quot;quotes&quot;    def start_requests(self):        urls = [            &apos;http://quotes.toscrape.com/page/1/&apos;,            &apos;http://quotes.toscrape.com/page/2/&apos;,        ]        for url in urls:            yield scrapy.Request(url=url,callback=self.parse)    def parse(self,response):        page = response.url.split(&quot;/&quot;)[-2]        filename = &apos;quotes-%s.html&apos; % page        with open(filename, &apos;2b&apos;) as f:            f.write(response.body)        self.log(&apos;Saved file %s&apos; % filename)</code></pre><p>正如你所看到的,我们的Spider 继承了 <code>scrapy.Spider</code> 并且定义了一些属性和方法:</p><ul><li><p><code>name</code>:Spider的唯一标识. 它必须在一个项目中保持唯一,这意味着,你不能在不同的Spiders之间使用同样的名称.</p></li><li><p><code>start_requests()</code>: 必须返回一个可迭代的Requests请求(你可以返回一个requests列表或者写一个生成器方法) ,Spider会使用它们来嗅探你想要的内容. 后续的requests请求将从这些初始请求中成功生成.</p></li><li><p><code>parse()</code> : 这个方法将用来处理每个成功请求响应下载的内容. 响应参数是<code>TextResponse</code> 的实例,这个实例持有整个页面的内容并且含有进一步的处理这些内容的方法.</p></li></ul><p><code>parse()</code> 方法通常用来转换reponse, 提取爬取的数据作为字段并且寻找新的URLs去追踪并且从它们那里创建新的请求.</p><h2 id="如何运行你的spider"><a href="#如何运行你的spider" class="headerlink" title="如何运行你的spider"></a>如何运行你的spider</h2><p>为了让我们的spider 工作, 回到项目的顶级目录并且运行:</p><pre><code>scrapy crawl quotes</code></pre><p>这个命令通过spider名称<code>quotes</code> 来运行我们刚刚添加的spider, 它将会发送一些请求到 <code>quotes.toscrape.com</code> 域名. 你将会收到的输出类似这样:</p><pre><code>... (omitted for brevity)2016-12-16 21:24:05 [scrapy.core.engine] INFO: Spider opened2016-12-16 21:24:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)2016-12-16 21:24:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:60232016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (404) &lt;GET http://quotes.toscrape.com/robots.txt&gt; (referer: None)2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://quotes.toscrape.com/page/1/&gt; (referer: None)2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://quotes.toscrape.com/page/2/&gt; (referer: None)2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-1.html2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-2.html2016-12-16 21:24:05 [scrapy.core.engine] INFO: Closing spider (finished)...</code></pre><p>现在，在当前目录检查文件.你应该能注意到两个新的文件已经被创建: quotes-1.html 和 quotes-2.html ,分别对应URLs请求的内容，并且通过<code>parse</code>方法进行了转换.</p><pre><code>Note如果你好奇为什么我们还没有转换HTML,稍等一下，我们很快会涉及到</code></pre><h2 id="在神秘面纱的掩盖下还发生了什么"><a href="#在神秘面纱的掩盖下还发生了什么" class="headerlink" title="在神秘面纱的掩盖下还发生了什么?"></a>在神秘面纱的掩盖下还发生了什么?</h2><p>Scrapy 通过 Spider的<code>start_requests</code>方法获得<strong><code>scrapy.Request</code></strong>对象.通过从每个请求接收到response,它会实例化<code>**Response**</code>对象并且调用与request相关联的回调方法(在这个例子中，就是<code>parse</code>方法),并且将response作为参数.</p><h2 id="start-requests-方法的一个捷径"><a href="#start-requests-方法的一个捷径" class="headerlink" title="start_requests 方法的一个捷径"></a>start_requests 方法的一个捷径</h2><p>相比实现<strong><code>start_requests()</code></strong>方法来从URLs生成<strong><code>scrapy.Request</code></strong>对象,你可以仅定义一个<strong><code>start_urls</code></strong>类属性来包含一个URLs列表. 这个泪飙将会被<strong><code>start_requests()</code></strong>的默认实现用来为你的spider创建默认请求:</p><pre><code>import scrapyclass QuotesSpider(scrapy.Spider):    name = &quot;quotes&quot;    start_urls = [        &apos;http://quotes.toscrape.com/page/1/&apos;,        &apos;http://quotes.toscrape.com/page/2/&apos;,    ]    def parse(self, response):        page = response.url.split(&quot;/&quot;)[-2]        filename = &apos;quotes-%s.html&apos; % page        with open(filename, &apos;wb&apos;) as f:            f.write(response.body)</code></pre><p><code>parse()</code>将用来处理那些URL所对应的请求,尽管我们没有明确指定Scrapy这样去做. 这是因为<code>parse()</code>方法是Scrapy的默认回调方法,用来处理那些没有明确指定回调方法的请求.</p><h2 id="提取数据"><a href="#提取数据" class="headerlink" title="提取数据"></a>提取数据</h2><p>学习使用Scrpay提取数据的最好方式是使用 <a href="https://doc.scrapy.org/en/latest/topics/shell.html#topics-shell" target="_blank" rel="external">Scrapy shell</a>.运行:</p><pre><code>scrapy shell &apos;http://quotes.toscrape.com/page/1/&apos;Note:当在命令行运行Scrapy shell的时候，记得要用引号闭合URL,否则url包含的参数(比如.`&amp;`带的参数)将不会工作.在Windows环境，使用双引号:scrapy shell &quot;http://quotes.toscrape.com/page/1/&quot;</code></pre><p>你将会看到如下输出:</p><pre><code>[ ... Scrapy log here ... ]2016-09-19 12:09:27 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://quotes.toscrape.com/page/1/&gt; (referer: None)[s] Available Scrapy objects:[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x7fa91d888c90&gt;[s]   item       {}[s]   request    &lt;GET http://quotes.toscrape.com/page/1/&gt;[s]   response   &lt;200 http://quotes.toscrape.com/page/1/&gt;[s]   settings   &lt;scrapy.settings.Settings object at 0x7fa91d888c10&gt;[s]   spider     &lt;DefaultSpider &apos;default&apos; at 0x7fa91c8af990&gt;[s] Useful shortcuts:[s]   shelp()           Shell help (print this help)[s]   fetch(req_or_url) Fetch request (or URL) and update local objects[s]   view(response)    View response in a browser&gt;&gt;&gt;</code></pre><p>使用shell，你可以通过使用response 对象的<a href="https://www.w3.org/TR/selectors" target="_blank" rel="external">CSS</a>语法来选择元素.</p><pre><code>&gt;&gt;&gt; response.css(&apos;title&apos;)[&lt;Selector xpath=&apos;descendant-or-self::title&apos; data=&apos;&lt;title&gt;Quotes to Scrape&lt;/title&gt;&apos;&gt;]</code></pre><p>运行<code>response.css(&#39;title&#39;)</code>的结果是一个类似列表的对象，命名为<strong><code>SelectorList</code></strong>,它代表了一个<strong><code>Selector</code></strong>对象列表，这些对象包含了XML/HTML元素并且允许你运行一些查询来获得更小粒度的选择器或者提取数据.</p><p>从上述的above提取text，如下:</p><pre><code>&gt;&gt;&gt; response.css(&apos;title::text&apos;).extract()[&apos;Quotes to Scrape&apos;]</code></pre><p>这里有两个我们需要注意的地方,其一是我们添加了<code>::text</code>到css查询,这意味着我们只想要选择在<code>&lt;title&gt;</code>元素中的text元素.如果我们不指定<code>::text</code>,我们将会会的这个title元素,包含它的tags:</p><pre><code>&gt;&gt;&gt; response.css(&apos;title&apos;).extract()[&apos;&lt;title&gt;Quotes to Scrape&lt;/title&gt;&apos;]</code></pre><p>另一件事就是调用的结果.<code>.extract()</code>是一个列表,因为我们处理的是<strong><code>SelectorList</code></strong>的实例.当你知道你仅仅只想要首个结果，就像在这个例子中,你可以这样做:</p><pre><code>&gt;&gt;&gt; response.css(&apos;title::text&apos;).extract_first()&apos;Quotes to Scrape&apos;</code></pre><p>或者:</p><pre><code>&gt;&gt;&gt; response.css(&apos;title::text&apos;)[0].extract()&apos;Quotes to Scrape&apos;</code></pre><p>然而,使用<code>.extract_first()</code> 避免了一个 <code>IndexError</code>错误 并且当它没有找到任何可匹配的元素时返回 <code>None</code>.</p><p>注意：对于大多数scraping 代码，你想要当在页面上查找不到你想要的数据而发生错误时显得更有弹性的话,所以即使有一些部分对scraped失败了,你至少可以获得<strong>部分</strong>数据.</p><p>除了<code>extract()</code>方法和 <code>extract_first()</code> 方法,你同样能使用<code>re()</code> 方法来使用正则表达式来提取数据:</p><pre><code>&gt;&gt;&gt; response.css(&apos;title::text&apos;).re(r&apos;Quotes.*&apos;)[&apos;Quotes to Scrape&apos;]&gt;&gt;&gt; response.css(&apos;title::text&apos;).re(r&apos;Q\w+&apos;)[&apos;Quotes&apos;]&gt;&gt;&gt; response.css(&apos;title::text&apos;).re(r&apos;(\w+) to (\w+)&apos;)[&apos;Quotes&apos;, &apos;Scrape&apos;]</code></pre><p>为了找到适当的CSS 选择器来使用,你可以通过<code>view(response)</code>来在浏览器直接打开响应页面. 你可以使用你的浏览器开发者工具或者扩展类似Firebug(详细查看<a href="https://doc.scrapy.org/en/latest/topics/firebug.html#topics-firebug" target="_blank" rel="external">Using Firebug for scraping</a> 和 <a href="https://doc.scrapy.org/en/latest/topics/firefox.html#topics-firefox" target="_blank" rel="external">Using Firefox for scraping</a>).</p><p><a href="http://selectorgadget.com/" target="_blank" rel="external">Selector Gadget</a>同样是一个能够快速找到CSS选择器的绝佳工具,在很多浏览器它都工作良好.</p><h2 id="Xpath-简要介绍"><a href="#Xpath-简要介绍" class="headerlink" title="Xpath:简要介绍"></a>Xpath:简要介绍</h2><p>除了<a href="https://www.w3.org/TR/selectors" target="_blank" rel="external">CSS</a>,Scrapy 选择器同样支持使用<a href="https://www.w3.org/TR/xpath" target="_blank" rel="external">XPath</a>表达式:</p><pre><code>&gt;&gt;&gt; response.xpath(&apos;//title&apos;)[&lt;Selector xpath=&apos;//title&apos; data=&apos;&lt;title&gt;Quotes to Scrape&lt;/title&gt;&apos;&gt;]&gt;&gt;&gt; response.xpath(&apos;//title/text()&apos;).extract_first()&apos;Quotes to Scrape&apos;</code></pre><p>XPath表达式功能非常强大,并且是Scrapy选择器的基础. 事实上,CSS选择器最后是转化为XPath表达式.</p><p>也许XPath没有CSS选择器那样受欢迎,但是XPath表达式提供更多强大的功能因为除了结构导航,它同样可以查看内容.使用XPath,你可以同样选中像如下的事物: 选中包含”Next Page”内容的超链接.这使得XPath 与scraping任务非常适宜,尽管你已经知道如何去操作CSS选择器我们仍然鼓励你去学习XPath,它会使得scraping更加容易.</p><p>我们不想再这个教程涉及太多XPath的内容,详情阅读<a href="https://doc.scrapy.org/en/latest/topics/selectors.html#topics-selectors" target="_blank" rel="external">using XPath with Scrapy Selectors here</a>. 学习更多XPath的内容，我们推荐<a href="http://zvon.org/comp/r/tut-XPath_1.html" target="_blank" rel="external">this tutorial to learn XPath through examples</a>或者<a href="http://plasmasturm.org/log/xpath101/" target="_blank" rel="external">this tutorial to learn “how to think in XPath”</a>.</p><h2 id="提取名言和作者"><a href="#提取名言和作者" class="headerlink" title="提取名言和作者"></a>提取名言和作者</h2><p>现在你大致了解如何选中和解析了,接下来完成从web页面解析名言的spider代码.</p><p><a href="">http://quotes.toscrape.com</a>页面的每个引用名言都被HTML元素包含，类似这样:</p><pre><code>&lt;div class=&quot;quote&quot;&gt;    &lt;span class=&quot;text&quot;&gt;“The world as we have created it is a process of our    thinking. It cannot be changed without changing our thinking.”&lt;/span&gt;    &lt;span&gt;        by &lt;small class=&quot;author&quot;&gt;Albert Einstein&lt;/small&gt;        &lt;a href=&quot;/author/Albert-Einstein&quot;&gt;(about)&lt;/a&gt;    &lt;/span&gt;    &lt;div class=&quot;tags&quot;&gt;        Tags:        &lt;a class=&quot;tag&quot; href=&quot;/tag/change/page/1/&quot;&gt;change&lt;/a&gt;        &lt;a class=&quot;tag&quot; href=&quot;/tag/deep-thoughts/page/1/&quot;&gt;deep-thoughts&lt;/a&gt;        &lt;a class=&quot;tag&quot; href=&quot;/tag/thinking/page/1/&quot;&gt;thinking&lt;/a&gt;        &lt;a class=&quot;tag&quot; href=&quot;/tag/world/page/1/&quot;&gt;world&lt;/a&gt;    &lt;/div&gt;&lt;/div&gt;</code></pre><p>在scrapy shell 中执行如下命令:</p><pre><code>$ scrapy shell &apos;http://quotes.toscrape.com&apos;</code></pre><p>我们获得一系列quote HTML元素的选择器:</p><pre><code>&gt;&gt;&gt; response.css(&quot;div.quote&quot;)</code></pre><p>上述查询返回的每个选择器允许我们运行更多查询来获得它们的子元素等.让我们将首个选择器复制给一个变量,这样我们能通过运行我们的CSS选择器来直接操作一个特别的 “名言引用”:</p><pre><code>&gt;&gt;&gt; quote = response.css(&quot;div.quote&quot;)[0]</code></pre><p>现在，通过我们刚刚创建的<code>quote</code>对象提取<code>title</code>,<code>author</code>和<code>tags</code> :</p><pre><code>&gt;&gt;&gt; title = quote.css(&quot;span.text::text&quot;).extract_first()&gt;&gt;&gt; title&apos;“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”&apos;&gt;&gt;&gt; author = quote.css(&quot;small.author::text&quot;).extract_first()&gt;&gt;&gt; author&apos;Albert Einstein&apos;</code></pre><p>使用<code>.extract()</code> 方法获取所有的tags:</p><pre><code>&gt;&gt;&gt; tags = quote.css(&quot;div.tags a.tag::text&quot;).extract()&gt;&gt;&gt; tags[&apos;change&apos;, &apos;deep-thoughts&apos;, &apos;thinking&apos;, &apos;world&apos;]</code></pre><p>现在我们可以迭代所有的名言引用元素，并且将它们放置到一个Python目录:</p><pre><code>&gt;&gt;&gt; for quote in response.css(&quot;div.quote&quot;):...     text = quote.css(&quot;span.text::text&quot;).extract_first()...     author = quote.css(&quot;small.author::text&quot;).extract_first()...     tags = quote.css(&quot;div.tags a.tag::text&quot;).extract()...     print(dict(text=text, author=author, tags=tags)){&apos;tags&apos;: [&apos;change&apos;, &apos;deep-thoughts&apos;, &apos;thinking&apos;, &apos;world&apos;], &apos;author&apos;: &apos;Albert Einstein&apos;, &apos;text&apos;: &apos;“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”&apos;}{&apos;tags&apos;: [&apos;abilities&apos;, &apos;choices&apos;], &apos;author&apos;: &apos;J.K. Rowling&apos;, &apos;text&apos;: &apos;“It is our choices, Harry, that show what we truly are, far more than our abilities.”&apos;}    ... a few more of these, omitted for brevity&gt;&gt;&gt;</code></pre><h2 id="在我们的spider中提取数据"><a href="#在我们的spider中提取数据" class="headerlink" title="在我们的spider中提取数据"></a>在我们的spider中提取数据</h2><p>现在让我们回到自己的spider.直到现在,它并不提取任何特别的数据，仅仅保存整个HTML页面到本地 .现在集成提取逻辑到我们的spider中。</p><p>一个Scrpay spider 通常生成很多包含从页面中解析出来的数据的字典. 为了实现这一点，我们使用<code>yield</code> Python 关键字在回调上,正如你在如下看到的那样:</p><pre><code>import scrapyclass QuotesSpider(scrapy.Spider):    name = &quot;quotes&quot;    start_urls = [        &apos;http://quotes.toscrape.com/page/1/&apos;,        &apos;http://quotes.toscrape.com/page/2/&apos;,    ]    def parse(self, response):        for quote in response.css(&apos;div.quote&apos;):            yield {                &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),                &apos;author&apos;: quote.css(&apos;small.author::text&apos;).extract_first(),                &apos;tags&apos;: quote.css(&apos;div.tags a.tag::text&apos;).extract(),            }</code></pre><p>如果你运行这只spider，它将会用日志输出如下数据:</p><pre><code>2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 http://quotes.toscrape.com/page/1/&gt;{&apos;tags&apos;: [&apos;life&apos;, &apos;love&apos;], &apos;author&apos;: &apos;André Gide&apos;, &apos;text&apos;: &apos;“It is better to be hated for what you are than to be loved for what you are not.”&apos;}2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 http://quotes.toscrape.com/page/1/&gt;{&apos;tags&apos;: [&apos;edison&apos;, &apos;failure&apos;, &apos;inspirational&apos;, &apos;paraphrased&apos;], &apos;author&apos;: &apos;Thomas A. Edison&apos;, &apos;text&apos;: &quot;“I have not failed. I&apos;ve just found 10,000 ways that won&apos;t work.”&quot;}</code></pre><h2 id="存储我们爬取的数据"><a href="#存储我们爬取的数据" class="headerlink" title="存储我们爬取的数据"></a>存储我们爬取的数据</h2><p>存储爬取数据的最简单方法是使用<a href="https://doc.scrapy.org/en/latest/topics/feed-exports.html#topics-feed-exports" target="_blank" rel="external">Feed exports</a>,使用如下命令:</p><pre><code>scrapy crawl quotes -o quotes.json</code></pre><p>这将会生成一个 <code>quotes.json</code>文件，包含所有爬取的items,序列化成<a href="https://en.wikipedia.org/wiki/JSON" target="_blank" rel="external">JSON</a>的形式.</p><p>因为一些历史上的原因，Scrapy 会将爬取的数据内容添加到所指定的文件后方，而不是直接重写覆盖. 如果你连续运行这个命令两次，并且在第二次命令之前没有移除这个文件，你将会获得拥有两份重复json数据的json文件.</p><p>其它的格式，像<a href="http://jsonlines.org/" target="_blank" rel="external">JSON Lines</a>:</p><pre><code>scrapy crawl quotes -o quotes.jl</code></pre><p><a href="http://jsonlines.org/" target="_blank" rel="external">JSON Lines</a>格式非常有用，因为它类似流那样,你可以轻松地在它后面添加新的记录行.当你同样运行两次它不会产生跟JSON格式一样的问题.同样的，由于每条记录都是一行，最后你可能要遍历一个巨大的文件,但是你不必在内存中完成所有事情,通过<a href="https://stedolan.github.io/jq" target="_blank" rel="external">JQ</a>可以在命令行完成这些事情.</p><p>在小型的项目中(类似这个教程),这可能足够了.然而，如果你想要使用scrapy完成更复杂的事情.你可以写一个<a href="https://doc.scrapy.org/en/latest/topics/item-pipeline.html#topics-item-pipeline" target="_blank" rel="external">Item Pipeline</a>.</p><p>当项目被创建的时候一个Item Pipelines 的占位符文件就已经被创建了，就在 <code>tutorial/pipelines.py</code> 目录下面.如果你只是想要存储scraped items 的话你不需要实现任何item pipelines .</p><h2 id="追踪超链接"><a href="#追踪超链接" class="headerlink" title="追踪超链接"></a>追踪超链接</h2><p>与在<a href="">http://quotes.toscrape.com</a>网站前两个页面爬取一些信息相比，你想要这个网站所有页面的名言引用.</p><p>现在你知道如何从这些页面提取数据.接下来让我们了解一下如何从它们追踪超链接:</p><p>我们要做的第一件事就是从页面解析我们想要追踪的超链接, 我们可以看到在下个页面有一个如下标记的超链接:</p><pre><code>&lt;ul class=&quot;pager&quot;&gt;    &lt;li class=&quot;next&quot;&gt;        &lt;a href=&quot;/page/2/&quot;&gt;Next &lt;span aria-hidden=&quot;true&quot;&gt;&amp;rarr;&lt;/span&gt;&lt;/a&gt;    &lt;/li&gt;&lt;/ul&gt;</code></pre><p>我们可以在shell中对其进行解析:</p><pre><code>&gt;&gt;&gt; response.css(&apos;li.next a&apos;).extract_first()&apos;&lt;a href=&quot;/page/2/&quot;&gt;Next &lt;span aria-hidden=&quot;true&quot;&gt;→&lt;/span&gt;&lt;/a&gt;&apos;</code></pre><p>这能获取 <code>a</code> 元素，但是我们想要的是 <code>href</code> 属性. Scrapy 支持CSS扩展能够让你选中属性内容,就像这样:</p><pre><code>&gt;&gt;&gt; response.css(&apos;li.next a::attr(href)&apos;).extract_first()&apos;/page/2/&apos;</code></pre><p>现在我们的spider 代码修改为能够自动追踪下个页面的超链接，并从它解析数据:</p><pre><code>import scrapyclass QuotesSpider(scrapy.Spider):    name = &quot;quotes&quot;    start_urls = [        &apos;http://quotes.toscrape.com/page/1/&apos;,    ]    def parse(self, response):        for quote in response.css(&apos;div.quote&apos;):            yield {                &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),                &apos;author&apos;: quote.css(&apos;small.author::text&apos;).extract_first(),                &apos;tags&apos;: quote.css(&apos;div.tags a.tag::text&apos;).extract(),            }        next_page = response.css(&apos;li.next a::attr(href)&apos;).extract_first()        if next_page is not None:            next_page = response.urljoin(next_page)            yield scrapy.Request(next_page, callback=self.parse)</code></pre><p>现在，在解析完数据之后, <code>parse()</code> 方法从下一个页面寻找超链接,使用<code>urljoin()</code> 方法创建完全路径的URL(因为超链接是相关的)并且yields 一个新的请求到下一个页面,注册它本身作为回调来处理下个页面的数据解析并且确保能爬取到所有页面的数据.</p><p>你在这里看到的就是Scrapy 追踪超链接的原理:<br>但你在一个回调方法中yield 一个请求,Scrapy 将会安排这个请求在发送并且请求完成后执行它所注册的回调方法.</p><p>通过这个原理, 你可以根据你定义的规则构建追踪超链接的负责爬取器,并且根据它访问的页面解析不同类型的数据.</p><p>在我们的例子中，它创建了一个一种循环，追踪所有到下个页面的超链接直到它不能再找到下一个位置 - 这对于爬取依赖分页的博客，论坛或者其它网站非常遍历.</p><h2 id="创建请求的捷径"><a href="#创建请求的捷径" class="headerlink" title="创建请求的捷径"></a>创建请求的捷径</h2><p>你可以直接通过<strong><code>response.follow</code></strong>创建请求:</p><pre><code>import scrapyclass QuotesSpider(scrapy.Spider):    name = &quot;quotes&quot;    start_urls = [        &apos;http://quotes.toscrape.com/page/1/&apos;,    ]    def parse(self, response):        for quote in response.css(&apos;div.quote&apos;):            yield {                &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),                &apos;author&apos;: quote.css(&apos;span small::text&apos;).extract_first(),                &apos;tags&apos;: quote.css(&apos;div.tags a.tag::text&apos;).extract(),            }        next_page = response.css(&apos;li.next a::attr(href)&apos;).extract_first()        if next_page is not None:            yield response.follow(next_page, callback=self.parse)</code></pre><p>与scrapy.Request不同, <code>response.follow</code> 直接支持关联的URL  不需要调用 urljoin. 需要注意的是 <code>response.follow</code> 只是返回一个Request实例; 你仍然需要 yield 这个请求.</p><p>你同样可以传递一个选择器到 <code>response.follow</code> 而不是一个string; 这个选择器需要解析必要的属性:</p><pre><code>for href in response.css(&apos;li.next a::attr(href)&apos;):    yield response.follow(href, callback=self.parse)</code></pre><p>对于 <code>&lt;a&gt;</code> 元素: <code>response.follow</code> 自动使用它们的href属性. 这样能进一步的简化代码:</p><pre><code>for a in response.css(&apos;li.next a&apos;):    yield response.follow(a, callback=self.parse)</code></pre><p><strong>Note:</strong></p><pre><code>`response.follow(response.css(&apos;li.next a&apos;))` 是无效的 ,因为`response.css` 返回一个所有a元素结果集的选择器列表对象,不是一个单独的选择器. 需要用一个 `for` 循环来处理上述的例子,或者 `response.follow(response.css(&apos;li.next a&apos;)[0]` 也可以.</code></pre><h2 id="更多的例子和模式"><a href="#更多的例子和模式" class="headerlink" title="更多的例子和模式"></a>更多的例子和模式</h2><p>这是另一个阐明回调和追踪超链接的spider,这次是为了爬取作者的信息:</p><pre><code>import scrapyclass AuthorSpider(scrapy.Spider):    name = &apos;author&apos;    start_urls = [&apos;http://quotes.toscrape.com/&apos;]    def parse(self, response):        # follow links to author pages        for href in response.css(&apos;.author + a::attr(href)&apos;):            yield response.follow(href, self.parse_author)        # follow pagination links        for href in response.css(&apos;li.next a::attr(href)&apos;):            yield response.follow(href, self.parse)    def parse_author(self, response):        def extract_with_css(query):            return response.css(query).extract_first().strip()        yield {            &apos;name&apos;: extract_with_css(&apos;h3.author-title::text&apos;),            &apos;birthdate&apos;: extract_with_css(&apos;.author-born-date::text&apos;),            &apos;bio&apos;: extract_with_css(&apos;.author-description::text&apos;),        }</code></pre><p>spider 将会从主页面开始,它将会追踪所有到作者页面的超链接并且调用<code>parse_author</code> 回掉方法来处理返回的每一个响应页面,并且同样追踪分页的超链接并调用<code>parse</code>回调方法如同之前的一样.</p><p>这里我们传递回调到 <code>response.follow</code> 作为位置参数来简化代码,它同样对 <code>scrapy.Request</code> 有效.</p><p><code>parse_author</code> 回调方法定义了一个工具方法用来解析和清理从CSS查询获得的数据并且最终 yields 一个包含作者数据的Python 字典.</p><p>另一个有趣的事情是,在这个示例中，即使有很多名言引用来自同一个作者，但是我们并不需要担心会访问同一个作者页面多次.因为默认情况下,scrapy 会过滤已经访问过的URL请求，来防止因为程序错误而过多访问服务器的问题. 这个配置可在 <strong><a href="https://doc.scrapy.org/en/latest/topics/settings.html#std:setting-DUPEFILTER_CLASS" target="_blank" rel="external">DUPEFILTER_CLASS</a></strong>中配置.</p><p>查看<a href="https://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.CrawlSpider" target="_blank" rel="external">CrawlSpider</a> 类，这是一个泛用的spider,实现了一些比较小的规则引擎，你可以在这个基础上开发自己的crawlers.</p><p>同时，一个普通的模式是从多个页面构建一个数据项,使用<a href="https://doc.scrapy.org/en/latest/topics/request-response.html#topics-request-response-ref-request-callback-arguments" target="_blank" rel="external">trick to pass additional data to the callbacks</a> 来实现.</p><h2 id="使用spider-参数"><a href="#使用spider-参数" class="headerlink" title="使用spider 参数"></a>使用spider 参数</h2><p>你可以通过使用 <code>-a</code> 选项在spider运行的时候附加命令行参数:</p><pre><code>scrapy crawl quotes -o quotes-humor.json -a tag=humor</code></pre><p>这些参数会被传递到 Spider 的 <code>__init__</code> 方法并且默认成为spider的属性》</p><p>在这里例子中, <code>tag</code> 参数可以通过 <code>self.tag</code> 进行调用, 你可以通过它来控制spider只爬取特定标签的的名言引用, 同时基于参数构建URL:</p><pre><code>import scrapyclass QuotesSpider(scrapy.Spider):    name = &quot;quotes&quot;    def start_requests(self):        url = &apos;http://quotes.toscrape.com/&apos;        tag = getattr(self, &apos;tag&apos;, None)        if tag is not None:            url = url + &apos;tag/&apos; + tag        yield scrapy.Request(url, self.parse)    def parse(self, response):        for quote in response.css(&apos;div.quote&apos;):            yield {                &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),                &apos;author&apos;: quote.css(&apos;small.author::text&apos;).extract_first(),            }        next_page = response.css(&apos;li.next a::attr(href)&apos;).extract_first()        if next_page is not None:            yield response.follow(next_page, self.parse)</code></pre><p>如果你传递 <code>tag=humor</code> 参数到spider，那么你将会注意到spider将会只访问 <code>humor</code> 标签的URL,比如 <code>http://quotes.toscrape.com/tag/humor</code>.</p><p>更多spider参数查看<a href="https://doc.scrapy.org/en/latest/topics/spiders.html#spiderargs" target="_blank" rel="external">learn more about handling spider arguments here</a>.</p><h2 id="下一步"><a href="#下一步" class="headerlink" title="下一步"></a>下一步</h2><p>这个教程只涉及Scrapy最基本的东西,还有一大坨没有被提及的新特性.查看<a href="https://doc.scrapy.org/en/latest/intro/overview.html#topics-whatelse" target="_blank" rel="external">还有啥?</a> ,在<a href="https://doc.scrapy.org/en/latest/intro/overview.html#intro-overview" target="_blank" rel="external">Scrapy at a glance</a>章节中快速查看比较重要的部分.</p><p>你可以继续从小节<a href="https://doc.scrapy.org/en/latest/index.html#section-basics" target="_blank" rel="external">Basic concepts</a>中知道更多关于命令行工具,spiders,selectors 选择器和其它在教程中没有涉及的东西比如 模块化爬取数据. 如果你更喜欢通过例子项目来学习，查看<a href="https://doc.scrapy.org/en/latest/intro/examples.html#intro-examples" target="_blank" rel="external">Examples</a>小节.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在这个教程里面, 我们会假设Scrapy 已经安装在你的系统里面,如果还没安装的话，查看&lt;a href=&quot;https://docs.scrapy.org/en/latest/intro/install.html#intro-install&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;安装教程&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="scrapy" scheme="http://www.zhz.gift/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>MySql binary log 二进制日志介绍</title>
    <link href="http://www.zhz.gift/2018/05/23/mysql%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%97%A5%E5%BF%97%E4%BB%8B%E7%BB%8D/"/>
    <id>http://www.zhz.gift/2018/05/23/mysql二进制日志介绍/</id>
    <published>2018-05-23T03:07:42.000Z</published>
    <updated>2018-05-23T14:34:30.324Z</updated>
    
    <content type="html"><![CDATA[<p><a href="#5.4.4.1">二进制日志格式</a><br><a href="#5.4.4.2">设置二进制日志格式</a><br><a href="#5.4.4.3">混合二进制日志格式</a><br><a href="#5.4.4.4">针对mysql数据库表变化的日志格式</a></p><a id="more"></a><p>二进制日志包含了描述数据库变化例如表创建操作或者表数据变化的“事件”。它同样包含了一些潜在性可能造成改变的statements声明事件(比如,,一个可能没有相应匹配的DELETE语句),除非使用了<code>row-based logging</code>.二进制日志同样包含了一些信息关于每个声明持有这些已更新数据的时间.MySql 的二进制日志存在两个重要的目的:</p><ul><li><p>为了复制，master 服务器上的二进制日志提供了一系列数据改变的记录到slave 从服务器.master 服务器发送包含这些事件的二进制日志给它的从服务器，通过执行这些事件，从服务器可以完成与master服务器同样的数据变更.详细查看<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-implementation.html" target="_blank" rel="external">Section 17.2, “Replication Implementation”</a>.</p></li><li><p>某些数据恢复操作需要使用二进制日志.在一个备份呗还原之后,二进制日志当中的事件在备份被重新执行之后将被记录.这些事件将随着数据库更新到备份完成的这个时间节点.详细查看<a href="https://dev.mysql.com/doc/refman/5.5/en/point-in-time-recovery.html" target="_blank" rel="external">Section 7.5, “Point-in-Time (Incremental) Recovery Using the Binary Log”</a>.</p></li></ul><p>二进制日志并不应用于像select 或者 show 这些不造成数据变更的声明.如果想要记录所有声明(比如，标记一个问题查询),使用<code>general query log</code>.详细查看<a href="https://dev.mysql.com/doc/refman/5.5/en/query-log.html" target="_blank" rel="external">Section 5.4.3, “The General Query Log”</a>.</p><p>运行的服务器如果开启了二进制日志功能会使性能稍微下降.但是，开启二进制日志来达到复制(从库)或者还原等操作，实际的好处是要远远超出的》</p><p>二进制日志需要收到保护(加密),因为日志记录的声明可能会包含密码.<a href="https://dev.mysql.com/doc/refman/5.5/en/password-logging.html" target="_blank" rel="external">Section 6.1.2.3, “Passwords and Logging”</a>.</p><p>下述的讨论描述了一些服务器选项和变量，用于设置二进制日志的一些操作和行为.完整的列表查看<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-options-binary-log.html" target="_blank" rel="external">Section 17.1.3.4, “Binary Log Options and Variables”</a>.</p><p>想要开启二进制日志,在启动服务器时需要添加<strong><a href="https://dev.mysql.com/doc/refman/5.5/en/replication-options-binary-log.html#option_mysqld_log-bin" target="_blank" rel="external">–log-bin[=base_name]</a></strong>选项.如果没有提供<strong>base_name</strong>选项,那么默认的名称的值将是在<code>-bin</code>之后的<code>pid-file</code>选项(默认将是主机名称).如果提供了<strong>base name</strong>,服务器将会在这个数据目录写入文件,除非<strong>base name</strong>前面有一个描述不同路径的绝对路径名.推荐明确地定义base name,而不是使用默认的主机名.详情查看<a href="https://dev.mysql.com/doc/refman/5.5/en/bugs.html" target="_blank" rel="external"> Section B.5.7, “Known Issues in MySQL”</a>.</p><p>如果你在日志名称提供一个扩展，(比如,<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-options-binary-log.html#option_mysqld_log-bin" target="_blank" rel="external">–log-bin=base_name.extension</a>),这个扩展就会被默默地无视并且移除.</p><p><a href="https://dev.mysql.com/doc/refman/5.5/en/mysqld.html" target="_blank" rel="external">mysqld</a>添加了一个数字扩展到二进制日志 base name 来生成二进制文件名称.每当服务器创建一个log file 这个数字都会增加, 因此会创建已排序的连续文件. 服务器会在启动或者刷新时按照规则创建新的文件.服务器同样会在当前日志大小达到设置的最大值时(<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-options-binary-log.html#sysvar_max_binlog_size" target="_blank" rel="external">max_binlog_size</a>)自动地创建一个二进制日志文件. 如果你使用大型事务，同时因为事务是一次性写入文件，不会发生分隔文件的情况，因此一个二进制文件超越最大限制的情况仍然是存在的.</p><p>为了持续跟踪哪个二进制文件已经被使用,<a href="https://dev.mysql.com/doc/refman/5.5/en/mysqld.html" target="_blank" rel="external">mysqld</a>创建了一个二进制索引日志文件,包含了所有已使用的二进制日志文件名称. 默认情况下，这个索引文件拥有与普通二进制日志文件同样的base name,只是会带有一个<strong>‘.index’</strong>的索引名称. 你可以通过<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-options-binary-log.html#option_mysqld_log-bin-index" target="_blank" rel="external">–log-bin-index[=file_name]</a>命令来改变索引文件的名称. 你不能在<code>mysqld</code>运行的时候手动编辑这个文件,因为那样做会让<code>mysqld</code>感到困惑啊喵！.</p><p><code>binary log file</code>二进制日志文件通常表现为独特的以数字顺序编号并且包含数据库事件的文件.<code>binary log</code> 二进制日志一般包含数字编号的二进制日志文件集合 及其索引文件.</p><p>一个拥有<a href="https://dev.mysql.com/doc/refman/5.5/en/privileges-provided.html#priv_super" target="_blank" rel="external">SUPER</a>权限的客户端能够通过命令<code>SET sql_log_bin=0</code>关闭它自身声明的二进制日志输出.详情查看<a href="https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html" target="_blank" rel="external"> Section 5.1.7, “Server System Variables”</a>.</p><p>记录在二进制日志当中的事件格式依赖于二进制记录格式.mysql支持三种日志格式,<code>row-based logging</code>,<code>statement-based logging</code> 和<code>mixed-base logging</code>. 使用的二进制记录格式取决于mysql的版本.更多日志记录格式的详情，查看<a href="https://dev.mysql.com/doc/refman/5.5/en/binary-log-formats.html" target="_blank" rel="external">Section 5.4.4.1, “Binary Logging Formats”</a>. 二进制日志格式的详细信息查看<a href="https://dev.mysql.com/doc/internals/en/binary-log.html" target="_blank" rel="external">MySQL Internals: The Binary Log</a>.</p><p>服务器视 <a href="https://dev.mysql.com/doc/refman/5.5/en/replication-options-binary-log.html#option_mysqld_binlog-do-db" target="_blank" rel="external">–binlog-do-db</a>命令和<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-options-binary-log.html#option_mysqld_binlog-ignore-db" target="_blank" rel="external">–binlog-ignore-db</a>命令等同于<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-options-slave.html#option_mysqld_replicate-do-db" target="_blank" rel="external">–replicate-do-db</a>和<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-options-slave.html#option_mysqld_replicate-ignore-db" target="_blank" rel="external">–replicate-ignore-db</a>.具体查看<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-rules-db-options.html" target="_blank" rel="external">Section 17.2.3.1, “Evaluation of Database-Level Replication and Binary Logging Options”</a>.</p><p>如果你是准备从一个NDB集群复制到一个单独的MySQL服务器,你必须认识到<a href="https://dev.mysql.com/doc/refman/5.5/en/mysql-cluster.html" target="_blank" rel="external">NDB</a>存储使用一些默认的二进制记录选项值(包括定义<code>NDB</code>的选项,比如<a href="https://dev.mysql.com/doc/refman/5.5/en/mysql-cluster-replication-conflict-resolution.html#option_mysqld_ndb-log-update-as-write" target="_blank" rel="external">–ndb-log-update-as-write</a>,区别于使用其它存储引擎. 如果不做出一些修正,这些不同的地方将引起master 和 slave 主从之间二进制日志的分歧. 更多查看<a href="https://dev.mysql.com/doc/refman/5.5/en/mysql-cluster-replication-issues.html#mysql-cluster-replication-ndb-to-non-ndb" target="_blank" rel="external">Replication from NDB to other storage engines</a> . 尤其是当你使用的是非事务性的存储引擎，比如在从库使用<a href="https://dev.mysql.com/doc/refman/5.5/en/myisam-storage-engine.html" target="_blank" rel="external">MyISAM</a>,详细查看<a href="https://dev.mysql.com/doc/refman/5.5/en/mysql-cluster-replication-issues.html#mysql-cluster-replication-ndb-to-nontransactional" target="_blank" rel="external">Replication from NDB to a nontransactional storage engine</a>.</p><p>一个用于复制的从服务器，默认不写入自己的二进制日志文件,任何数据的改变都是从主服务器master接收.为了记录这些改变,使用<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-options-slave.html#option_mysqld_log-slave-updates" target="_blank" rel="external">–log-slave-updates</a>选项及 <a href="https://dev.mysql.com/doc/refman/5.5/en/replication-options-binary-log.html#option_mysqld_log-bin" target="_blank" rel="external">–log-bin</a>选项(详情查看<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-options-slave.html" target="_blank" rel="external"> Section 17.1.3.3, “Replication Slave Options and Variables”</a>. 当一个slave 同样是在复制链上的另一个slave的master，那么这种情况正好适用.</p><p>你能通过<a href="https://dev.mysql.com/doc/refman/5.5/en/reset-master.html" target="_blank" rel="external">RESET MASTER</a>命令删除所有二进制日志文件,或者使用<a href="https://dev.mysql.com/doc/refman/5.5/en/purge-binary-logs.html" target="_blank" rel="external">PURGE BINARY LOGS</a>命令删除其中一部分.详情查看<a href="https://dev.mysql.com/doc/refman/5.5/en/reset.html" target="_blank" rel="external">Section 13.7.6.6, “RESET Syntax”</a>, 和 <a href="https://dev.mysql.com/doc/refman/5.5/en/purge-binary-logs.html" target="_blank" rel="external">Section 13.4.1.1, “PURGE BINARY LOGS Syntax”</a>.</p><p>如果你正在使用replication复制功能，那么你不应当在master上删除任何旧的二进制日志文件,除非你完全确认没有任何的从服务区需要去使用它们.比如，你的从服务器从来没有落后主服务器三天的日志差距，那么你可以在master上执行<a href="https://dev.mysql.com/doc/refman/5.5/en/mysqladmin.html" target="_blank" rel="external">mysqladmin flush-logs</a>命令，然后移除三天之前的所有旧日志.你可以手动移除文件,但是更好的选择是使用<a href="https://dev.mysql.com/doc/refman/5.5/en/purge-binary-logs.html" target="_blank" rel="external">PURGE BINARY LOGS</a>命令,它同时会为你安全地更新二进制日志索引文件.(同时还能添加一个日期参数). 详情查看<a href="https://dev.mysql.com/doc/refman/5.5/en/purge-binary-logs.html" target="_blank" rel="external">Section 13.4.1.1, “PURGE BINARY LOGS Syntax”</a>.</p><p>你可以通过<a href="https://dev.mysql.com/doc/refman/5.5/en/mysqlbinlog.html" target="_blank" rel="external">mysqlbinlog</a>工具来展示二进制日志文件的内容.当你想要通过日志重新运行声明来进行还原的操作这就很有用了.比如，你可以从二进制日志更新MySQL 服务器,如下:</p><pre><code>shell&gt; mysqlbinlog log_file | mysql -h server_name</code></pre><p><a href="https://dev.mysql.com/doc/refman/5.5/en/mysqlbinlog.html" target="_blank" rel="external">mysqlbinlog</a> 同样能用来展示复制从服务器的中继日志文件内容，因为它们是相同格式的二进制日志文件.更多<code>mysqlbinlog</code>工具及其如何使用的相关信息,查看<a href="https://dev.mysql.com/doc/refman/5.5/en/mysqlbinlog.html" target="_blank" rel="external">Section 4.6.7, “mysqlbinlog — Utility for Processing Binary Log Files”</a>.更多关于二进制日志和还原操作的相关信息,查看<a href="https://dev.mysql.com/doc/refman/5.5/en/point-in-time-recovery.html" target="_blank" rel="external">Section 7.5, “Point-in-Time (Incremental) Recovery Using the Binary Log”</a>.</p><p>二进制日志记录动作会在声明或者事务完成之后，但在任何锁释放或者任何提交完成之前 完成.这确保了日志是按照commit的顺序记录的.</p><p>非事务性表的更新事件会在执行之后立刻存储在二进制日志当中.</p><p>在一个未完成提交的事务当中,所有对事务性表的更新(<a href="https://dev.mysql.com/doc/refman/5.5/en/update.html" target="_blank" rel="external">UPDATE</a>,<a href="https://dev.mysql.com/doc/refman/5.5/en/delete.html" target="_blank" rel="external">DELETE</a>或者<a href="https://dev.mysql.com/doc/refman/5.5/en/insert.html" target="_blank" rel="external">INSERT</a>，比如<code>InnoDB</code>,都会被缓存,知道一个[COMMIT]（<a href="https://dev.mysql.com/doc/refman/5.5/en/commit.html）被服务器接收到" target="_blank" rel="external">https://dev.mysql.com/doc/refman/5.5/en/commit.html）被服务器接收到</a>. 在这个时候，<strong>mysqld</strong>会在<a href="https://dev.mysql.com/doc/refman/5.5/en/commit.html" target="_blank" rel="external">COMMIT</a>执行之前，将整个事务写进到二进制日志当中.</p><p>对非事务性表的变更无法回滚.如果一个包含非事务性表的变更的事务被回滚，整个事务会在<a href="https://dev.mysql.com/doc/refman/5.5/en/commit.html" target="_blank" rel="external">ROLLBACK</a>声明的最后被记录进日志来确保所有对表的变更都能被复制.</p><p>当一个控制事务的线程启动,它分配一个<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-options-binary-log.html#sysvar_binlog_cache_size" target="_blank" rel="external">binlog_cache_size</a>设置的buffer 给buffer statements声明.如果一个声明大于这个buffer,这个线程就会打开一个临时文件来存储这个线程. 临时文件将会被线程结束时被删除.</p><p><a href="https://dev.mysql.com/doc/refman/5.5/en/server-status-variables.html#statvar_Binlog_cache_use" target="_blank" rel="external">Binlog_cache_use</a> 状态变量展示了已经使用这个buffer(也可能同时使用了一个临时文件)来存储声明的事务的数量. <a href="https://dev.mysql.com/doc/refman/5.5/en/server-status-variables.html#statvar_Binlog_cache_disk_use" target="_blank" rel="external">Binlog_cache_disk_use</a> 状态变量展示了那些事务当中实际使用临时文件的数量. 这两个变量可以用来调整<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-options-binary-log.html#sysvar_binlog_cache_size" target="_blank" rel="external">binlog_cache_size</a>的大小以避免使用临时文件》</p><p><a href="https://dev.mysql.com/doc/refman/5.5/en/replication-options-binary-log.html#sysvar_max_binlog_cache_size" target="_blank" rel="external">max_binlog_cache_size</a> 系统变量(默认 4GB,同时也是最大值了)可以用来限制一个多声明事务使用的缓存总大小. 如果一个事务超过这个值很多字节,那么它会失败并且回滚,最小值是4096 个字节.</p><p>如果你正在使用二进制日志和<code>row based logging</code>格式,并发插入会被转换为普通插入比如:<code>CREATE ... SELECT</code> 或者 [INSERT … SELECT]声明.  这是为了确保能够通过应用日志正确的进行备份的还原操作. 如果你是使用<code>statement-based logging</code> 格式，原始的声明会被写入到日志当中.</p><p>二进制日志格式有一些已知的限制可能会影响从备份还原的操作.详细查看<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-features.html" target="_blank" rel="external">Section 17.4.1, “Replication Features and Issues”</a>.</p><p>保存程序的二进制日志已经完成，详细查看<a href="https://dev.mysql.com/doc/refman/5.5/en/stored-programs-logging.html" target="_blank" rel="external">Section 20.7, “Binary Logging of Stored Programs”</a>.</p><p>需要注意的是二进制日志格式在MySQL5.5版及其相近版本之间是有所差别的，原因是为了增强replication复制功能. 详细查看<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-compatibility.html" target="_blank" rel="external"> Section 17.4.2, “Replication Compatibility Between MySQL Versions”</a>.</p><p>当写入到<code>MyISAM</code> 表时，写入到二进制日志文件和二进制日志索引文件都是用的同一种方式. 详细查看<a href="https://dev.mysql.com/doc/refman/5.5/en/full-disk.html" target="_blank" rel="external">Section B.5.3.4, “How MySQL Handles a Full Disk”</a>.</p><p>默认情况下,二进制日志是不会在每次写入都同步到磁盘的.所以如果操作系统或者主机(不仅仅是MySQL服务器)宕机的话，这部分二进制日志包含的声明改变等都会丢失. 为了防止出现这个问题，你可以设置二进制日志每<strong><code>N</code></strong>次写入到二进制日志就会触发同步到磁盘的操作.  通过<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-options-binary-log.html#sysvar_sync_binlog" target="_blank" rel="external">sync_binlog</a>系统变量来进行设置.  详细查看<a href="https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html" target="_blank" rel="external"> Section 5.1.7, “Server System Variables”</a>. <code>sync_binlog</code>设置为 1 是最安全的值,但同时也是最慢的方式. 而且即使设置为1，同样也可能存在因为宕机而引起的表内容和二进制日志内容之间的不同步. 比如，如果你是使用<code>InnoDB</code> 表和 MySQL服务器来完成一个<a href="https://dev.mysql.com/doc/refman/5.5/en/commit.html" target="_blank" rel="external">COMMIT</a> 声明,它会把整个事务写入到二进制日志然后提交这个事务到<code>InnoDB</code>. 如果服务器在这两个操作之间宕机的话,事务会在<code>InnoDB</code>重启的时候被回滚,但是它同样会存在于二进制日志当中. 为了解决这个问题, 你需要把 <a href="https://dev.mysql.com/doc/refman/5.5/en/innodb-parameters.html#sysvar_innodb_support_xa" target="_blank" rel="external">–innodb_support_xa</a>设置为1. 尽管这个选项在InnoDB当中更适应于支持XA事务, 但它同样能确保二进制日志和InnoDB数据文件被同步.</p><p>为了这个设置提供的更大程度的安全性,MySQL 服务器应该同样被配置为在每个事务都同步二进制日志和<code>InnoDB</code>日志到磁盘. <code>InnoDB</code> 日志默认情况下是会同步的, <code>sync_binlog=1</code> 用来设置同步二进制日志. 这个选项影响的是当宕机重启之后,在完成事务回滚的过程中,MySQL服务器扫描最新的二进制日志文件来手机事务<strong><code>xid</code></strong>值并且在二进制文件当中计算最新有效的位点. MySQL服务器接着就会告诉<code>InnoDB</code> 去完成所有成功写入到二进制日志的 prepared transactions , 并且阶段二进制日志到最新的有效位点. 这能确保二进制日志反馈正确的<code>InnoDB</code>表数据. 并且因此,slave 服务器也会通过master 来同步(已经被回滚的声明不会再被slave服务器收到).</p><p>如果MySQL 服务器发现宕机还原情况下二进制日志比它实际应有的大小要小的话，那么它至少缺少了了一个成功的<code>InnoDB</code>提交事务. 如果<code>sync_binlog=1</code>设置为1的话这种情况就不应当会发生,然后 文件系统当它们被请求的时候会完成一次实际的同步(有些可能不会),所以服务器会打印一个错误信息 <strong>The binary log file_name is shorter than its expected size</strong>. 在这种情况下,二进制日志不再正确并且replication应当从一个全新的master’s data 快照重启.</p><p>下列系统变量会影响 replication slave,当转换二进制日志的时候:</p><ul><li><p><a href="https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html#sysvar_sql_mode" target="_blank" rel="external">sql_mode</a>(除了<a href="https://dev.mysql.com/doc/refman/5.5/en/sql-mode.html#sqlmode_no_dir_in_create" target="_blank" rel="external">NO_DIR_IN_CREATE</a> 模式是不支持replicated的;参考<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-features-variables.html" target="_blank" rel="external"> Section 17.4.1.38, “Replication and Variables”</a>)</p></li><li><p><a href="https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html#sysvar_foreign_key_checks" target="_blank" rel="external">foreign_key_checks</a></p></li><li><p><a href="https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html#sysvar_unique_checks" target="_blank" rel="external">unique_checks</a></p></li></ul><ul><li><p><a href="https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html#sysvar_character_set_client" target="_blank" rel="external">character_set_client</a></p></li><li><p><a href="https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html#sysvar_collation_connection" target="_blank" rel="external">collation_connection</a></p></li><li><p><a href="https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html#sysvar_collation_database" target="_blank" rel="external">collation_database</a></p></li><li><p><a href="https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html#sysvar_collation_server" target="_blank" rel="external">collation_server</a></p></li><li><p><a href="https://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html#sysvar_sql_auto_is_null" target="_blank" rel="external">sql_auto_is_null</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;#5.4.4.1&quot;&gt;二进制日志格式&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;#5.4.4.2&quot;&gt;设置二进制日志格式&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;#5.4.4.3&quot;&gt;混合二进制日志格式&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;#5.4.4.4&quot;&gt;针对mysql数据库表变化的日志格式&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="MySql" scheme="http://www.zhz.gift/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>Docker Java教程6：使用Swarm 模式部署应用</title>
    <link href="http://www.zhz.gift/2018/05/14/Docker%20Java%E6%95%99%E7%A8%8B6/"/>
    <id>http://www.zhz.gift/2018/05/14/Docker Java教程6/</id>
    <published>2018-05-14T15:09:42.000Z</published>
    <updated>2018-05-17T13:36:13.714Z</updated>
    
    <content type="html"><![CDATA[<p>Docker Engine 包含 swarm 模式 用来管理一个Docker Engines 的集群.Docker CLI 可以用来创建swarm,部署应用服务到swarm上,并且管理swarm的行为.完全的细节地址：<a href="https://docs.docker.com/engine/swarm/.在开始这个章节之前需要先了解一些重要的概念" target="_blank" rel="external">https://docs.docker.com/engine/swarm/.在开始这个章节之前需要先了解一些重要的概念</a>: <a href="https://docs.docker.com/engine/swarm/key-concepts/" target="_blank" rel="external">Swarm mode key concepts</a> </p><a id="more"></a><p><a href="#1.1">初始化 Swarm</a></p><p><a href="#1.2">多容器应用</a></p><p><a href="#1.3">验证在应用中的服务和容器</a></p><p><a href="#1.4">访问应用</a></p><p><a href="#1.5">停止应用</a></p><p><a href="#1.6">完全地移除应用</a></p><p>Swarm 是多个Docker Engines 的集群.但一般情况下我们只会运行一个单独节点的Swarm.</p><p>这个章节将会部署一个应用，在<a href="https://www.mysql.com/" target="_blank" rel="external">MySQL</a>的数据桶上提供一个 CRUD/REST 接口.这一点通过使用部署在<a href="http://wildfly.org/" target="_blank" rel="external">WildFly</a>上的Java EE应用 来访问数据库已经完成》</p><h2 id="1.1">初始化 Swarm</h2><p>使用如下命令初始化Swarm :</p><pre><code>docker swarm init</code></pre><p>这会启动一个 Swarm Manager.默认情况下,一个管理节点同样是一个worker,但是只能配置给一个manager.</p><p>使用<code>docker info</code>命令可以得到一些关于这个单节点集群的一些信息.</p><pre><code>Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 17Server Version: 17.09.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: p9a1tqcjh58ro9ucgtqxa2wgq Is Manager: true ClusterID: r3xdxly8zv82e4kg38krd0vog Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 192.168.65.2 Manager Addresses:  192.168.65.2:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0runc version: 3f2f8b84a77f73d38244dd690525642a72156c64init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.49-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 1.952GiBName: mobyID: TJSZ:O44Y:PWGZ:ZWZM:SA73:2UHI:VVKV:KLAH:5NPO:AXQZ:XWZD:6IRJDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 35 Goroutines: 142 System Time: 2017-10-05T20:57:14.037442426Z EventsListeners: 1Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false</code></pre><p>这个集群有一个节点，同时也是一个管理节点.默认情况下，管理节点也同样是一个worker 节点.这意味着容器能在这个节点上运行.</p><h2 id="1.2">多容器应用</h2><p>这个章节描述了如何使用 Docker Compose 在 Swarm 模式下使用 Docker CLI 来部署一个多容器应用.</p><p>创建一个新目录并且使用<code>cd</code>命令移动到此:</p><pre><code>mkdir webappcd webapp</code></pre><p>使用<a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch05-compose.adoc#configuration-file" target="_blank" rel="external">configuration file</a>创建一个新的Compose 定义文件 <code>docker-compose.yml</code>.</p><p>这个应用能够用如下命令启动:</p><pre><code>docker stack deploy --compose-file=docker-compose.yml webapp</code></pre><p>这里展示的输出如下:</p><pre><code>Ignoring deprecated options:container_name: Setting the container name is not supported.Creating network webapp_defaultCreating service webapp_dbCreating service webapp_web</code></pre><p>WildFly Swarm 和 MySQL services 在这个节点上启动.每个 service 有一个单独的容器. 如果Swarm 模式在多个节点上可用的话，那么所有容器将会通过这些节点进行分布式部署.</p><p>一个新的覆盖网络被创建.这可以通过<code>docker network ls</code>命令来验证.这个网络允许多个容器在不同的hosts上互相交互联系.</p><h2 id="1.3">验证在应用中的服务和容器</h2><p>使用<code>docker service ls</code>命令验证WildFly 和 MySQL 服务.</p><pre><code>ID                  NAME                MODE                REPLICAS            IMAGE                                   PORTSj21lwelj529f        webapp_db           replicated          1/1                 mysql:8                                 *:3306-&gt;3306/tcpm0m44axt35cg        webapp_web          replicated          1/1                 arungupta/docker-javaee:dockerconeu17   *:8080-&gt;8080/tcp,*:9990-&gt;9990/tcp</code></pre><p>使用<code>docker service inspect webapp_web</code> 命令取得更多细节:</p><pre><code>[    {        &quot;ID&quot;: &quot;m0m44axt35cgjetcjwzls7u9r&quot;,        &quot;Version&quot;: {            &quot;Index&quot;: 22        },        &quot;CreatedAt&quot;: &quot;2017-10-07T00:17:44.038961419Z&quot;,        &quot;UpdatedAt&quot;: &quot;2017-10-07T00:17:44.040746062Z&quot;,        &quot;Spec&quot;: {            &quot;Name&quot;: &quot;webapp_web&quot;,            &quot;Labels&quot;: {                &quot;com.docker.stack.image&quot;: &quot;arungupta/docker-javaee:dockerconeu17&quot;,                &quot;com.docker.stack.namespace&quot;: &quot;webapp&quot;            },            &quot;TaskTemplate&quot;: {                &quot;ContainerSpec&quot;: {                    &quot;Image&quot;: &quot;arungupta/docker-javaee:dockerconeu17@sha256:6a403c35d2ab4442f029849207068eadd8180c67e2166478bc3294adbf578251&quot;,                    &quot;Labels&quot;: {                        &quot;com.docker.stack.namespace&quot;: &quot;webapp&quot;                    },                    &quot;Privileges&quot;: {                        &quot;CredentialSpec&quot;: null,                        &quot;SELinuxContext&quot;: null                    },                    &quot;StopGracePeriod&quot;: 10000000000,                    &quot;DNSConfig&quot;: {}                },                &quot;Resources&quot;: {},                &quot;RestartPolicy&quot;: {                    &quot;Condition&quot;: &quot;any&quot;,                    &quot;Delay&quot;: 5000000000,                    &quot;MaxAttempts&quot;: 0                },                &quot;Placement&quot;: {                    &quot;Platforms&quot;: [                        {                            &quot;Architecture&quot;: &quot;amd64&quot;,                            &quot;OS&quot;: &quot;linux&quot;                        }                    ]                },                &quot;Networks&quot;: [                    {                        &quot;Target&quot;: &quot;bwnp1nvkkga68dirhp1ue7qey&quot;,                        &quot;Aliases&quot;: [                            &quot;web&quot;                        ]                    }                ],                &quot;ForceUpdate&quot;: 0,                &quot;Runtime&quot;: &quot;container&quot;            },            &quot;Mode&quot;: {                &quot;Replicated&quot;: {                    &quot;Replicas&quot;: 1                }            },            &quot;UpdateConfig&quot;: {                &quot;Parallelism&quot;: 1,                &quot;FailureAction&quot;: &quot;pause&quot;,                &quot;Monitor&quot;: 5000000000,                &quot;MaxFailureRatio&quot;: 0,                &quot;Order&quot;: &quot;stop-first&quot;            },            &quot;RollbackConfig&quot;: {                &quot;Parallelism&quot;: 1,                &quot;FailureAction&quot;: &quot;pause&quot;,                &quot;Monitor&quot;: 5000000000,                &quot;MaxFailureRatio&quot;: 0,                &quot;Order&quot;: &quot;stop-first&quot;            },            &quot;EndpointSpec&quot;: {                &quot;Mode&quot;: &quot;vip&quot;,                &quot;Ports&quot;: [                    {                        &quot;Protocol&quot;: &quot;tcp&quot;,                        &quot;TargetPort&quot;: 8080,                        &quot;PublishedPort&quot;: 8080,                        &quot;PublishMode&quot;: &quot;ingress&quot;                    },                    {                        &quot;Protocol&quot;: &quot;tcp&quot;,                        &quot;TargetPort&quot;: 9990,                        &quot;PublishedPort&quot;: 9990,                        &quot;PublishMode&quot;: &quot;ingress&quot;                    }                ]            }        },        &quot;Endpoint&quot;: {            &quot;Spec&quot;: {                &quot;Mode&quot;: &quot;vip&quot;,                &quot;Ports&quot;: [                    {                        &quot;Protocol&quot;: &quot;tcp&quot;,                        &quot;TargetPort&quot;: 8080,                        &quot;PublishedPort&quot;: 8080,                        &quot;PublishMode&quot;: &quot;ingress&quot;                    },                    {                        &quot;Protocol&quot;: &quot;tcp&quot;,                        &quot;TargetPort&quot;: 9990,                        &quot;PublishedPort&quot;: 9990,                        &quot;PublishMode&quot;: &quot;ingress&quot;                    }                ]            },            &quot;Ports&quot;: [                {                    &quot;Protocol&quot;: &quot;tcp&quot;,                    &quot;TargetPort&quot;: 8080,                    &quot;PublishedPort&quot;: 8080,                    &quot;PublishMode&quot;: &quot;ingress&quot;                },                {                    &quot;Protocol&quot;: &quot;tcp&quot;,                    &quot;TargetPort&quot;: 9990,                    &quot;PublishedPort&quot;: 9990,                    &quot;PublishMode&quot;: &quot;ingress&quot;                }            ],            &quot;VirtualIPs&quot;: [                {                    &quot;NetworkID&quot;: &quot;vysfza7wgjepdlutuwuigbws1&quot;,                    &quot;Addr&quot;: &quot;10.255.0.5/16&quot;                },                {                    &quot;NetworkID&quot;: &quot;bwnp1nvkkga68dirhp1ue7qey&quot;,                    &quot;Addr&quot;: &quot;10.0.0.4/24&quot;                }            ]        }    }]</code></pre><p>使用<code>docker service logs -f webapp_web</code>命令来查看service 的日志.</p><pre><code>webapp_web.1.lf3y5k7pkpt9@moby    | 00:17:47,296 INFO  [org.jboss.msc] (main) JBoss MSC version 1.2.6.Finalwebapp_web.1.lf3y5k7pkpt9@moby    | 00:17:47,404 INFO  [org.jboss.as] (MSC service thread 1-8) WFLYSRV0049: WildFly Core 2.0.10.Final &quot;Kenny&quot; startingwebapp_web.1.lf3y5k7pkpt9@moby    | 2017-10-07 00:17:48,636 INFO  [org.wildfly.extension.io] (ServerService Thread Pool -- 20) WFLYIO001: Worker &apos;default&apos; has auto-configured to 8 core threads with 64 task threads based on your 4 available processors. . .webapp_web.1.lf3y5k7pkpt9@moby    | 2017-10-07 00:17:56,619 INFO  [org.jboss.resteasy.resteasy_jaxrs.i18n] (ServerService Thread Pool -- 12) RESTEASY002225: Deploying javax.ws.rs.core.Application: class org.javaee.samples.employees.MyApplicationwebapp_web.1.lf3y5k7pkpt9@moby    | 2017-10-07 00:17:56,621 WARN  [org.jboss.as.weld] (ServerService Thread Pool -- 12) WFLYWELD0052: Using deployment classloader to load proxy classes for module com.fasterxml.jackson.jaxrs.jackson-jaxrs-json-provider:main. Package-private access will not work. To fix this the module should declare dependencies on [org.jboss.weld.core, org.jboss.weld.spi]webapp_web.1.lf3y5k7pkpt9@moby    | 2017-10-07 00:17:56,682 INFO  [org.wildfly.extension.undertow] (ServerService Thread Pool -- 12) WFLYUT0021: Registered web context: /webapp_web.1.lf3y5k7pkpt9@moby    | 2017-10-07 00:17:57,094 INFO  [org.jboss.as.server] (main) WFLYSRV0010: Deployed &quot;docker-javaee.war&quot; (runtime-name : &quot;docker-javaee.war&quot;)</code></pre><h2 id="1.4">访问应用</h2><p>现在 WildFly 和 MySQL 服务器已经被配置,接下来根据指定的ip地址进行访问:</p><pre><code>curl -v http://localhost:8080/resources/employees</code></pre><p>输出如下:</p><pre><code>*   Trying ::1...* TCP_NODELAY set* Connected to localhost (::1) port 8080 (#0)&gt; GET /resources/employees HTTP/1.1&gt; Host: localhost:8080&gt; User-Agent: curl/7.51.0&gt; Accept: */*&gt;&lt; HTTP/1.1 200 OK&lt; Connection: keep-alive&lt; Content-Type: application/xml&lt; Content-Length: 478&lt; Date: Sat, 07 Oct 2017 00:22:59 GMT&lt;* Curl_http_done: called premature == 0* Connection #0 to host localhost left intact&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;&lt;collection&gt;&lt;employee&gt;&lt;id&gt;1&lt;/id&gt;&lt;name&gt;Penny&lt;/name&gt;&lt;/employee&gt;&lt;employee&gt;&lt;id&gt;2&lt;/id&gt;&lt;name&gt;Sheldon&lt;/name&gt;&lt;/employee&gt;&lt;employee&gt;&lt;id&gt;3&lt;/id&gt;&lt;name&gt;Amy&lt;/name&gt;&lt;/employee&gt;&lt;employee&gt;&lt;id&gt;4&lt;/id&gt;&lt;name&gt;Leonard&lt;/name&gt;&lt;/employee&gt;&lt;employee&gt;&lt;id&gt;5&lt;/id&gt;&lt;name&gt;Bernadette&lt;/name&gt;&lt;/employee&gt;&lt;employee&gt;&lt;id&gt;6&lt;/id&gt;&lt;name&gt;Raj&lt;/name&gt;&lt;/employee&gt;&lt;employee&gt;&lt;id&gt;7&lt;/id&gt;&lt;name&gt;Howard&lt;/name&gt;&lt;/employee&gt;&lt;employee&gt;&lt;id&gt;8&lt;/id&gt;&lt;name&gt;Priya&lt;/name&gt;&lt;/employee&gt;&lt;/collection&gt;</code></pre><h2 id="1.5">停止应用</h2><p>如果你只是想临时性地停止应用，并保持已经被创建的networks，推荐的方式是将service replicas(服务副本)的数量设置为0.</p><pre><code>docker service scale webapp_db=0 webapp_web=0</code></pre><p>输出如下:</p><pre><code>webapp_db scaled to 0webapp_web scaled to 0Since --detach=false was not specified, tasks will be scaled in the background.In a future release, --detach=false will become the default.</code></pre><p>这特别有用尤其是堆具备一定体积而你又想保存数据的时候.它允许你再次启动堆,通过将replicas 的数设置为大于0的方式.</p><h2 id="1.6">完全地移除应用</h2><p>使用<code>docker stack rm webapp</code>命令关闭应用 :</p><pre><code>Removing service webapp_dbRemoving service webapp_webRemoving network webapp_default</code></pre><p>这会停止在每个service中的容器，并且移除services.这同样会删除这个应用中的所有网络通信.</p><p><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch06-swarm.adoc" target="_blank" rel="external">官方链接</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Docker Engine 包含 swarm 模式 用来管理一个Docker Engines 的集群.Docker CLI 可以用来创建swarm,部署应用服务到swarm上,并且管理swarm的行为.完全的细节地址：&lt;a href=&quot;https://docs.docker.com/engine/swarm/.在开始这个章节之前需要先了解一些重要的概念&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://docs.docker.com/engine/swarm/.在开始这个章节之前需要先了解一些重要的概念&lt;/a&gt;: &lt;a href=&quot;https://docs.docker.com/engine/swarm/key-concepts/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Swarm mode key concepts&lt;/a&gt; &lt;/p&gt;
    
    </summary>
    
    
      <category term="docker" scheme="http://www.zhz.gift/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker Java教程4：运行一个Docker 容器</title>
    <link href="http://www.zhz.gift/2018/05/10/Docker%20Java%E6%95%99%E7%A8%8B4%EF%BC%9A%E8%BF%90%E8%A1%8C%E4%B8%80%E4%B8%AADocker%20%E5%AE%B9%E5%99%A8/"/>
    <id>http://www.zhz.gift/2018/05/10/Docker Java教程4：运行一个Docker 容器/</id>
    <published>2018-05-10T15:09:42.000Z</published>
    <updated>2018-05-10T13:22:07.120Z</updated>
    
    <content type="html"><![CDATA[<p>使用Docker运行一个应用的方式就是运行一个容器.如果你考虑使用一个开源的软件,那么有很大的可能Docker Store 已经有对应的Docker 镜像了.Docker 客户端能够通过镜像名称轻松地运行这个容器.客户端首先会检查Docker Host是否存在这个镜像,如果存在，则直接运行容器，否则host会首先去下载镜像.</p><a id="more"></a><p><a href="#1">拉取镜像</a><br><a href="#2">运行容器</a><br><a href="#2.1">交互式地</a><br><a href="#2.2">隔离的容器</a><br><a href="#2.3">使用默认端口</a><br><a href="#2.4">使用指定的端口</a><br><a href="#2.5">部署一个war文件到应用服务器</a><br><a href="#3">停止容器</a><br><a href="#4">移除容器</a><br><a href="#5">端口映射的额外方式</a></p><h2 id="1">拉取镜像</h2><p>查看可用镜像:</p><pre><code>docker image ls</code></pre><p>输出如下:</p><pre><code>REPOSITORY                   TAG                 IMAGE ID            CREATED             SIZEhellojava                    latest              8d76bf5691c4        32 minutes ago      740MBhello-java                   latest              93b1180c5d91        36 minutes ago      740MBhelloworld                   2                   7fbedda27c66        41 minutes ago      1.13MB</code></pre><p>更多关于镜像的细节可以使用<code>docker image history jboss/wildfly</code>命令:</p><pre><code>IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT9adbdb00cded        8 days ago          /bin/sh -c #(nop)  CMD [&quot;/opt/jboss/wildfl...   0B&lt;missing&gt;           8 days ago          /bin/sh -c #(nop)  EXPOSE 8080/tcp              0B&lt;missing&gt;           8 days ago          /bin/sh -c #(nop)  USER [jboss]                 0B&lt;missing&gt;           8 days ago          /bin/sh -c #(nop)  ENV LAUNCH_JBOSS_IN_BAC...   0B</code></pre><h2 id="2">运行容器</h2><h3 id="2.1">交互式地</h3><p>以交互模式运行WildFly 容器.</p><pre><code>docker container run -it jboss/wildfly</code></pre><p>输出如下:</p><pre><code>=========================================================================  JBoss Bootstrap Environment  JBOSS_HOME: /opt/jboss/wildfly  JAVA: /usr/lib/jvm/java/bin/java. . .00:26:27,455 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0060: Http management interface listening on http://127.0.0.1:9990/management00:26:27,456 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0051: Admin console listening on http://127.0.0.1:999000:26:27,457 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0025: WildFly Full 10.1.0.Final (WildFly Core 2.2.0.Final) started in 3796ms - Started 331 of 577 services (393 services are lazy, passive or on-demand)</code></pre><p>这个输出说明服务器已经正常启动了,皮卡丘!</p><p>默认，Docker会运行在前台.<code>-i</code> 允许与STDIN(standard input,stdin是标准输入，一般指键盘输入到缓冲区里的东西)进行交互,<code>-t</code> 附加一个 TTY(通常使用tty来简称各种类型的终端设备terminal) 到进程. 两个开关能够合并为<code>-it</code>.</p><p>点击 Ctrl+C 来停止容器.</p><h3 id="2.2">隔离的容器</h3><p>以detached(隔离)模式启动容器:</p><pre><code>docker container run -d jboss/wildfly254418caddb1e260e8489f872f51af4422bc4801d17746967d9777f565714600</code></pre><p>这次使用<code>-d</code>来替换<code>-it</code>,以隔离模式来运行容器.</p><p>输出是一个唯一的id 分配给容器.通过<code>docker container logs &lt;CONTAINER_ID&gt;</code>命令可以查看容器的日志记录,<code>&lt;CONTAINER_ID&gt;</code> 代表容器的id.</p><p><code>docker container ls</code> 命令能够查看容器的状态:</p><pre><code>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES254418caddb1        jboss/wildfly       &quot;/opt/jboss/wildfl...&quot;   2 minutes ago       Up 2 minutes        8080/tcp            gifted_haibt</code></pre><p><code>docker container ls -a</code>命令能够查看主机上的所有容器.</p><h3 id="2.3">使用默认端口</h3><p>如果你想要容器接受请求链接,那么你需要在调用<code>docker run</code>命令时提供特殊的参数选项.否则，启动的容器无法被我们的浏览器所访问.我们需要再次停止它并且以不同的选项重新启动.</p><pre><code>docker container stop `docker container ps | grep wildfly | awk &apos;{print $1}&apos;`</code></pre><p>以如下命令重启容器:</p><pre><code>docker container run -d -P --name wildfly jboss/wildfly</code></pre><p><code>-P</code> 代表在Docker host 上暴露 对应的端口.另外,<code>--name</code>一般用来给予这个容器一个名称.这个名称可以用来查询更多关于容器的信息或作为一个id来停止它.通过<code>docker container ls</code>命令来验证容器名称:</p><pre><code>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                     NAMES89fbfbceeb56        jboss/wildfly       &quot;/opt/jboss/wildfl...&quot;   9 seconds ago       Up 8 seconds        0.0.0.0:32768-&gt;8080/tcp   wildfly</code></pre><p>端口映射显示在 PORTS列.通过<a href="http://localhost:32768地址防卫" target="_blank" rel="external">http://localhost:32768地址防卫</a> WildFly服务器.确保使用正确的端口来进行访问.</p><p>页面展示如下:</p><p>【我是图片】</p><h3 id="2.4">使用指定的端口</h3><p>停止并且移除最近运行的容器:</p><pre><code>docker container stop wildflydocker container rm wildfly</code></pre><p>也可以用<code>docker container rm -f wildfly</code>命令来同时完成停止和移除容器的工作.需要谨慎小心，因为<code>-f</code>使用<code>SIGKILL</code>来kill容器.</p><p>重启容器:</p><pre><code>docker container run -d -p 8080:8080 --name wildfly jboss/wildfly</code></pre><p>这种格式表示<code>-p hostPort:containerPort</code>.这允许我们访问主机上容器的特定端口.</p><p>现在通过<a href="http://localhost:8080" target="_blank" rel="external">http://localhost:8080</a> 链接来测试.确认运行正常，接着如下同样停止并移除容器.</p><h3 id="2.5">部署一个war文件到应用服务器</h3><p>现在你的应用服务器正在运行,接下来展示如何部署war包到上面.</p><p>创建一个新目录<code>hellojavaee</code>.用如下内容创建<code>Dockerfile</code>文件:</p><pre><code>FROM jboss/wildfly:latestRUN curl -L https://github.com/javaee-samples/javaee7-simple-sample/releases/download/v1.10/javaee7-simple-sample-1.10.war -o /opt/jboss/wildfly/standalone/deployments/javaee-simple-sample.war</code></pre><p>创建镜像:</p><pre><code>docker image build -t javaee-sample .</code></pre><p>启动容器:</p><pre><code>docker container run -d -p 8080:8080 --name wildfly javaee-sample</code></pre><p>访问网站路由：</p><pre><code>curl http://localhost:8080/javaee-simple-sample/resources/persons</code></pre><p>输出如下:</p><pre><code>&lt;persons&gt;    &lt;person&gt;        &lt;name&gt;        Penny        &lt;/name&gt;    &lt;/person&gt;&lt;/persons&gt;</code></pre><p>可选的:<code>brew install XML-Coreutils</code>命令将会在Mac上安装xml格式的工具.这个输出能够通过<code>xml-fmt</code>选项来展示格式化结果.</p><h2 id="3">停止容器</h2><p>通过容器id或者名称来停止容器:</p><pre><code>docker container stop &lt;CONTAINER ID&gt;docker container stop &lt;NAME&gt;</code></pre><p>停止所有正在运行的容器:</p><pre><code>docker container stop $(docker container ps -q)</code></pre><p>只停止已经退出的容器:</p><pre><code>docker container ps -a -f &quot;exited=-1&quot;</code></pre><h2 id="4">移除容器</h2><p>通过id或者名称移除指定的容器:</p><pre><code>docker container rm &lt;CONTAINER_ID&gt;docker container rm &lt;NAME&gt;</code></pre><p>通过表达式匹配来移除容器:</p><pre><code>docker container ps -a | grep wildfly | awk &apos;{print $1}&apos; | xargs docker container rm</code></pre><p>无条件移除所有容器:</p><pre><code>docker container rm $(docker container ps -aq)</code></pre><h2 id="5">端口映射的额外方式</h2><p>确切的端口映射能够通过docker port命令进行设置:</p><pre><code>docker container port &lt;CONTAINER_ID&gt; or &lt;NAME&gt;</code></pre><p>输出如下:</p><pre><code>8080/tcp -&gt; 0.0.0.0:8080</code></pre><p>端口映射情况能够通过docker inspect命令进行查看:</p><pre><code>docker container inspect --format=&apos;{{(index (index .NetworkSettings.Ports "8080/tcp") 0).HostPort}}&apos; &lt;CONTAINER ID&gt;</code></pre><p><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch04-run-container.adoc" target="_blank" rel="external">官网链接</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用Docker运行一个应用的方式就是运行一个容器.如果你考虑使用一个开源的软件,那么有很大的可能Docker Store 已经有对应的Docker 镜像了.Docker 客户端能够通过镜像名称轻松地运行这个容器.客户端首先会检查Docker Host是否存在这个镜像,如果存在，则直接运行容器，否则host会首先去下载镜像.&lt;/p&gt;
    
    </summary>
    
    
      <category term="docker" scheme="http://www.zhz.gift/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker java教程3.2: 使用JDK9 构建 Docker 镜像</title>
    <link href="http://www.zhz.gift/2018/05/10/Docker%20java%E6%95%99%E7%A8%8B3.2_%20%E4%BD%BF%E7%94%A8JDK9%20%E6%9E%84%E5%BB%BA%20Docker%20%E9%95%9C%E5%83%8F/"/>
    <id>http://www.zhz.gift/2018/05/10/Docker java教程3.2_ 使用JDK9 构建 Docker 镜像/</id>
    <published>2018-05-10T15:09:42.000Z</published>
    <updated>2018-05-10T13:32:20.628Z</updated>
    
    <content type="html"><![CDATA[<p>目的: 这个章节解释了如何使用JDK9 创建Docker 镜像.</p><p><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch03-build-image.adoc" target="_blank" rel="external">之前的章节</a>中讲解了通常情况下Docker镜像的创建方法，这一章节在之前的基础上进行了扩展，主要关注JDK9 的特性.</p><a id="more"></a><p><a href="#1.1">使用JDK9 创建Docker镜像</a><br><a href="#1.2">使用JDK9 和 Alpine Linux 创建Docker镜像</a><br><a href="#1.3">使用JDK9  创建Docker镜像 和 Java应用</a><br><a href="#1.4">使用JDK9  为Docker镜像 和 Java应用 瘦身</a></p><h2 id="1.1">使用JDK9 创建Docker镜像</h2><p>创建一个目录，比如:<code>docker-jdk9</code>.</p><p>在那个目录,创建一个新的text文件<code>jdk-9-debian-slim.Dockerfile</code>. 内容如下:</p><pre><code># A JDK 9 with Debian slimFROM debian:stable-slim# Download from http://jdk.java.net/9/# ADD http://download.java.net/java/GA/jdk9/9/binaries/openjdk-9_linux-x64_bin.tar.gz /optADD openjdk-9_linux-x64_bin.tar.gz /opt# Set up env variablesENV JAVA_HOME=/opt/jdk-9ENV PATH=$PATH:$JAVA_HOME/binCMD [&quot;jshell&quot;, &quot;-J-XX:+UnlockExperimentalVMOptions&quot;, \               &quot;-J-XX:+UseCGroupMemoryLimitForHeap&quot;, \               &quot;-R-XX:+UnlockExperimentalVMOptions&quot;, \               &quot;-R-XX:+UseCGroupMemoryLimitForHeap&quot;]</code></pre><p>这个镜像使用debian slim 作为基础镜像 并且安装对应 linxu x64 版本的OpenJDK(查看<a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch01-setup.adoc" target="_blank" rel="external">设置章节</a>了解如何下载到当前目录.</p><p>镜像默认配置为运行 <code>jshell</code>，即 Java REPL(REPL — 交互式解释器环境。<br>R(read)、E(evaluate)、P(print)、L(loop)).了解更多<a href="https://docs.oracle.com/javase/9/jshell/introduction-jshell.htm" target="_blank" rel="external">关于JShell的介绍</a>.实验性的标志参数<code>-XX:+UseCGroupMemoryLimitForHeap</code> 传递到REPL进程(前端管理用户输入的进程以及后端管理编译的Java进程).这个选项会确保容器内存约束是有效的.</p><p>使用如下命令构建镜像:</p><pre><code>docker image build -t jdk-9-debian-slim -f jdk-9-debian-slim.Dockerfile .</code></pre><p>使用<code>docker image ls</code>命令展示可用镜像:</p><pre><code>REPOSITORY              TAG                 IMAGE ID            CREATED             SIZEjdk-9-debian-slim       latest              023f6999d94a        4 hours ago         400MBdebian                  stable-slim         d30525fb4ed2        4 days ago          55.3MB</code></pre><p>JDK9 和 JDK8之间最大的不同被认为是大小的不同,因为JDK 9提供 Java modules,这一点我们将在之后的章节看到.</p><p>使用如下命令运行容器:</p><pre><code>docker container run -m=200M -it --rm jdk-9-debian-slim</code></pre><p>输出如下:</p><pre><code>INFO: Created user preferences directory.|  Welcome to JShell -- Version 9|  For an introduction type: /help introjshell&gt;</code></pre><p>在Java REPL 中输入如下表达式来查询Java进程的可用内存:</p><pre><code>Runtime.getRuntime().maxMemory() / (1 &lt;&lt; 20)  </code></pre><p>输出:</p><pre><code>jshell&gt; Runtime.getRuntime().maxMemory() / (1 &lt;&lt; 20)$1 ==&gt; 100</code></pre><p>需要注意的是Java进程受限于内存约束(<code>--memory</code> of <code>docker container run</code>)并且在指定范围之外将不会为容器分配内存.</p><p>在未来的JDK版本将不再需要指定一个特殊标识(<code>-XX:+UnlockExperimentalVMOptions</code>)，一旦检测到哪个内存约束是稳定有效的，将会自动应用.</p><p>JDK9支持 set CUPs 约束(<code>--cpuset-cpus</code> of <code>docker container run</code>)但是当前不支持其它CPU约束，比如CPU shares.这是 OpenJDK project 正在进行的工作<a href="http://openjdk.java.net/jeps/8182070" target="_blank" rel="external">跟进</a>.</p><p>注意: CPU sets 和 内存约束同样被移植到 JDK 8 release 8u131 及其以上的版本.</p><p>输入<code>Ctrl</code> + <code>D</code>来退出<code>jshell</code>.</p><p>展示所有的JDK 9 Java 模块 分布 运行如下命令：</p><pre><code>docker container run -m=200M -it --rm jdk-9-debian-slim java --list-modules</code></pre><p>输出如下:</p><pre><code>java.activation@9java.base@9java.compiler@9java.corba@9java.datatransfer@9java.desktop@9java.instrument@9java.logging@9java.management@9java.management.rmi@9java.naming@9java.prefs@9java.rmi@9java.scripting@9java.se@9java.se.ee@9java.security.jgss@9java.security.sasl@9java.smartcardio@9java.sql@9java.sql.rowset@9java.transaction@9java.xml@9java.xml.bind@9java.xml.crypto@9java.xml.ws@9java.xml.ws.annotation@9jdk.accessibility@9jdk.aot@9jdk.attach@9jdk.charsets@9jdk.compiler@9jdk.crypto.cryptoki@9jdk.crypto.ec@9jdk.dynalink@9jdk.editpad@9jdk.hotspot.agent@9jdk.httpserver@9jdk.incubator.httpclient@9jdk.internal.ed@9jdk.internal.jvmstat@9jdk.internal.le@9jdk.internal.opt@9jdk.internal.vm.ci@9jdk.internal.vm.compiler@9jdk.jartool@9jdk.javadoc@9jdk.jcmd@9jdk.jconsole@9jdk.jdeps@9jdk.jdi@9jdk.jdwp.agent@9jdk.jlink@9jdk.jshell@9jdk.jsobject@9jdk.jstatd@9jdk.localedata@9jdk.management@9jdk.management.agent@9jdk.naming.dns@9jdk.naming.rmi@9jdk.net@9jdk.pack@9jdk.policytool@9jdk.rmic@9jdk.scripting.nashorn@9jdk.scripting.nashorn.shell@9jdk.sctp@9jdk.security.auth@9jdk.security.jgss@9jdk.unsupported@9jdk.xml.bind@9jdk.xml.dom@9jdk.xml.ws@9jdk.zipfs@9  </code></pre><p>总计75个模块：</p><pre><code>$ docker container run -m=200M -it --rm jdk-9-debian-slim java --list-modules | wc -l  75</code></pre><h2 id="1.2">使用JDK9 和 Alpine Linux 创建Docker镜像</h2>      <p>与使用debian 作为基础镜像相比,使用Alpine Linux JDK 9 的先行版本能够与muslc 库兼容.</p><p>创建一个新的text文件 jdk-9-alpine.Dockerfile.使用如下内容:</p><pre><code># A JDK 9 with Alpine LinuxFROM alpine:3.6# Add the musl-based JDK 9 distributionRUN mkdir /opt# Download from http://jdk.java.net/9/# ADD http://download.java.net/java/jdk9-alpine/archive/181/binaries/jdk-9-ea+181_linux-x64-musl_bin.tar.gzADD jdk-9-ea+181_linux-x64-musl_bin.tar.gz /opt# Set up env variablesENV JAVA_HOME=/opt/jdk-9ENV PATH=$PATH:$JAVA_HOME/binCMD [&quot;jshell&quot;, &quot;-J-XX:+UnlockExperimentalVMOptions&quot;, \               &quot;-J-XX:+UseCGroupMemoryLimitForHeap&quot;, \               &quot;-R-XX:+UnlockExperimentalVMOptions&quot;, \               &quot;-R-XX:+UseCGroupMemoryLimitForHeap&quot;]</code></pre><p>这个镜像将alpine 3.6 作为基础镜像并且安装相应版本的OpenJDK.(查看<a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch01-setup.adoc" target="_blank" rel="external">环境变量设置章节</a>了解如何下载到当前目录.</p><p>这个镜像配置的方式与debian 基础镜像相同.</p><p>使用如下命令构建镜像:</p><pre><code>docker image build -t jdk-9-alpine -f jdk-9-alpine.Dockerfile .</code></pre><p>使用<code>docker image ls</code>展示可用镜像:</p><pre><code>REPOSITORY              TAG                 IMAGE ID            CREATED             SIZEjdk-9-debian-slim       latest              023f6999d94a        4 hours ago         400MBjdk-9-alpine            latest              f5a57382f240        4 hours ago         356MBdebian                  stable-slim         d30525fb4ed2        4 days ago          55.3MBalpine                  3.6                 7328f6f8b418        3 months ago        3.97MB</code></pre><p>注意各个镜像大小的不同.Alpine Linux 被小心地设计为一个迷你型的可运行OS镜像.这个设计的的一部分开销在于可选择的标准库<a href="https://www.musl-libc.org/" target="_blank" rel="external">musl libc</a>,这个库与C标准库(libc)不兼容,因此JDK需要进行一些改造来运行Alpine Linux.这些改动已经被OpenJDK <a href="http://openjdk.java.net/projects/portola/" target="_blank" rel="external">Portola Project</a>提出.</p><h2 id="1.3">使用JDK9  创建Docker镜像 和 Java应用</h2>   <p>Clone  GitHib 项目 <a href="https://github.com/PaulSandoz/helloworld-java-9" target="_blank" rel="external">https://github.com/PaulSandoz/helloworld-java-9</a> ,这个项目包含了一个Java基础项目示例:</p><p>进入 helloworld-java-9的目录并且在一个正在运行的Docker 容器 使用JDK9 构建这个项目:</p><pre><code>docker container run --volume $PWD:/helloworld-java-9 --workdir /helloworld-java-9 \-it --rm openjdk:9-jdk-slim \./mvnw package</code></pre><p>(如果你在主机系统本地已经安装了JDK 9,你可以直接通过 <code>./mvnw package</code> 命令进行构建.)</p><p>在这个示例我们直接使用Docker hub 的 <code>openjdk:9-jdk-slim</code>,它已经配置了SSL证书,这样我们能直接通过maven wrapper tool 成功下载 maven 工具. 这个镜像是非官方的并且不以任何形式被 OpenJDK 项目支持(不像 JDK 9 distributions 在最近已经被依赖).相信在未来OpenJDK project发布的JDK版本，将会有root CA 证书(查看<a href="https://bugs.openjdk.java.net/browse/JDK-8189131" target="_blank" rel="external">issue JDK-8189131</a>)</p><p>使用文件 helloworld-jdk-9.Dockerfile 来将这个应用构建为Docker 镜像.<br>文件内容如下:</p><pre><code># Hello world application with JDK 9 and Debian slimFROM jdk-9-debian-slimCOPY target/helloworld-1.0-SNAPSHOT.jar /opt/helloworld/helloworld-1.0-SNAPSHOT.jar# Set up env variablesCMD java -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap \  -cp /opt/helloworld/helloworld-1.0-SNAPSHOT.jar org.examples.java.App</code></pre><p>基于<code>jdk-9-debian-slim</code>构建一个包含示例Java应用的Docker 镜像:</p><pre><code>docker image build -t helloworld-jdk-9 -f helloworld-jdk-9.Dockerfile .</code></pre><p>使用<code>docker image ls</code>命令展示可用镜像:</p><pre><code>REPOSITORY              TAG                 IMAGE ID            CREATED              SIZEhelloworld-jdk-9        latest              eb0539e9529a        19 seconds ago       400MBjdk-9-debian-slim       latest              023f6999d94a        5 hours ago          400MBjdk-9-alpine            latest              f5a57382f240        5 hours ago          356MBopenjdk                 9-jdk-slim          6dca67f4790e        3 days ago           372MBdebian                  stable-slim         d30525fb4ed2        4 days ago           55.3MBalpine                  3.6                 7328f6f8b418        3 months ago         3.97MB</code></pre><p>注意下 应用镜像 <code>helloworld-jdk-9</code>究竟有多大.</p><p>运行<code>jdeps</code>工具来查看应用所依赖的模块:</p><pre><code>docker container run -it --rm helloworld-jdk-9 jdeps --list-deps /opt/helloworld/helloworld-1.0-SNAPSHOT.jar</code></pre><p>可以观察到应用只依赖<code>java.base</code>模块.</p><h2 id="1.4">使用JDK9  为Docker镜像 和 Java应用 瘦身</h2>   <p>这个Java应用相当简单并且只使用了JDK 9 发行版本的少量函数,特别是这个应用使用函数只依赖<code>java.base</code>模块.我们可以创建一个只包含<code>java.base</code> 模块的自定义Java runtime 并且包含到 应用的Docker 镜像当中.</p><p>创建一个只包含<code>java.base</code>模块的自定义Java runtime:</p><pre><code>docker container run --rm \  --volume $PWD:/out \  jdk-9-debian-slim \  jlink --module-path /opt/jdk-9/jmods \    --verbose \    --add-modules java.base \    --compress 2 \    --no-header-files \    --output /out/target/openjdk-9-base_linux-x64</code></pre><p><a href="https://github.com/PaulSandoz/helloworld-java-9" target="_blank" rel="external">helloworld-java-9</a>项目中已存在对应的脚本.</p><p>JDK 9 工具 <code>jlink</code> 一般用来创建自定义 Java 运行时.了解更多关于jlink点击<a href="https://docs.oracle.com/javase/9/tools/jlink.htm" target="_blank" rel="external">Tools Reference</a>.<br>这个工具在模块所属的包含JDK 9 及其目录的容器当中执行,/opt/jdk-9/jmods,定义的是模块的路径.<br>This command exists as create-minimal-java-runtime.sh script in the repo earlier checked out from helloworld-java-9.只有<code>java.base</code>模块被选中.</p><p>自定义runtime 被输出到目标路径:</p><pre><code>$ du -k target/openjdk-9-base_linux-x64/24      target/openjdk-9-base_linux-x64//bin12      target/openjdk-9-base_linux-x64//conf/security/policy/limited8       target/openjdk-9-base_linux-x64//conf/security/policy/unlimited24      target/openjdk-9-base_linux-x64//conf/security/policy68      target/openjdk-9-base_linux-x64//conf/security76      target/openjdk-9-base_linux-x64//conf44      target/openjdk-9-base_linux-x64//legal/java.base44      target/openjdk-9-base_linux-x64//legal72      target/openjdk-9-base_linux-x64//lib/jli16      target/openjdk-9-base_linux-x64//lib/security19824   target/openjdk-9-base_linux-x64//lib/server31656   target/openjdk-9-base_linux-x64//lib31804   target/openjdk-9-base_linux-x64/  </code></pre><p>使用<code>helloworld-jdk-9-base.Dockerfile</code>文件构建Docker 镜像.文件内容如下:</p><pre><code># Hello world application with custom Java runtime with just the base module and Debian slimFROM debian:stable-slimCOPY target/openjdk-9-base_linux-x64 /opt/jdk-9COPY target/helloworld-1.0-SNAPSHOT.jar /opt/helloworld/helloworld-1.0-SNAPSHOT.jar# Set up env variablesENV JAVA_HOME=/opt/jdk-9ENV PATH=$PATH:$JAVA_HOME/binCMD java -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap \  -cp /opt/helloworld/helloworld-1.0-SNAPSHOT.jar org.examples.java.App</code></pre><p>以 debian:stable-slim作为基础镜像，创建示例Java应用的Docker镜像:</p><pre><code>docker image build -t helloworld-jdk-9-base -f helloworld-jdk-9-base.Dockerfile .  </code></pre><p>再度展示可用镜像L<code>docker image ls</code>:    </p><pre><code>REPOSITORY              TAG                 IMAGE ID            CREATED             SIZEhelloworld-jdk-9-base   latest              7052483fdb77        24 seconds ago      87.7MBhelloworld-jdk9         latest              eb0539e9529a        17 minutes ago      400MBjdk-9-debian-slim       latest              023f6999d94a        5 hours ago         400MBjdk-9-alpine            latest              f5a57382f240        5 hours ago         356MBopenjdk                 9-jdk-slim          6dca67f4790e        3 days ago          372MBdebian                  stable-slim         d30525fb4ed2        4 days ago          55.3MBalpine                  3.6                 7328f6f8b418        3 months ago        3.97MB[source, text]</code></pre><p><code>helloworld-jdk-9-base</code> 体积要小得多，并且如果Alpine Linux 使用Debian Slim,体积还能进一步缩小.</p><p>一个真实的应用会依赖更多的JDK 模块，但是仍然有可能通过只依赖必须模块的方式来减小Java runtime的体积(比如很多应用就并不需要Corba 或者RMI的编译工具模块).</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;目的: 这个章节解释了如何使用JDK9 创建Docker 镜像.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch03-build-image.adoc&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;之前的章节&lt;/a&gt;中讲解了通常情况下Docker镜像的创建方法，这一章节在之前的基础上进行了扩展，主要关注JDK9 的特性.&lt;/p&gt;
    
    </summary>
    
    
      <category term="docker" scheme="http://www.zhz.gift/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker java教程3.1: 构建一个Docker 镜像</title>
    <link href="http://www.zhz.gift/2018/05/10/Docker%20java%E6%95%99%E7%A8%8B3.1_%20%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AADocker%20%E9%95%9C%E5%83%8F/"/>
    <id>http://www.zhz.gift/2018/05/10/Docker java教程3.1_ 构建一个Docker 镜像/</id>
    <published>2018-05-10T15:09:42.000Z</published>
    <updated>2018-05-10T13:32:13.711Z</updated>
    
    <content type="html"><![CDATA[<p><a href="#1.1">Dockerfile</a><br><a href="#1.2">创建你的首个镜像</a><br><a href="#1.3">使用java创建你的首个镜像</a></p><ul><li><a href="#1.3.1">创建一个普通的java应用</a></li><li><a href="#1.3.2">作为Docker镜像打包和运行Java应用</a></li><li><a href="#1.3.3">使用Docker Maven Plugin 打包和运行Java应用</a></li></ul><p><a href="#1.4">Dockerfile 命令设计模式</a></p><ul><li><a href="#1.4.1">CMD 和 ENTRYPOINT 之间的不同</a></li><li><a href="#1.4.2">ADD 和 COPY 之间的不同</a></li><li><a href="#1.4.3">导入和导出镜像</a></li></ul><a id="more"></a><h2 id="1.1">Dockerfile</h2><p>Docker 构建镜像是通过读取Dockerfile 文件的指令.Dockerfile 是一个包含了所有用户能在命令行执行用以装配镜像的命令的文本文件.<code>docker image build</code>命令使用这个文件并且成功执行所有的命令来创建镜像.</p><p><code>build</code> 命令在镜像创建期间同样传递一个上下文.这个上下文可以是你本地文件系统的路径或者一个git仓库的URL地址.</p><p><strong>Dockerfile is usually called Dockerfile.</strong><br>完全的命令一览查看以下链接  <a href="https://docs.docker.com/reference/builder/" target="_blank" rel="external">https://docs.docker.com/reference/builder/</a>. 常见命令见下文:</p><p>Table 1. Dockerfile 常见命令</p><table><thead><tr><th style="text-align:center">Command</th><th style="text-align:center">Purpose</th><th style="text-align:center">Example</th></tr></thead><tbody><tr><td style="text-align:center">FROM</td><td style="text-align:center">First non-comment instruction in Dockerfile</td><td style="text-align:center"><code>FROM ubuntu</code></td></tr><tr><td style="text-align:center">COPY</td><td style="text-align:center">Copies mulitple source files from the context to the file system of the container at the specified path</td><td style="text-align:center"><code>COPY .bash_profile /home</code></td></tr><tr><td style="text-align:center">ENV</td><td style="text-align:center">Sets the environment variable</td><td style="text-align:center"><code>ENV HOSTNAME=test</code></td></tr><tr><td style="text-align:center">RUN</td><td style="text-align:center">Executes a command</td><td style="text-align:center"><code>RUN apt-get update</code></td></tr><tr><td style="text-align:center">CMD</td><td style="text-align:center">Defaults for an executing container</td><td style="text-align:center"><code>CMD [&quot;/bin/echo&quot;, &quot;hello world&quot;]</code></td></tr><tr><td style="text-align:center">EXPOSE</td><td style="text-align:center">Informs the network ports that the container will listen on</td><td style="text-align:center"><code>EXPOSE 8093</code></td></tr></tbody></table><h2 id="1.2">创建你的首个镜像</h2><p>创建一个新目录 <code>hellodocker</code>.</p><p>在这个目录,创建一个新的Dockerfile 文件.使用以下内容:</p><pre><code>FROM ubuntu:latestCMD [&quot;/bin/echo&quot;, &quot;hello world&quot;]</code></pre><p>这个镜像使用 <code>ubuntu</code> 作为基础镜像.<code>CMD</code> 命令定义需要运行的命令.<br>它提供了一个不同的入口 <code>/bin/echo</code> 并且提供参数 “hello world”.</p><p>使用以下命令构建镜像:<br>    docker image build . -t helloworld</p><p><code>.</code> 在这个命令当中是作为 <code>docker image build</code> 的上下文. <code>-t</code> 添加标志到镜像当中.</p><p>输出如下:</p><pre><code>Sending build context to Docker daemon  2.048kBStep 1/2 : FROM ubuntu:latestlatest: Pulling from library/ubuntu9fb6c798fa41: Pull complete3b61febd4aef: Pull complete9d99b9777eb0: Pull completed010c8cf75d7: Pull complete7fac07fb303e: Pull completeDigest: sha256:31371c117d65387be2640b8254464102c36c4e23d2abe1f6f4667e47716483f1Status: Downloaded newer image for ubuntu:latest ---&gt; 2d696327ab2eStep 2/2 : CMD /bin/echo hello world ---&gt; Running in 9356a508590c ---&gt; e61f88f3a0f7Removing intermediate container 9356a508590cSuccessfully built e61f88f3a0f7Successfully tagged helloworld:latest</code></pre><p>使用<code>docker image ls</code>命令展示可用的镜像:</p><pre><code>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZEhelloworld          latest              e61f88f3a0f7        3 minutes ago       122MBubuntu              latest              2d696327ab2e        4 days ago          122MB</code></pre><p>使用以下命令运行容器:    </p><pre><code>docker container run helloworld</code></pre><p>命令输出如下:</p><pre><code>hello world</code></pre><p>如果你没有看到期望的输出,检查你的Dockerfille文件确保内容与上文所示一致.再次构建镜像并且运行它.</p><p>在<code>Dockerfile</code>文件中改变基础镜像，从<code>ubuntu</code> 修改为<code>busybox</code>.<br>再次构建镜像:    </p><pre><code>docker image build -t helloworld:2 .</code></pre><p>并且通过<code>docker image ls</code>命令查看镜像:</p><pre><code>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZEhelloworld          2                   7fbedda27c66        3 seconds ago       1.13MBhelloworld          latest              e61f88f3a0f7        5 minutes ago       122MBubuntu              latest              2d696327ab2e        4 days ago          122MBbusybox             latest              54511612f1c4        9 days ago          1.13MB  </code></pre><p><code>helloworld:2</code> 是一种定义镜像名称的格式,通过<code>:</code>分割标识/版本号.</p><h2 id="1.3">使用Java创建你的首个镜像</h2><h3 id="1.3.1">创建你的首个镜像</h3><p><strong>Note:</strong></p><p>如果你正在运行 OpenJDK 9<br>If you are running OpenJDK 9, <code>mvn package</code> 可能会失败:</p><pre><code>[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project helloworld: Compilation failure: Compilation failure:[ERROR] Source option 1.5 is no longer supported. Use 1.6 or later.[ERROR] Target option 1.5 is no longer supported. Use 1.6 or later.</code></pre><p>因为一些Java 5的支持在JDK9中被<a href="http://openjdk.java.net/jeps/182" target="_blank" rel="external">废弃</a>了.<br>你可以通过添加以下属性配置:</p><pre><code>&lt;properties&gt;  &lt;maven.compiler.source&gt;1.6&lt;/maven.compiler.source&gt;  &lt;maven.compiler.target&gt;1.6&lt;/maven.compiler.target&gt;&lt;/properties&gt;</code></pre><p>到生成的pom.xml中用1.6来代替.详情查看 <a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/chapters/ch03-build-image-java-9.adoc" target="_blank" rel="external">用Java 9构建Docker 镜像章节</a>.</p><p>创建一个java项目:</p><pre><code>mvn archetype:generate -DgroupId=org.examples.java -DartifactId=helloworld -DinteractiveMode=false</code></pre><p>构建项目:</p><pre><code>cd helloworldmvn package</code></pre><p>运行java应用:</p><pre><code>java -cp target/helloworld-1.0-SNAPSHOT.jar org.examples.java.App</code></pre><p>输出如下:</p><pre><code>Hello World!</code></pre><p>接下来将这个应用打包成docker镜像</p><p><strong>Java Docker 镜像</strong></p><p>以一种交互性的方式运行 OpenJDK 容器:</p><pre><code>docker container run -it openjdk</code></pre><p>这将会在容器当中打开一个终端窗口.检查Java的版本:</p><pre><code>root@8d0af9da5258:/# java -versionopenjdk version &quot;1.8.0_141&quot;OpenJDK Runtime Environment (build 1.8.0_141-8u141-b15-1~deb9u1-b15)OpenJDK 64-Bit Server VM (build 25.141-b15, mixed mode)</code></pre><p>通过在容器 shell中输入<code>exit</code> 退出容器.</p><h3 id="1.3.2">作为Docker 镜像打包和运行Java应用</h3>    <p>在<code>helloworld</code>目录创建一个新的Dockerfile文件并且使用以下内容:</p><pre><code>FROM openjdk:latestCOPY target/helloworld-1.0-SNAPSHOT.jar /usr/src/helloworld-1.0-SNAPSHOT.jarCMD java -cp /usr/src/helloworld-1.0-SNAPSHOT.jar org.examples.java.App</code></pre><p>构建镜像:</p><pre><code>docker image build -t hello-java:latest .</code></pre><p>运行镜像:</p><pre><code>docker container run hello-java:latest</code></pre><p>输出如下:</p><pre><code>Hello World!</code></pre><h3 id="1.3.2">使用Docker Maven Plugin打包和运行Java应用</h3>   <p><a href="https://github.com/fabric8io/docker-maven-plugin" target="_blank" rel="external">Docker Maven Plugin</a> 允许你通过Maven管理Docker 镜像和容器.<br>allows you to manage Docker images and containers using Maven. 它通过预定义目标来完成相应操作:</p><table><thead><tr><th style="text-align:center">Goal</th><th style="text-align:center">Description</th></tr></thead><tbody><tr><td style="text-align:center">docker:build</td><td style="text-align:center">Build images</td></tr><tr><td style="text-align:center">docker:start</td><td style="text-align:center">Create and start containers</td></tr><tr><td style="text-align:center">docker:stop</td><td style="text-align:center">Stop and destroy containers</td></tr><tr><td style="text-align:center">docker:push</td><td style="text-align:center">Push images to a registry</td></tr><tr><td style="text-align:center">docker:remove</td><td style="text-align:center">Remove images from local docker host</td></tr><tr><td style="text-align:center">docker:logs</td><td style="text-align:center">Show container logs</td></tr></tbody></table><p>完整的目标列表如下: <a href="https://github.com/fabric8io/docker-maven-plugin" target="_blank" rel="external">https://github.com/fabric8io/docker-maven-plugin</a>.</p><p>示例下载地址: <a href="https://github.com/arun-gupta/docker-java-sample/" target="_blank" rel="external">https://github.com/arun-gupta/docker-java-sample/</a>.</p><p>创建Docker 镜像:</p><pre><code>mvn -f docker-java-sample/pom.xml package -Pdocker</code></pre><p>输出如下:    </p><pre><code>[INFO] Copying files to /Users/argu/workspaces/docker-java-sample/target/docker/hellojava/build/maven[INFO] Building tar: /Users/argu/workspaces/docker-java-sample/target/docker/hellojava/tmp/docker-build.tar[INFO] DOCKER&gt; [hellojava:latest]: Created docker-build.tar in 87 milliseconds[INFO] DOCKER&gt; [hellojava:latest]: Built image sha256:6f815[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------</code></pre><p>使用<code>docker image ls | grep hello-java</code>命令查看镜像列表:    </p><pre><code>hello-java  latest  ea64a9f5011e   5 seconds ago       643 MB</code></pre><p>运行Docker容器:</p><pre><code>mvn -f docker-java-sample/pom.xml install -Pdocker</code></pre><p>输出如下:</p><pre><code>[INFO] DOCKER&gt; [hellojava:latest]: Start container 30a08791eedb30a087&gt; Hello World![INFO] DOCKER&gt; [hellojava:latest]: Waited on log out &apos;Hello World!&apos; 510 ms</code></pre><p>使用 <code>java</code> CLI 或者使用 Docker 容器使用 <code>docker container run</code> 命令来运行这个Java应用，输出都是相似的.</p><p>容器运行在最顶层的位置.使用 <code>Ctrl</code> + <code>C</code> 来终止容器并且返回到终端.</p><p>在项目中想要允许或禁止 Docker packaging 和 running ,只需要改变一处地方.在<code>pom.xml</code>配置文件中添加如下Maven配置:</p><pre><code>&lt;profiles&gt;    &lt;profile&gt;        &lt;id&gt;docker&lt;/id&gt;        &lt;build&gt;            &lt;plugins&gt;                &lt;plugin&gt;                    &lt;groupId&gt;io.fabric8&lt;/groupId&gt;                    &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt;                    &lt;version&gt;0.22.1&lt;/version&gt;                    &lt;configuration&gt;                        &lt;images&gt;                            &lt;image&gt;                                &lt;name&gt;hello-java&lt;/name&gt;                                &lt;build&gt;                                    &lt;from&gt;openjdk:latest&lt;/from&gt;                                    &lt;assembly&gt;                                        &lt;descriptorRef&gt;artifact&lt;/descriptorRef&gt;                                    &lt;/assembly&gt;                                    &lt;cmd&gt;java -cp maven/${project.name}-${project.version}.jar org.examples.java.App&lt;/cmd&gt;                                &lt;/build&gt;                                &lt;run&gt;                                    &lt;wait&gt;                                        &lt;log&gt;Hello World!&lt;/log&gt;                                    &lt;/wait&gt;                                &lt;/run&gt;                            &lt;/image&gt;                        &lt;/images&gt;                    &lt;/configuration&gt;                    &lt;executions&gt;                        &lt;execution&gt;                            &lt;id&gt;docker:build&lt;/id&gt;                            &lt;phase&gt;package&lt;/phase&gt;                            &lt;goals&gt;                                &lt;goal&gt;build&lt;/goal&gt;                            &lt;/goals&gt;                        &lt;/execution&gt;                        &lt;execution&gt;                            &lt;id&gt;docker:start&lt;/id&gt;                            &lt;phase&gt;install&lt;/phase&gt;                            &lt;goals&gt;                                &lt;goal&gt;start&lt;/goal&gt;                                &lt;goal&gt;logs&lt;/goal&gt;                            &lt;/goals&gt;                        &lt;/execution&gt;                    &lt;/executions&gt;                &lt;/plugin&gt;            &lt;/plugins&gt;        &lt;/build&gt;    &lt;/profile&gt;&lt;/profiles&gt;</code></pre><h2 id="1.4">Dockerfile 命令设计模式</h2><h3 id="1.4.1">CMD 和 ENTRYPOINT 之间的不同</h3><p><code>CMD</code> 在大多数情况下都能正常工作.</p><p>容器默认的入口是<code>/bin/sh</code>,即默认的shell.</p><p>使用命令<code>docker container run -it ubuntu</code> 来运行容器并且启动默认shell.输出如下:</p><pre><code>&gt; docker container run -it ubunturoot@88976ddee107:/#</code></pre><p><code>ENTRYPOINT</code> 允许使用其它命令重写 entry point ，设置进行自定义.例如,一个容器能这样启动:</p><pre><code>&gt; docker container run -it --entrypoint=/bin/cat ubuntu /etc/passwdroot:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologinsys:x:3:3:sys:/dev:/usr/sbin/nologin. . .</code></pre><p>这个容器重写了容器的 entry point 到 <code>/bin/cat</code> 目录. </p><h3 id="1.4.2">ADD 和 COPY 之间的不同</h3><p><code>COPY</code> 大多数情况都能正常工作.</p><p><code>ADD</code> 拥有 <code>COPY</code> 命令的所有功能并且拥有以下额外特性:</p><ul><li><p>允许tar 文件在镜像中自动解压缩,例如:<code>ADD app.tar.gz /opt/var/myapp</code>.</p></li><li><p>允许文件从远程URL下载.然而,下载文件会成为镜像的一部分.这会使得镜像越来越臃肿.所以一般还是建议使用curl 或者wget的方式来明确地下载，解压缩或者移除存档文件.</p></li></ul><h3 id="1.4.3">导入和导出镜像</h3><p>Docker 镜像能使用<code>image save</code>命令保存为<code>.tar</code>文件.</p><pre><code>docker image save helloworld &gt; helloworld.tar</code></pre><p>这些tar文件能够使用<code>load</code>命令进行导入:</p><pre><code>docker image load -i helloworld.tar</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;#1.1&quot;&gt;Dockerfile&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;#1.2&quot;&gt;创建你的首个镜像&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;#1.3&quot;&gt;使用java创建你的首个镜像&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1.3.1&quot;&gt;创建一个普通的java应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#1.3.2&quot;&gt;作为Docker镜像打包和运行Java应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#1.3.3&quot;&gt;使用Docker Maven Plugin 打包和运行Java应用&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;#1.4&quot;&gt;Dockerfile 命令设计模式&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1.4.1&quot;&gt;CMD 和 ENTRYPOINT 之间的不同&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#1.4.2&quot;&gt;ADD 和 COPY 之间的不同&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#1.4.3&quot;&gt;导入和导出镜像&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="docker" scheme="http://www.zhz.gift/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker Java教程5：使用Docker Compose 实现多容器应用</title>
    <link href="http://www.zhz.gift/2018/05/10/Docker%20Java%E6%95%99%E7%A8%8B5_%E4%BD%BF%E7%94%A8Docker%20Compose%20%E5%AE%9E%E7%8E%B0%E5%A4%9A%E5%AE%B9%E5%99%A8%E5%BA%94%E7%94%A8/"/>
    <id>http://www.zhz.gift/2018/05/10/Docker Java教程5_使用Docker Compose 实现多容器应用/</id>
    <published>2018-05-10T15:09:42.000Z</published>
    <updated>2018-05-10T13:27:10.849Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1.1"> 什么是Docker Compose？</h2><p>Docker Compose 是一个使用Docker来定义和运行复杂应用的工具.<br>通过Compose,你能在一个单独的文件中定义一个多容器应用,通过一个命令就能完成所有事情，并使它们运行起来.</p><p>— github.com/docker/compose</p><a id="more"></a><p><a href="#1.1">什么是Docker Compose</a><br><a href="#1.2">配置文件</a><br><a href="#1.3">启动应用</a><br><a href="#1.4">验证应用</a><br><a href="#1.5">停止应用</a></p><p>一个使用Docker容器技术的应用一般都会包含多个容器.通过Docker Compose,没有必要去写shell 脚本来启动你的容器.所有的容器都通过services定义在一个配置文件当中,然后docker-compose 脚本就可以用来启动，停止，或者重启应用，这样一来，所有的容器就集成在service当中，而所有的services则被包含在应用当中.<br>完整的命令列表如下所示:</p><table><thead><tr><th style="text-align:center">Command</th><th style="text-align:center">Purpose</th></tr></thead><tbody><tr><td style="text-align:center">build</td><td style="text-align:center">Build or rebuild services</td></tr><tr><td style="text-align:center">help</td><td style="text-align:center">Get help on a command</td></tr><tr><td style="text-align:center">kill</td><td style="text-align:center">Kill containers</td></tr><tr><td style="text-align:center">logs</td><td style="text-align:center">View output from containers</td></tr><tr><td style="text-align:center">port</td><td style="text-align:center">Print the public port for a port binding</td></tr><tr><td style="text-align:center">ps</td><td style="text-align:center">List containers</td></tr><tr><td style="text-align:center">pull</td><td style="text-align:center">Pulls service images</td></tr><tr><td style="text-align:center">restart</td><td style="text-align:center">Restart services</td></tr><tr><td style="text-align:center">rm</td><td style="text-align:center">Remove stopped containers</td></tr><tr><td style="text-align:center">run</td><td style="text-align:center">Run a one-off command</td></tr><tr><td style="text-align:center">scale</td><td style="text-align:center">Set number of containers for a service</td></tr><tr><td style="text-align:center">start</td><td style="text-align:center">Start services</td></tr><tr><td style="text-align:center">stop</td><td style="text-align:center">Stop services</td></tr><tr><td style="text-align:center">up</td><td style="text-align:center">Create and start containers</td></tr></tbody></table><p>这个章节使用的应用是一个与数据库交互的Java EE应用.<br>这个应用发布一个REST节点，可以通过<code>curl</code>调用.它通过<a href="http://wildfly-swarm.io/" target="_blank" rel="external">WildFly Swarm</a>部署，并且与MySQL数据库进行交互.</p><p>WildFly Swarm 和 MySQL 将会在两个隔离的容器当中运行,因此这是一个多容器应用.</p><h2 id="1.2">配置文件</h2><p>Docker Compose 的入口是一个Compose 文件,通常命名为<code>docker-compose.yml</code>.创建一个新目录<code>javaee</code>,在该目录创建一个<code>docker-compose.yml</code>文件，内容如下:</p><pre><code>version: &apos;3.3&apos;services:  db:    container_name: db    image: mysql:8    environment:      MYSQL_DATABASE: employees      MYSQL_USER: mysql      MYSQL_PASSWORD: mysql      MYSQL_ROOT_PASSWORD: supersecret    ports:      - 3306:3306  web:    image: arungupta/docker-javaee:dockerconeu17    ports:      - 8080:8080      - 9990:9990    depends_on:      - db</code></pre><p>在这个Compose文件当中:</p><ol><li><p>在这个Compose 文件当中定义了两个services，分别是 db 和 web.</p></li><li><p>每个service的镜像名称通过image 属性进行定义.<br>MYSQL_ROOT_PASSWORD is mandatory and specifies the password that will be set for the MySQL root superuser account.</p></li><li><p>mysql:8 镜像 启动 MySQL 服务器.</p></li><li><p>环境变量属性定义环境变量来初始化MySQL 服务器.</p><ul><li>MYSQL_DATABASE 允许你在镜像启动的时候指定被创建的数据库的名称.</li><li>MYSQL_USER 和 MYSQL_PASSWORD 用来创建一个新用户并且赋予那个用户的密码.这个用户将会赋予MYSQL_DATABASE属性指定的数据库的超级管理员权限.</li><li>MYSQL_ROOT_PASSWORD 是强制必填项,并且将会设置为MySQL root 超级用户账号的密码.</li></ul></li><li><p>Java EE 应用 使用的 <code>db</code> 服务通过 <code>connection-url</code> 进行指定<a href="https://github.com/arun-gupta/docker-javaee/blob/master/employees/src/main/resources/project-defaults.yml/" target="_blank" rel="external">https://github.com/arun-gupta/docker-javaee/blob/master/employees/src/main/resources/project-defaults.yml/</a>.</p></li><li><p>arungupta/docker-javaee:dockerconeu17 image 启动 WildFly Swarm 应用服务器. 它包含从 <a href="https://github.com/arun-gupta/docker-javaee" target="_blank" rel="external">https://github.com/arun-gupta/docker-javaee</a> 构建的Java EE 应用. 如果你想要构建自己的镜像可以Clone这个项目.</p></li><li><p>端口跳转通过<code>ports</code>属性来完成.</p></li><li><p><code>depends_on</code> 属性允许表达services之间的依赖关系.在这个例子中,MySQL将会在WildFly之前启动. </p></li></ol><h2 id="1.3">启动应用</h2><p>在这个应用当中的所有services都能在detached模式被启动，通过以下命令:</p><pre><code>docker-compose up -d</code></pre><p>一个可替代的Compose文件名称能通过<code>-f</code>标志来指定.</p><p>一个可选的compose文件存在的目录能够通过<code>-p</code>标志来指定.</p><p>输出如下:</p><pre><code>docker-compose up -dCreating network &quot;javaee_default&quot; with the default driverCreating db ...Creating db ... doneCreating javaee_web_1 ...Creating javaee_web_1 ... done</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1.1&quot;&gt; 什么是Docker Compose？&lt;/h2&gt;

&lt;p&gt;Docker Compose 是一个使用Docker来定义和运行复杂应用的工具.&lt;br&gt;通过Compose,你能在一个单独的文件中定义一个多容器应用,通过一个命令就能完成所有事情，并使它们运行起来.&lt;/p&gt;
&lt;p&gt;— github.com/docker/compose&lt;/p&gt;
    
    </summary>
    
    
      <category term="docker" scheme="http://www.zhz.gift/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker java教程2—— docker 基础概念</title>
    <link href="http://www.zhz.gift/2018/03/15/Docker%20java%E6%95%99%E7%A8%8B2_%20docker%20%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"/>
    <id>http://www.zhz.gift/2018/03/15/Docker java教程2_ docker 基础概念/</id>
    <published>2018-03-15T15:09:42.000Z</published>
    <updated>2018-03-15T14:51:13.624Z</updated>
    
    <content type="html"><![CDATA[<p>**目的: 这个章节主要介绍一些关于Docker 的术语.</p><pre><code>Docker 是一个提供给开发人员以及系统管理员构建，部署和运行应用的平台.Docker 令你能够快速地从组件库装配应用,并且在发布代码时排除冲突.Docker 使你尽可能快地测试和部署你的代码到生产环境.</code></pre><p>— docs.docker.com/</p><a id="more"></a><p><a href="#1.1">主要组件</a><br><a href="#1.2">Docker 镜像</a><br><a href="#1.3">Docker 容器</a><br><a href="#1.4">Docker Engine</a><br><a href="#1.5">Docker 客户端</a></p><p>Docker 通过更便捷的构建和共享包含你整个应用环境或者应用的操作系统的镜像来简化软件的交付.</p><p><strong>一个应用操作系统意味着什么?</strong></p><p>你的应用一般需要一个特定版本的操作系统,应用服务器,JDK,和数据库服务器,还可能需要调整配置文件,并且同样需要多个其它的依赖.应用可能需要绑定到特定的端口和一定大小的内存.这些组件和配置组成运行你的应用的应用操作系统. </p><p>你可以提供一个将会下载和安装这些组件的安装脚本.同样Docker 允许创建包含你应用及其基础环境的镜像,它就像一个组件一样使用，大大简化了这个过程.这些镜像接着用来创建Docker 容器,Docker 容器运行在Docker提供的虚拟平台.</p><h2 id="1.1">主要组件</h2><p>Docker 包含三个主要组件:</p><ul><li><p>镜像是Docker 的构建组件, 并且是一定了一个应用操作系统的只读模板.</p></li><li><p>容器是Docker的运行组件,它是基于镜像创建的.容器能够运行,启动,停止,移除,或者删除.</p></li><li><p>镜像能够被存储，共享在注册表中进行管理，属于Docker 的分布组件.Docker Store 是一个公共可用的注册表,可用网址为:<a href="http://store.docker.com" target="_blank" rel="external">http://store.docker.com</a>.</p></li></ul><p>为了这三个组件能够正常工作,Docker Daemon(Docker Engine)在一个主机机器上运行,并且完成构建,运行和分发Docker 容器的工作.另外,客户端是一个Docker binary,能够通过Engine响应用户的命令,完成交互.</p><p>关键点 1. Docker 架构<br>Client 客户端与Engine交互可以是在本地同一个主机,也可以是其它任意一个.客户端使用<code>pull</code>命令请求Engine来从注册表拉取镜像.Engine接着从Docker Store下载镜像,或者任意一个配置的注册表.从注册表能够下载多个镜像并且安装到Engine上.客户端使用<code>run</code>命令来运行容器.</p><h2 id="1.2">Docker 镜像</h2><br>在Docerk 容器中运行的docker镜像是只读模板.每个镜像由一系列层次构成.Docker利用联合文件系统(Union file systems)来将这些层面结合到一个镜像当中.联合文件系统允许文件或者以目录为单位的独立文件系统,就像分支一样(branches),通过覆盖的方式，形成一个单一而连贯的文件系统.<br><br>Docker 如此轻量级的原因之一就是因为这些分层.当你改变一个Docker镜像-比如,更新一个应用到新的版本-一个新的分层被构建.因此,并不是替换整个镜像或者完全地重新构建,就像你可能在虚拟机中做的那样,只有那个分层被添加或者更新.现在你不需要去分配一整个全新的镜像,只需要更新,这使得Docker 镜像的分配更加快速和便捷.<br><br>每个镜像都是基于基础镜像(base image)构建的,例如 ubuntu,一个基础的Ubuntu镜像,或者 fedora,一个基础调的Fedora 镜像.你同样能使用自己的镜像作为基础镜像来构建一个新镜像,比如如果你有一个基础的Apache镜像你能将它作为你所有web应用镜像的基础镜像.<br><br>|Note|Docker 默认从Docker Store获取这些基础镜像|<br>|:—-:|:—-:|<br><br>Docker 镜像可以很简单的从这些基础镜像当中构建出来,我们将依次介绍相关指令,每个指令都会在我们的镜像当中创建一个新的分层.指令包含的动作：<br><br><em> 运行一个命令</em> 添加一个文件或者目录<br><br><em> 创建一个环境变量</em> 当容器运行时运行一个进程<br><br>这些指令被存储在一个命名为Dockerfile的文件当中.Docker 会在你请求构建一个镜像时读取这个文件,执行这些指令,并且返回最终的镜像.<br><br><h2 id="1.3">Docker 容器</h2><p>一个容器由一个操作系统,用户添加的文件，和元数据组成.就像我们看到的那样,每个容器都是从镜像中构建的.那个镜像会告诉Docker容器应该包含什么东西,当容器启动时运行什么进程,和一系列其它配置文件.Docker镜像是只读的.当Docker从一个镜像当中运行容器,它会在那个镜像的顶部添加一个读写层(使用一个联合文件系统),让你的应用能够顺利运行.</p><h2 id="1.4">Docker Engine</h2><p>Docker Host 作为安装在你机器上的Docker的一部分被创建.一旦你的Docker host已经被创建,它就允许你去管理镜像和容器.例如,这个镜像能够被下载，容器能够被启动,停止和重启.</p><h2 id="1.5">Docker 客户端</h2><p>这个客户端与Docker Host进行交互并且让你能够对镜像和容器产生影响作用.</p><p>通过以下命令检查你的客户端是否正常工作:</p><pre><code>docker -v</code></pre><p>它将展示以下输出:</p><pre><code>Docker version 17.09.0-ce-rc3, build 2357fb2</code></pre><p>客户端和服务器的版本能够通过<code>docker version</code>命令来进行查看.它将展示以下输出:</p><pre><code>Client: Version:      17.09.0-ce-rc3 API version:  1.32 Go version:   go1.8.3 Git commit:   2357fb2 Built:        Thu Sep 21 02:31:18 2017 OS/Arch:      darwin/amd64Server: Version:      17.09.0-ce-rc3 API version:  1.32 (minimum version 1.12) Go version:   go1.8.3 Git commit:   2357fb2 Built:        Thu Sep 21 02:36:52 2017 OS/Arch:      linux/amd64 Experimental: true</code></pre><p>完整的命令说明能够通过使用<code>docker --help</code>命令进行查看.</p><p><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch02-basic-concepts.adoc" target="_blank" rel="external">官方参考链接</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;**目的: 这个章节主要介绍一些关于Docker 的术语.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Docker 是一个提供给开发人员以及系统管理员构建，部署和运行应用的平台.
Docker 令你能够快速地从组件库装配应用,并且在发布代码时排除冲突.
Docker 使你尽可能快地测试和部署你的代码到生产环境.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;— docs.docker.com/&lt;/p&gt;
    
    </summary>
    
    
      <category term="docker" scheme="http://www.zhz.gift/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker java教程1—— docker java 环境设置</title>
    <link href="http://www.zhz.gift/2018/03/15/Docker%20java%E6%95%99%E7%A8%8B1_%20docker%20java%20%E7%8E%AF%E5%A2%83%E8%AE%BE%E7%BD%AE/"/>
    <id>http://www.zhz.gift/2018/03/15/Docker java教程1_ docker java 环境设置/</id>
    <published>2018-03-15T15:08:42.000Z</published>
    <updated>2018-03-15T14:51:45.110Z</updated>
    
    <content type="html"><![CDATA[<p>这个章节描述了在这个教程中所需的硬件和软件及其相关的配置方式.</p><a id="more"></a><p><a href="#1.1">硬件 &amp; 软件</a><br><a href="#1.2">Docker安装</a><br><a href="#1.3">下载镜像</a><br><a href="#1.4">其它软件</a></p><h2 id="1.1">硬件 &amp; 软件</h2><ol><li><p>内存: 至少 4 GB+, 推荐 8 GB</p></li><li><p>操作系统: Mac OS X (10.10.3+), Windows 10 Pro+ 64-bit, Ubuntu 12+, CentOS 7+.</p></li><li><p>Amazon Web Services 凭证需要<a href="https://docs.docker.com/docker-for-aws/iam-permissions/" target="_blank" rel="external">以下凭证</a>. 这只在这个教程的部分地方需要用到.</p></li></ol><table><thead><tr><th style="text-align:center">Note</th><th style="text-align:center">如果使用老版本的操作系统，安装介绍将会有些许不同，这将在下一个章节里讲到.</th></tr></thead><tbody><tr><td style="text-align:center"></td></tr></tbody></table><h2 id="1.2">Docker安装</h2><br>Docker在Mac,Windows 和 Linux上运行十分顺畅.这个教程将使用<a href="https://www.docker.com/community-edition" target="_blank" rel="external">Docker Community Edition (CE)</a>.从<a href="https://store.docker.com/search?type=edition&amp;offering=community" target="_blank" rel="external">docker Store</a>下载 Docker CE edition .<br><br>Docker CE requires a fairly recent operating system version. If your machine does not meet the requirements, then you need to install Docker Toolbox.<br><br>|Note|Docker CE 需要一个相当新的操作系统版本.如果你的机器不满足要求，那你需要安装<a href="https://www.docker.com/products/docker-toolbox" target="_blank" rel="external">Docker Toolbox</a>.|<br>|:-:|:-:|<br><br><br><h2 id="1.3">下载镜像</h2><p>这个教程使用到一些Docker 镜像和软件.让我们在开始教程前下载它们.</p><p>从 <a href="https://raw.githubusercontent.com/docker/labs/master/developer-tools/java/scripts/docker-compose-pull-images.yml" target="_blank" rel="external">https://raw.githubusercontent.com/docker/labs/master/developer-tools/java/scripts/docker-compose-pull-images.yml</a> 下载文件 并且使用以下命令拉取所需的镜像:</p><pre><code>docker-compose -f docker-compose-pull-images.yml pull --parallel</code></pre><table><thead><tr><th style="text-align:center">Note</th><th style="text-align:center">对于Linux来说,<code>docker-compose</code>和<code>docker commands</code>需要<code>sudo</code>访问权限.所以在所有命令前加上<code>sudo</code>前缀.</th></tr></thead><tbody><tr><td style="text-align:center"></td></tr></tbody></table><h2 id="1.4">其它软件</h2><p>这个小节介绍的软件只在教程的某些部分中使用到.如果你计划尝试它们的话再进行安装.</p><ul><li><p>安装 <a href="https://git-scm.com//" target="_blank" rel="external">git</a>.</p></li><li><p>按照<a href="https://docs.docker.com/docker-cloud/installing-cli/" target="_blank" rel="external">教程</a>安装 Docker Cloud CLI .</p></li><li><p>下载 Java IDE .</p><ul><li><p><a href="https://netbeans.org/downloads/" target="_blank" rel="external">NetBeans 8.2</a> (“Java SE” version)</p></li><li><p><a href="https://www.jetbrains.com/idea/download/" target="_blank" rel="external">IntelliJ IDEA Community or Ultimate</a></p></li><li><p><a href="http://www.eclipse.org/downloads/eclipse-packages/" target="_blank" rel="external">Eclipse IDE for Java EE Developers</a></p></li></ul></li><li><p>下载并且安装 <a href="https://maven.apache.org/download.cgi" target="_blank" rel="external">Maven</a>.</p></li><li><p>下载通过 <a href="http://download.java.net/java/GA/jdk9/9/binaries/openjdk-9_linux-x64_bin.tar.gz" target="_blank" rel="external">JDK 9 for Linux x64</a>构建的OpenJDK. (同样参照 <a href="http://jdk.java.net/9/" target="_blank" rel="external">OpenJDK JDK 9 download page</a>.)</p></li><li><p>下载通过<a href="http://jdk.java.net/9/ea" target="_blank" rel="external">JDK 9 for Alpine Linux</a>构建的先行版本Open JDK.</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这个章节描述了在这个教程中所需的硬件和软件及其相关的配置方式.&lt;/p&gt;
    
    </summary>
    
    
      <category term="docker" scheme="http://www.zhz.gift/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker for Java Developers</title>
    <link href="http://www.zhz.gift/2018/03/15/Docker%20for%20Java%20Developers/"/>
    <id>http://www.zhz.gift/2018/03/15/Docker for Java Developers/</id>
    <published>2018-03-15T15:07:42.000Z</published>
    <updated>2018-03-15T14:46:32.729Z</updated>
    
    <content type="html"><![CDATA[<p>这个教程为java开发者提供了一门可以按照自己进度操作实践的入门级课程.</p><a id="more"></a><ul><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch01-setup.adoc" target="_blank" rel="external">Setup Environments</a></li><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch02-basic-concepts.adoc" target="_blank" rel="external">Docker Basic Concepts</a></li><li>Building<ul><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch03-build-image.adoc" target="_blank" rel="external">Build a Docker Image</a></li><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch03-build-image-java-9.adoc" target="_blank" rel="external">Build a Docker Image for Java 9</a></li></ul></li><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch04-run-container.adoc" target="_blank" rel="external">Run a Docker Container</a></li><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch05-compose.adoc" target="_blank" rel="external">Multi-container application using Docker Compose</a></li><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch06-swarm.adoc" target="_blank" rel="external">Multi-container application using Compose and Swarm Mode</a></li><li>Java IDEs<ul><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch07-netbeans.adoc" target="_blank" rel="external">Docker Tooling in NetBeans</a></li><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch07-intellij.adoc" target="_blank" rel="external">Docker Tooling in IntelliJ IDEA</a></li><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch07-eclipse.adoc" target="_blank" rel="external">Docker Tooling in Eclipse</a></li></ul></li><li>Multi-container application on multi-host<ul><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch08-aws.adoc" target="_blank" rel="external">Docker for AWS</a></li><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch08-azure.adoc" target="_blank" rel="external">Docker for Azure (coming)</a></li><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch08-cloud.adoc" target="_blank" rel="external">Docker Cloud</a></li></ul></li><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch09-cicd.adoc" target="_blank" rel="external">CI/CD using Docker</a></li><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch10-monitoring.adoc" target="_blank" rel="external">Monitoring Docker Containers with Prometheus and Grafana</a></li><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/ch11-bigdata.adoc" target="_blank" rel="external">Big Data Processing with Docker and Hadoop</a></li><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/appa-common-commands.adoc" target="_blank" rel="external">Common Docker Commands</a></li><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/appb-troubleshooting.adoc" target="_blank" rel="external">Troubleshooting</a></li><li><a href="https://github.com/docker/labs/blob/master/developer-tools/java/chapters/appc-references.adoc" target="_blank" rel="external">References</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这个教程为java开发者提供了一门可以按照自己进度操作实践的入门级课程.&lt;/p&gt;
    
    </summary>
    
    
      <category term="docker" scheme="http://www.zhz.gift/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker Swarm 教程</title>
    <link href="http://www.zhz.gift/2018/03/15/Docker%20Swarm%20%E6%95%99%E7%A8%8B/"/>
    <id>http://www.zhz.gift/2018/03/15/Docker Swarm 教程/</id>
    <published>2018-03-15T14:08:42.000Z</published>
    <updated>2018-03-15T14:47:06.593Z</updated>
    
    <content type="html"><![CDATA[<p>Note:这个教程使用Docker Machine 来模拟多台机器运行的情况.有一种更简单的方式来学习swarm mode,那就是通过<a href="http://training.play-with-docker.com/swarm-mode-intro/" target="_blank" rel="external">Play with Docker</a>.这个教程因为历史原因保留下来，并且同样因为当你真的想要使用自己的机器来学习swarm时.</p><a id="more"></a><p>Docker 的swarm 模式是用来管理Docker Engines的集群,所以称之为swarm.你能使用Docker CLI 来创建swarm,部署应用服务到一个swarm,并且管理swarm的行为.这个教程使用<a href="https://docs.docker.com/machine/" target="_blank" rel="external">Docker Machine</a>来在你的桌面电脑上创建多个节点.你也可以选择在云上或者多台机器上创建多个节点.</p><p>重要提示: 你并不需要使用Docker CLI来执行这些操作.只需要使用<code>docker stack deploy --compose-file STACKNAME.yml STACKNAME</code> 命令即可.关于以compose 文件格式的stack文件来部署一个app,参考<a href="https://github.com/docker/labs/blob/master/beginner/chapters/votingapp.md" target="_blank" rel="external">Deploying an app to a Swarm</a></p><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>你需要在你的系统上安装Docker 和Docker Machine.<a href="https://docker.com/getdocker" target="_blank" rel="external">下载Docker</a>并且安装.</p><p>提示:</p><ul><li><p>如果你是使用Docker for Mac 或者Docker for Windows,Docker Machine已经默认安装.查看<a href="https://docs.docker.com/docker-for-mac/#/download-docker-for-mac" target="_blank" rel="external">Download Docker for Mac</a>和<a href="https://docs.docker.com/docker-for-windows/#/download-docker-for-windows" target="_blank" rel="external">Download Docker for Windows</a>来查询详细安装细节.</p></li><li><p>如果你是使用Docker for Windows 你还需要使用Hyper-V driver 来正常驱动Docker Machine.这可能需要更多一点设置.查看<a href="https://docs.docker.com/machine/drivers/hyper-v/" target="_blank" rel="external">Microsoft Hyper-V driver documentation</a>来获取设置指引.</p></li><li><p>如果你是直接在linux系统上使用Docker,你将需要安装Docker Machine(在安装Docker Engine之后).</p></li></ul><h2 id="创建nodes和Swarm"><a href="#创建nodes和Swarm" class="headerlink" title="创建nodes和Swarm"></a>创建nodes和Swarm</h2><p><a href="https://docs.docker.com/machine/overview/" target="_blank" rel="external">Docker Machine</a>可以用来:</p><ul><li>在Mac或者Windows上安装和运行Docker</li><li>提供和管理多个远程Docker 主机</li><li>提供Swarm 集群</li></ul><p>但它同样能用来在你本地的机器上创建多个节点.在这个仓库有一个<a href="https://github.com/docker/labs/blob/master/swarm-mode/beginner-tutorial/swarm-node-vbox-setup.sh" target="_blank" rel="external">bash脚本</a>实现了这一点并且创建swarm.同样有一个<a href="https://github.com/docker/labs/blob/master/swarm-mode/beginner-tutorial/swarm-node-hyperv-setup.ps1" target="_blank" rel="external">powershell Hyper-V version</a>.在这篇教程我们将贯穿这个脚本,步步深入，除了设置以外,与Hyper-V version基本相同.</p><p>首先创建3个machines,并且命名为manger1,manger2和manger3.</p><pre><code>#!/bin/bash# Swarm mode using Docker Machine#This configures the number of workers and managers in the swarmmanagers=3workers=3# This creates the manager machinesecho &quot;======&gt; Creating $managers manager machines ...&quot;;for node in $(seq 1 $managers);do    echo &quot;======&gt; Creating manager$node machine ...&quot;;    docker-machine create -d virtualbox manager$node;done</code></pre><p>第二个步骤是创建三个及以上的machines,并且命名为worker1,worker2,和worker3</p><pre><code># This create worker machinesecho &quot;======&gt; Creating $workers worker machines ...&quot;;for node in $(seq 1 $workers);do    echo &quot;======&gt; Creating worker$node machine ...&quot;;    docker-machine create -d virtualbox worker$node;done# This lists all machines createddocker-machine ls</code></pre><p>接下来你创建一个swarm通过在首个manger上初始化它.通过<code>docker-machine ssh</code>来运行<code>docker-machine ssh</code>命令.</p><pre><code># initialize swarm mode and create a managerecho &quot;======&gt; Initializing first swarm manager ...&quot;docker-machine ssh manager1 &quot;docker swarm init --listen-addr $(docker-machine ip manager1) --advertise-addr $(docker-machine ip manager1)&quot;</code></pre><p>接下来为mangers和workers获取tokens.</p><pre><code># get manager and worker tokensexport manager_token=`docker-machine ssh manager1 &quot;docker swarm join-token manager -q&quot;`export worker_token=`docker-machine ssh manager1 &quot;docker swarm join-token worker -q&quot;`</code></pre><p>然后把其他managers加入到Swarm</p><pre><code>for node in $(seq 2 $managers);do    echo &quot;======&gt; manager$node joining swarm as manager ...&quot;    docker-machine ssh manager$node \        &quot;docker swarm join \        --token $manager_token \        --listen-addr $(docker-machine ip manager$node) \        --advertise-addr $(docker-machine ip manager$node) \        $(docker-machine ip manager1)&quot;done</code></pre><p>最后，添加worker machines并且加入swarm</p><pre><code># workers join swarmfor node in $(seq 1 $workers);do    echo &quot;======&gt; worker$node joining swarm as worker ...&quot;    docker-machine ssh worker$node \    &quot;docker swarm join \    --token $worker_token \    --listen-addr $(docker-machine ip worker$node) \    --advertise-addr $(docker-machine ip worker$node) \    $(docker-machine ip manager1):2377&quot;done# show members of swarmdocker-machine ssh manager1 &quot;docker node ls&quot;</code></pre><p>最后一行将向你展示所有的节点,就像这样:</p><pre><code>ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS3cq6idpysa53n6a21nqe0924h    manager3  Ready   Active        Reachable64swze471iu5silg83ls0bdip *  manager1  Ready   Active        Leader7eljvvg0icxlw20od5f51oq8t    manager2  Ready   Active        Reachable8awcmkj3sd9nv1pi77i6mdb1i    worker1   Ready   Active        avu80ol573rzepx8ov80ygzxz    worker2   Ready   Active        bxn1iivy8w7faeugpep76w50j    worker3   Ready   Active   </code></pre><p>也可以运行以下命令:</p><pre><code>$ docker-machine lsNAME       ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER      ERRORSmanager1   -        virtualbox   Running   tcp://192.168.99.100:2376           v17.03.0-ce   manager2   -        virtualbox   Running   tcp://192.168.99.101:2376           v17.03.0-ce manager3   -        virtualbox   Running   tcp://192.168.99.102:2376           v17.03.0-ceworker1    -        virtualbox   Running   tcp://192.168.99.103:2376           v17.03.0-ceworker2    -        virtualbox   Running   tcp://192.168.99.104:2376           v17.03.0-ceworker3    -        virtualbox   Running   tcp://192.168.99.105:2376           v17.03.0-ce</code></pre><p>下一步是创建一个service并且进行展示.这里创建单个命名为web的service并且运行最新的nginx:</p><pre><code>$ docker-machine ssh manager1 &quot;docker service create -p 80:80 --name web nginx:latest&quot;$ docker-machine ssh manager1 &quot;docker service ls&quot;ID            NAME  REPLICAS  IMAGE         COMMAND2x4jsk6313az  web   1/1       nginx:latest    </code></pre><p>现在在你的浏览器上通过对应ip地址进行访问.在这个实例中manger1有一个ip地址为192.168.99.100.</p><p>你可以使用任意其它节点的ip地址进行访问都将得到同样的结果,因为<a href="https://docs.docker.com/engine/swarm/ingress/" target="_blank" rel="external">Swarm Mode’s Routing Mesh</a>.</p><p>现在检查service:</p><pre><code>$ docker-machine ssh manager1 &quot;docker service inspect web&quot;[    {        &quot;ID&quot;: &quot;2x4jsk6313azr6g1dwoi47z8u&quot;,        &quot;Version&quot;: {            &quot;Index&quot;: 104        },        &quot;CreatedAt&quot;: &quot;2016-08-23T22:43:23.573253682Z&quot;,        &quot;UpdatedAt&quot;: &quot;2016-08-23T22:43:23.576157266Z&quot;,        &quot;Spec&quot;: {            &quot;Name&quot;: &quot;web&quot;,            &quot;TaskTemplate&quot;: {                &quot;ContainerSpec&quot;: {                    &quot;Image&quot;: &quot;nginx:latest&quot;                },                &quot;Resources&quot;: {                    &quot;Limits&quot;: {},                    &quot;Reservations&quot;: {}                },                &quot;RestartPolicy&quot;: {                    &quot;Condition&quot;: &quot;any&quot;,                    &quot;MaxAttempts&quot;: 0                },                &quot;Placement&quot;: {}            },            &quot;Mode&quot;: {                &quot;Replicated&quot;: {                    &quot;Replicas&quot;: 1                }            },            &quot;UpdateConfig&quot;: {                &quot;Parallelism&quot;: 1,                &quot;FailureAction&quot;: &quot;pause&quot;            },            &quot;EndpointSpec&quot;: {                &quot;Mode&quot;: &quot;vip&quot;,                &quot;Ports&quot;: [                    {                        &quot;Protocol&quot;: &quot;tcp&quot;,                        &quot;TargetPort&quot;: 80,                        &quot;PublishedPort&quot;: 80                    }                ]            }        },        &quot;Endpoint&quot;: {            &quot;Spec&quot;: {                &quot;Mode&quot;: &quot;vip&quot;,                &quot;Ports&quot;: [                    {                        &quot;Protocol&quot;: &quot;tcp&quot;,                        &quot;TargetPort&quot;: 80,                        &quot;PublishedPort&quot;: 80                    }                ]            },            &quot;Ports&quot;: [                {                    &quot;Protocol&quot;: &quot;tcp&quot;,                    &quot;TargetPort&quot;: 80,                    &quot;PublishedPort&quot;: 80                }            ],            &quot;VirtualIPs&quot;: [                {                    &quot;NetworkID&quot;: &quot;24r1loluvdohuzltspkwbhsc8&quot;,                    &quot;Addr&quot;: &quot;10.255.0.9/16&quot;                }            ]        },        &quot;UpdateStatus&quot;: {            &quot;StartedAt&quot;: &quot;0001-01-01T00:00:00Z&quot;,            &quot;CompletedAt&quot;: &quot;0001-01-01T00:00:00Z&quot;        }    }]</code></pre><p>规模化service(运行多个相同service):    </p><pre><code>$ docker-machine ssh manager1 &quot;docker service scale web=15&quot;web scaled to 15$ docker-machine ssh manager1 &quot;docker service ls&quot;ID            NAME  REPLICAS  IMAGE         COMMAND2x4jsk6313az  web   15/15     nginx:latest  </code></pre><p>Docker会将15个服务均匀地分配到所有节点上:</p><pre><code>$ docker-machine ssh manager1 &quot;docker service ps web&quot;ID                         NAME    IMAGE         NODE      DESIRED STATE  CURRENT STATE           ERROR61wjx0zaovwtzywwbomnvjo4q  web.1   nginx:latest  worker3   Running        Running 13 minutes ago  bkkujhpbtqab8fyhah06apvca  web.2   nginx:latest  manager1  Running        Running 2 minutes ago   09zkslrkgrvbscv0vfqn2j5dw  web.3   nginx:latest  manager1  Running        Running 2 minutes ago   4dlmy8k72eoza9t4yp9c9pq0w  web.4   nginx:latest  manager2  Running        Running 2 minutes ago   6yqabr8kajx5em2auvfzvi8wi  web.5   nginx:latest  manager3  Running        Running 2 minutes ago   21x7sn82883e7oymz57j75q4q  web.6   nginx:latest  manager2  Running        Running 2 minutes ago   14555mvu3zee6aek4dwonxz3f  web.7   nginx:latest  worker1   Running        Running 2 minutes ago   1q8imt07i564bm90at3r2w198  web.8   nginx:latest  manager1  Running        Running 2 minutes ago   encwziari9h78ue32v5pjq9jv  web.9   nginx:latest  worker3   Running        Running 2 minutes ago   aivwszsjhhpky43t3x7o8ezz9  web.10  nginx:latest  worker2   Running        Running 2 minutes ago   457fsqomatl1lgd9qbz2dcqsb  web.11  nginx:latest  worker1   Running        Running 2 minutes ago   7chhofuj4shhqdkwu67512h1b  web.12  nginx:latest  worker2   Running        Running 2 minutes ago   7dynic159wyouch05fyiskrd0  web.13  nginx:latest  worker1   Running        Running 2 minutes ago   7zg9eki4610maigr1xwrx7zqk  web.14  nginx:latest  manager3  Running        Running 2 minutes ago   4z2c9j20gwsasosvj7mkzlyhc  web.15  nginx:latest  manager2  Running        Running 2 minutes ago   </code></pre><p>你同样能排除一个特定的节点，通过从那个节点移除所有的服务.这些服务会自动重新安排到其它节点上.</p><pre><code>$ docker-machine ssh manager1 &quot;docker node update --availability drain worker1&quot;worker1$ docker-machine ssh manager1 &quot;docker service ps web&quot;ID                         NAME        IMAGE         NODE      DESIRED STATE  CURRENT STATE           ERROR61wjx0zaovwtzywwbomnvjo4q  web.1       nginx:latest  worker3   Running        Running 15 minutes ago  bkkujhpbtqab8fyhah06apvca  web.2       nginx:latest  manager1  Running        Running 4 minutes ago   09zkslrkgrvbscv0vfqn2j5dw  web.3       nginx:latest  manager1  Running        Running 4 minutes ago   4dlmy8k72eoza9t4yp9c9pq0w  web.4       nginx:latest  manager2  Running        Running 4 minutes ago   6yqabr8kajx5em2auvfzvi8wi  web.5       nginx:latest  manager3  Running        Running 4 minutes ago   21x7sn82883e7oymz57j75q4q  web.6       nginx:latest  manager2  Running        Running 4 minutes ago   8so0xi55kqimch2jojfdr13qk  web.7       nginx:latest  worker3   Running        Running 3 seconds ago   14555mvu3zee6aek4dwonxz3f   \_ web.7   nginx:latest  worker1   Shutdown       Shutdown 4 seconds ago  1q8imt07i564bm90at3r2w198  web.8       nginx:latest  manager1  Running        Running 4 minutes ago   encwziari9h78ue32v5pjq9jv  web.9       nginx:latest  worker3   Running        Running 4 minutes ago   aivwszsjhhpky43t3x7o8ezz9  web.10      nginx:latest  worker2   Running        Running 4 minutes ago   738jlmoo6tvrkxxar4gbdogzf  web.11      nginx:latest  worker2   Running        Running 3 seconds ago   457fsqomatl1lgd9qbz2dcqsb   \_ web.11  nginx:latest  worker1   Shutdown       Shutdown 3 seconds ago  7chhofuj4shhqdkwu67512h1b  web.12      nginx:latest  worker2   Running        Running 4 minutes ago   4h7zcsktbku7peh4o32mw4948  web.13      nginx:latest  manager3  Running        Running 3 seconds ago   7dynic159wyouch05fyiskrd0   \_ web.13  nginx:latest  worker1   Shutdown       Shutdown 4 seconds ago  7zg9eki4610maigr1xwrx7zqk  web.14      nginx:latest  manager3  Running        Running 4 minutes ago   4z2c9j20gwsasosvj7mkzlyhc  web.15      nginx:latest  manager2  Running        Running 4 minutes ago   </code></pre><p>worker1节点仍然存活但是被标记为drain 状态.</p><pre><code>$ docker-machine ssh manager1 &quot;docker node ls&quot;ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS3cq6idpysa53n6a21nqe0924h    manager3  Ready   Active        Reachable64swze471iu5silg83ls0bdip *  manager1  Ready   Active        Leader7eljvvg0icxlw20od5f51oq8t    manager2  Ready   Active        Reachable8awcmkj3sd9nv1pi77i6mdb1i    worker1   Ready   Drain         avu80ol573rzepx8ov80ygzxz    worker2   Ready   Active        bxn1iivy8w7faeugpep76w50j    worker3   Ready   Active</code></pre><p>降低服务的规模:</p><pre><code>$ docker-machine ssh manager1 &quot;docker service scale web=10&quot;web scaled to 10$ docker-machine ssh manager1 &quot;docker service ps web&quot;ID                         NAME        IMAGE         NODE      DESIRED STATE  CURRENT STATE            ERROR61wjx0zaovwtzywwbomnvjo4q  web.1       nginx:latest  worker3   Running        Running 22 minutes ago   bkkujhpbtqab8fyhah06apvca  web.2       nginx:latest  manager1  Shutdown       Shutdown 54 seconds ago  09zkslrkgrvbscv0vfqn2j5dw  web.3       nginx:latest  manager1  Running        Running 11 minutes ago   4dlmy8k72eoza9t4yp9c9pq0w  web.4       nginx:latest  manager2  Running        Running 11 minutes ago   6yqabr8kajx5em2auvfzvi8wi  web.5       nginx:latest  manager3  Running        Running 11 minutes ago   21x7sn82883e7oymz57j75q4q  web.6       nginx:latest  manager2  Running        Running 11 minutes ago   8so0xi55kqimch2jojfdr13qk  web.7       nginx:latest  worker3   Running        Running 7 minutes ago    14555mvu3zee6aek4dwonxz3f   \_ web.7   nginx:latest  worker1   Shutdown       Shutdown 7 minutes ago   1q8imt07i564bm90at3r2w198  web.8       nginx:latest  manager1  Running        Running 11 minutes ago   encwziari9h78ue32v5pjq9jv  web.9       nginx:latest  worker3   Shutdown       Shutdown 54 seconds ago  aivwszsjhhpky43t3x7o8ezz9  web.10      nginx:latest  worker2   Shutdown       Shutdown 54 seconds ago  738jlmoo6tvrkxxar4gbdogzf  web.11      nginx:latest  worker2   Running        Running 7 minutes ago    457fsqomatl1lgd9qbz2dcqsb   \_ web.11  nginx:latest  worker1   Shutdown       Shutdown 7 minutes ago   7chhofuj4shhqdkwu67512h1b  web.12      nginx:latest  worker2   Running        Running 11 minutes ago   4h7zcsktbku7peh4o32mw4948  web.13      nginx:latest  manager3  Running        Running 7 minutes ago    7dynic159wyouch05fyiskrd0   \_ web.13  nginx:latest  worker1   Shutdown       Shutdown 7 minutes ago   7zg9eki4610maigr1xwrx7zqk  web.14      nginx:latest  manager3  Shutdown       Shutdown 54 seconds ago  4z2c9j20gwsasosvj7mkzlyhc  web.15      nginx:latest  manager2  Shutdown       Shutdown 54 seconds ago  </code></pre><p>现在重新把worker1 恢复为在线状态并且显示它的状态:</p><pre><code>$ docker-machine ssh manager1 &quot;docker node update --availability active worker1&quot;worker1$ docker-machine ssh manager1 &quot;docker node inspect worker1 --pretty&quot;ID:            8awcmkj3sd9nv1pi77i6mdb1iHostname:        worker1Joined at:        2016-08-23 22:30:15.556517377 +0000 utcStatus: State:            Ready Availability:        ActivePlatform: Operating System:    linux Architecture:        x86_64Resources: CPUs:            1 Memory:        995.9 MiBPlugins:  Network:        bridge, host, null, overlay  Volume:        localEngine Version:        17.03.0-ceEngine Labels: - provider = virtualbox</code></pre><p>现在把manager1 leader节点,从Swarm中移除:</p><pre><code>$ docker-machine ssh manager1 &quot;docker swarm leave --force&quot;Node left the swarm. </code></pre><p>等待30秒来确定生效.Swarm仍然可用,但是必须重新选举一个新的leader.这会自动发生.</p><pre><code>$ docker-machine ssh manager2 &quot;docker node ls&quot;ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS3cq6idpysa53n6a21nqe0924h    manager3  Ready   Active        Reachable64swze471iu5silg83ls0bdip    manager1  Down    Active        Unreachable7eljvvg0icxlw20od5f51oq8t *  manager2  Ready   Active        Leader8awcmkj3sd9nv1pi77i6mdb1i    worker1   Ready   Active        avu80ol573rzepx8ov80ygzxz    worker2   Ready   Active        bxn1iivy8w7faeugpep76w50j    worker3   Ready   Active</code></pre><p>可以看到manager1变为Down 并且 Unreachable ,并且manager2已经被选举为leader.同样简单的方式移除一个service:</p><pre><code>$ docker-machine ssh manager2 &quot;docker service rm web&quot;web</code></pre><h2 id="Cleanup"><a href="#Cleanup" class="headerlink" title="Cleanup"></a>Cleanup</h2><pre><code>$ ./swarm-node-vbox-teardown.shStopping &quot;manager3&quot;...Stopping &quot;manager2&quot;...Stopping &quot;worker1&quot;...Stopping &quot;manager1&quot;...Stopping &quot;worker3&quot;...Stopping &quot;worker2&quot;...Machine &quot;manager3&quot; was stopped.Machine &quot;manager1&quot; was stopped.Machine &quot;manager2&quot; was stopped.Machine &quot;worker2&quot; was stopped.Machine &quot;worker1&quot; was stopped.Machine &quot;worker3&quot; was stopped.About to remove worker1, worker2, worker3, manager1, manager2, manager3Are you sure? (y/n): ySuccessfully removed worker1Successfully removed worker2Successfully removed worker3Successfully removed manager1Successfully removed manager2Successfully removed manager3</code></pre><h2 id="Next-Steps"><a href="#Next-Steps" class="headerlink" title="Next Steps"></a>Next Steps</h2><p>更多详细信息查看<a href="https://docs.docker.com/engine/swarm/" target="_blank" rel="external">Docker Swarm Mode 文档</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Note:这个教程使用Docker Machine 来模拟多台机器运行的情况.有一种更简单的方式来学习swarm mode,那就是通过&lt;a href=&quot;http://training.play-with-docker.com/swarm-mode-intro/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Play with Docker&lt;/a&gt;.这个教程因为历史原因保留下来，并且同样因为当你真的想要使用自己的机器来学习swarm时.&lt;/p&gt;
    
    </summary>
    
    
      <category term="docker" scheme="http://www.zhz.gift/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>2.0用Docker运行web项目</title>
    <link href="http://www.zhz.gift/2018/02/12/2.0%E7%94%A8Docker%E8%BF%90%E8%A1%8Cweb%E9%A1%B9%E7%9B%AE/"/>
    <id>http://www.zhz.gift/2018/02/12/2.0用Docker运行web项目/</id>
    <published>2018-02-12T03:07:42.000Z</published>
    <updated>2018-02-12T03:03:44.797Z</updated>
    
    <content type="html"><![CDATA[<p>在<a href="">1.0运行你的第一个容器</a>中我们已经顺利让docker运行起来，并且熟悉了一些术语的含义.通过这些基础，我们终于可以实践一些更有意义的东西——用Docker部署web项目.</p><a id="more"></a><h2 id="在容器中运行静态web网站"><a href="#在容器中运行静态web网站" class="headerlink" title="在容器中运行静态web网站"></a>在容器中运行静态web网站</h2><p>Note: 本节示例网站文件请点击<a href="https://github.com/docker/labs/tree/master/beginner/static-site" target="_blank" rel="external">这里</a>.</p><p>让我们从初始步骤开始.首先,我们使用Docker在容器中运行一个静态网站.这个网站是基于一个已存在的镜像.我们将从Docker Store拉取Docker镜像，运行容器，并且看到它是怎么建立 web server的.</p><p>你将要使用的镜像是一个单页网站，并且为了这个demo示范，已经创建完毕并且在Docker Store中可用，存储路径为dockersamples/static-site.你可以直接使用docker run命令下载并且运行这个镜像.如下:</p><pre><code>$ docker run -d dockersamples/static-site</code></pre><p>Note: 这个当前版本的镜像必须添加-d 标识符才能运行.-d 标识符能够开启<strong>detached</strong>模式,它能从terminal/shell 终端 分派运行中的容器并且在容器启动后返回提示.我们正在调试这个镜像，至于现在，使用-d，即使它是你的第一个例子..(<del>好屌</del>)</p><p>该命令运行后,首先由于该镜像并不存在于你的主机上,所以Docker守护进程首先会从registry(Docker store)尝试拉取它然后再让它以容器的方式运行起来.</p><p>服务器运行起来后，如何访问网站？网站在哪个端口上运行？更重要的是,如何在我们的主机机器上面直接访问容器.</p><p>事实上，你可能还回答不了其中任意一个问题:)(<del>好想打死你</del>),在这种情况下,客户端并未告诉Docker Engine 去发布任何端口,所以你需要重新运行docker run命令去添加这个命令.</p><p>让我们重新运行命令，并添加一些新标识符去发布端口并且传递你的名字给容器，以自定义展示的信息.我们将会再次使用-d 选项在detached mode下运行容器.</p><p>首先，通过<strong>container ID</strong>停止你正在运行的容器.</p><p>因为之前我们已经在detached mode下运行容器,所以我们不需要开启其它的terminal来完成终止操作.运行<strong>docker ps</strong>命令来查看运行中的容器.</p><pre><code>$ docker psCONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS               NAMESa7a0e504ca3e        dockersamples/static-site   &quot;/bin/sh -c &apos;cd /usr/&quot;   28 seconds ago      Up 26 seconds       80/tcp, 443/tcp     stupefied_mahavira</code></pre><p>检查CONTAINER ID那一列.接下来通过CONTAINER ID来停止运行中的容器,并且移除掉它.</p><pre><code>$ docker stop a7a0e504ca3e$ docker rm   a7a0e504ca3e </code></pre><p>Note: 一个很cool的特性是你不需要指定整个CONTAINER ID.你可以只指定CONTAINER ID初始的几个字符，并且如果这几个字符在所有你运行的容器当中是唯一的话，那么Docker 客户端会自动获取到该容器.</p><pre><code>$ docker run --name static-site -e AUTHOR=&quot;Your Name&quot; -d -P dockersamples/static-sitee61d12292d69556eabe2a44c16cbd54486b2527e2ce4f95438e504afb7b02810</code></pre><p>在上面的命令当中:</p><ul><li>-d 将会从我们的terminal以detached模式创建容器.</li><li>-P 将会发布所有暴露的容器端口到Docker主机的随机端口上.</li><li>-e 是你传递环境变量(environment variables)给容器的方式</li><li>–name 允许你指定一个容器的名字 </li><li>AUTHOR 是环境变量的名字并且”Your Name” 可以由你进行自定义.</li></ul><p>现在你可以通过<strong>docker port</strong>命令看到端口了.</p><pre><code>$ docker port static-site443/tcp -&gt; 0.0.0.0:3277280/tcp -&gt; 0.0.0.0:32773</code></pre><p>如果你正在运行的是<strong>Docker for Mac</strong>,<strong>Docker for Windows</strong>,或者<strong>Docker on Linux</strong>,你可以打开 <a href="http://localhost:[YOUR_PORT_FOR" target="_blank" rel="external">http://localhost:[YOUR_PORT_FOR</a> 80/tcp].在我们的例子中就是<a href="http://localhost:32773" target="_blank" rel="external">http://localhost:32773</a>.</p><p>如果你是在Mac或者Windows上面使用Docker机器，你可以通过<strong>docker-machine</strong>命令行找到hostname.如下(假设你使用的是默认机器)</p><pre><code>$ docker-machine ip default192.168.99.100</code></pre><p>你可以打开 http://<your_ipaddress>:[YOUR_PORT_FOR 80/tcp] 去访问的网站.在我们的例子中就是:<a href="http://192.168.99.100:32773" target="_blank" rel="external">http://192.168.99.100:32773</a>.</your_ipaddress></p><p>你可以在同一时间运行第二个web服务器，制定一个自定义的host端口去映射你的对应容器的webserver.</p><pre><code>$ docker run --name static-site-2 -e AUTHOR=&quot;Your Name&quot; -d -p 8888:80 dockersamples/static-site</code></pre><p>部署它在一个真正的服务器上，你只需要安装Docker，并且通过上述docker命令运行(就像在这个例子中你可以看到AUTHOR是你传递给Docker的那个环境变量)</p><p>现在你已经知道了如何在一个Docker容器当中运行webserver，如何创建你自己的Docker镜像？这将是我们在下一小节当中探索的问题.</p><p>但现在首先停止并移除容器.</p><pre><code>$ docker stop static-site</code></pre><p>$ docker rm static-site</p><p>使用简略语法移除第二个网站:</p><pre><code>$ docker rm -f static-site-2</code></pre><p>运行<strong>docker ps</strong>命令确认容器已经正确停止了.</p><h2 id="Docker-镜像"><a href="#Docker-镜像" class="headerlink" title="Docker 镜像"></a>Docker 镜像</h2><p>在这个小节中，让我们更加深入的了解Docker images究竟是什么东西.你将会建立自己的镜像，使用这个镜像在你的本地运行一个应用，然后最终，推送一些你自己的镜像到Docker Cloud.</p><p>Docker images 是容器的基础.在上一个例子中,你从registry(docker store)拉取 dockersamples/static-site 镜像并且让Docker 客户端基于这个镜像运行一个容器.通过运行<strong>docker images</strong>命令来查看你系统上本地可用的镜像列表.</p><pre><code>$ docker imagesREPOSITORY             TAG                 IMAGE ID            CREATED             SIZEdockersamples/static-site   latest              92a386b6e686        2 hours ago        190.5 MBnginx                  latest              af4b3d7d5401        3 hours ago        190.5 MBpython                 2.7                 1c32174fd534        14 hours ago        676.8 MBpostgres               9.4                 88d845ac7a88        14 hours ago        263.6 MBcontainous/traefik     latest              27b4e0c6b2fd        4 days ago          20.75 MBnode                   0.10                42426a5cba5f        6 days ago          633.7 MBredis                  latest              4f5f397d4b7c        7 days ago          177.5 MBmongo                  latest              467eb21035a8        7 days ago          309.7 MBalpine                 3.3                 70c557e50ed6        8 days ago          4.794 MBjava                   7                   21f6ce84e43c        8 days ago          587.7 MB</code></pre><p>上述是我从registry拉取的一系列镜像,以及一些我自己创建的(我们很快会看到如何做的).在你的机器上可能是一个不同的镜像列表.TAG 指的是这个镜像特别的snapshot 快照版本，ID则是这个镜像唯一的标识.</p><p>简单地说，你可以把一个镜像理解为类似git仓库的东西，镜像可以像git一样提交commit并且有多个版本.当你没有提供一个指定的版本，客户端默认会是最新的.</p><p>例如，你可以指定一个特定版本的ubuntu镜像如下所示:</p><pre><code>$ docker pull ubuntu:12.04</code></pre><p>如果你没有指定一个特定版本的镜像,就像提到的那样,Dcoker 客户端将会默认选择最新版本的.</p><p>如例子所示,docker 将会拉取一个命名为: ubuntu:latest 的镜像:</p><pre><code>$ docker pull ubuntu</code></pre><p>获取Docker image的途径，一是从registry(就比如Docker Store),二是自己创建.在Docker Store中有成百上千的镜像等你临幸.或者你也可以直接通过<strong>docker search</strong>命令来搜索镜像.</p><p>镜像之间的一个重要区别是关于 base images(基础镜像)和child images(子镜像).</p><ul><li><p>Base images 没有父级镜像,通常是操作系统的镜像，像ubuntu,alpine 或者debian.</p></li><li><p>Child images 是在base images的基础上构建起来的，通常添加了一些额外的功能.</p></li></ul><p>另一个关键概念是 official images (官方镜像) 和 user images(用户镜像).<br>(它们都可以是基础镜像或者子镜像)</p><ul><li>Official images 是Docker 官方审核认可的 镜像.Docker,一个负责审核和发布所有官方仓库内容的团队.上述的一系列镜像,python,node,alpine 和 nginx镜像都是官方(base)镜像.通过查看官方镜像文档来了解更多官方镜像.(<a href="https://docs.docker.com/docker-hub/official_repos/" target="_blank" rel="external">official Images Documentation</a>)</li><li>User images 是由用户创建和共享的镜像.它们是在base images的基础上构建并添加额外的功能.典型的它们都是以 <strong>user/image-name</strong>格式来命名.用户名一般是你的Docker Store用户名或者组织名.</li></ul><h2 id="创建你的首个镜像"><a href="#创建你的首个镜像" class="headerlink" title="创建你的首个镜像"></a>创建你的首个镜像</h2><p>Note: 这个小节的示例代码在<a href="https://github.com/docker/labs/tree/master/beginner/flask-app" target="_blank" rel="external">flask-app</a> 路径下的仓库.</p><p>现在你已经对镜像有了进一步的理解了，是时候创建你自己的镜像了.我们的目标是创建一个镜像并在沙盒中运行一个<a href="http://flask.pocoo.org/" target="_blank" rel="external">Flash</a>应用.</p><p>这个练习的目的是创建一个Docker镜像并运行一个Flask app.</p><p>我们首先一次性领取一个用Python Flask构建的随机生成猫图片的组件，然后通过编写一个Dockerfile 来<strong>dockerizing</strong>它.最后,我们构建镜像,然后运行它.</p><p>具体步骤如下:</p><ul><li>创建一个展示随机猫图片的Python Flask app.</li><li>编写一个Dockerfile文件</li><li>构建镜像</li><li>运行镜像</li><li>Dockerfile 命令总结</li></ul><h3 id="创建一个展示随机猫图片的Python-Flask-app"><a href="#创建一个展示随机猫图片的Python-Flask-app" class="headerlink" title="创建一个展示随机猫图片的Python Flask app"></a>创建一个展示随机猫图片的Python Flask app</h3><p>创建一个flask-app目录,然后在该目录下创建以下文件:</p><ul><li>app.py</li><li>requirements.txt</li><li>templates/index.html</li><li>Dockerfile</li></ul><h3 id="app-py"><a href="#app-py" class="headerlink" title="app.py"></a>app.py</h3><p>用以下内容创建app.py:</p><pre><code>from flask import Flask, render_templateimport randomapp = Flask(__name__)# list of cat imagesimages = [    &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr05/15/9/anigif_enhanced-buzz-26388-1381844103-11.gif&quot;,    &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr01/15/9/anigif_enhanced-buzz-31540-1381844535-8.gif&quot;,    &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr05/15/9/anigif_enhanced-buzz-26390-1381844163-18.gif&quot;,    &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr06/15/10/anigif_enhanced-buzz-1376-1381846217-0.gif&quot;,    &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr03/15/9/anigif_enhanced-buzz-3391-1381844336-26.gif&quot;,    &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr06/15/10/anigif_enhanced-buzz-29111-1381845968-0.gif&quot;,    &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr03/15/9/anigif_enhanced-buzz-3409-1381844582-13.gif&quot;,    &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr02/15/9/anigif_enhanced-buzz-19667-1381844937-10.gif&quot;,    &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr05/15/9/anigif_enhanced-buzz-26358-1381845043-13.gif&quot;,    &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr06/15/9/anigif_enhanced-buzz-18774-1381844645-6.gif&quot;,    &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr06/15/9/anigif_enhanced-buzz-25158-1381844793-0.gif&quot;,    &quot;http://ak-hdl.buzzfed.com/static/2013-10/enhanced/webdr03/15/10/anigif_enhanced-buzz-11980-1381846269-1.gif&quot;]@app.route(&apos;/&apos;)def index():    url = random.choice(images)    return render_template(&apos;index.html&apos;, url=url)if __name__ == &quot;__main__&quot;:    app.run(host=&quot;0.0.0.0&quot;)</code></pre><h3 id="requirements-txt"><a href="#requirements-txt" class="headerlink" title="requirements.txt"></a>requirements.txt</h3><p>为了为我们的app安装所需的Python模块,我们需要创建一个requirements.txt文件并且添加如下内容:</p><pre><code>Flask==0.10.1      </code></pre><h3 id="templates-index-html"><a href="#templates-index-html" class="headerlink" title="templates/index.html"></a>templates/index.html</h3><p>创建一个命名为templates的目录并且在其中创建一个index.html 文件，具体内容如下:</p><pre><code>&lt;html&gt;  &lt;head&gt;    &lt;style type=&quot;text/css&quot;&gt;      body {        background: black;        color: white;      }      div.container {        max-width: 500px;        margin: 100px auto;        border: 20px solid white;        padding: 10px;        text-align: center;      }      h4 {        text-transform: uppercase;      }    &lt;/style&gt;  &lt;/head&gt;  &lt;body&gt;    &lt;div class=&quot;container&quot;&gt;      &lt;h4&gt;Cat Gif of the day&lt;/h4&gt;      &lt;img src=&quot;{{url}}&quot; /&gt;      &lt;p&gt;&lt;small&gt;Courtesy: &lt;a href=&quot;http://www.buzzfeed.com/copyranter/the-best-cat-gif-post-in-the-history-of-cat-gifs&quot;&gt;Buzzfeed&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;    &lt;/div&gt;  &lt;/body&gt;&lt;/html&gt;</code></pre><h2 id="编写一个Dockerfile文件"><a href="#编写一个Dockerfile文件" class="headerlink" title="编写一个Dockerfile文件"></a>编写一个Dockerfile文件</h2><p>我们想要为这个web app创建一个Docker镜像.就像上述提到的,所有的用户镜像都是基于基础镜像.因为我们的应用是用Python编写的,我们将会在Alpine的基础上构建我们的Python镜像.完成这一点我们需要使用一个Dockerfile.</p><p><a href="https://docs.docker.com/engine/reference/builder/" target="_blank" rel="external">Dockerfile</a>实际上只是一个包含了一系列docker指令的text文件,当创建镜像的时候,docker 守护进程会从后台调用.Dockerfile包含了所有Docker应该如何去运行这个app的所有信息 - 一个基础Docker 镜像从哪里运行,你项目代码的路径,它拥有的所有依赖 和启动是运行的命令.这是一个镜像创建过程自动化的最普遍方式.这种方式最大的优点是你在Dockerfile编写的<a href="https://docs.docker.com/engine/reference/builder/" target="_blank" rel="external">命令</a>完全等同于它们的linux命令.这意味着你不用去学习新的语法来创建你的Dockerfile文件.</p><p>1.创建一个命名为Dockerfile的文件,并添加如下描述内容.</p><p>我们将通过<strong>From</strong>关键字指令指定我们的基础镜像:</p><pre><code>FROM alpine:3.5</code></pre><p>2.下一步骤通常是编写复制文件和安装依赖的指令.但首先我们需要安装Python pip 包 到alpine linux发布版本.其它依赖安装也是同样，包括python interpreter 解释器.添加如下<a href="https://docs.docker.com/engine/reference/builder/#run" target="_blank" rel="external">RUN</a>命令:</p><pre><code>RUN apk add --update py2-pip</code></pre><p>3.添加 Flask Application的组成文件</p><p>安装所有我们app运行所需的Python requirements.通过以下命令完成:</p><pre><code>COPY requirements.txt /usr/src/app/RUN pip install --no-cache-dir -r /usr/src/app/requirements.txt</code></pre><p>通过<a href="https://docs.docker.com/engine/reference/builder/#copy" target="_blank" rel="external">COPY</a> 命令复制你早期创建的文件到我们的镜像当中.</p><pre><code>COPY app.py /usr/src/app/COPY templates/index.html /usr/src/app/templates/</code></pre><p>4.指定需要暴露的接口.flask app运行的端口是5000.</p><pre><code>EXPOSE 5000</code></pre><p>5.最后的步骤是运行我们的应用-<strong>python ./app.py</strong>.使用<a href="https://docs.docker.com/engine/reference/builder/#cmd" target="_blank" rel="external">CMD</a>指令:</p><pre><code>CMD [&quot;python&quot;, &quot;/usr/src/app/app.py&quot;]</code></pre><p>CMD命令的主要目的是告诉容器当它启动时默认应该运行哪些指令.</p><p>6.验证你的Dockerfile文件.</p><p>我们的Dockerfile文件终于准备好了.内容汇总如下:</p><pre><code># our base imageFROM alpine:3.5# Install python and pipRUN apk add --update py2-pip# install Python modules needed by the Python appCOPY requirements.txt /usr/src/app/RUN pip install --no-cache-dir -r /usr/src/app/requirements.txt# copy files required for the app to runCOPY app.py /usr/src/app/COPY templates/index.html /usr/src/app/templates/# tell the port number the container should exposeEXPOSE 5000# run the applicationCMD [&quot;python&quot;, &quot;/usr/src/app/app.py&quot;]</code></pre><h3 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h3><p>现在你已经有了自己的Dockerfile,你可以构建自己的镜像.<strong>docker build</strong>命令依据Dockerfile完成创建docker image的一系列复杂任务.</p><p>当你运行以下的<strong>docker build</strong>命令,确保用你的用户名去替换 <strong><your_username></your_username></strong> .这个用户名必须跟你在<a href="https://cloud.docker.com/" target="_blank" rel="external">Docker Cloud</a>注册创建的用户名保持一致.如果你还没有完成这一步,请先到Docker Cloud创建一个账户.</p><p><strong>docker build</strong> 命令相当简单 - 它提供一个可选的-t 参数 和包含Dockerfile文件的路径 - <strong>.</strong> 表明当前路径:</p><pre><code>$ docker build -t &lt;YOUR_USERNAME&gt;/myfirstapp .Sending build context to Docker daemon 9.728 kBStep 1 : FROM alpine:latest ---&gt; 0d81fc72e790Step 2 : RUN apk add --update py-pip ---&gt; Running in 8abd4091b5f5fetch http://dl-4.alpinelinux.org/alpine/v3.3/main/x86_64/APKINDEX.tar.gzfetch http://dl-4.alpinelinux.org/alpine/v3.3/community/x86_64/APKINDEX.tar.gz(1/12) Installing libbz2 (1.0.6-r4)(2/12) Installing expat (2.1.0-r2)(3/12) Installing libffi (3.2.1-r2)(4/12) Installing gdbm (1.11-r1)(5/12) Installing ncurses-terminfo-base (6.0-r6)(6/12) Installing ncurses-terminfo (6.0-r6)(7/12) Installing ncurses-libs (6.0-r6)(8/12) Installing readline (6.3.008-r4)(9/12) Installing sqlite-libs (3.9.2-r0)(10/12) Installing python (2.7.11-r3)(11/12) Installing py-setuptools (18.8-r0)(12/12) Installing py-pip (7.1.2-r0)Executing busybox-1.24.1-r7.triggerOK: 59 MiB in 23 packages ---&gt; 976a232ac4adRemoving intermediate container 8abd4091b5f5Step 3 : COPY requirements.txt /usr/src/app/ ---&gt; 65b4be05340cRemoving intermediate container 29ef53b58e0fStep 4 : RUN pip install --no-cache-dir -r /usr/src/app/requirements.txt ---&gt; Running in a1f26ded28e7Collecting Flask==0.10.1 (from -r /usr/src/app/requirements.txt (line 1))  Downloading Flask-0.10.1.tar.gz (544kB)Collecting Werkzeug&gt;=0.7 (from Flask==0.10.1-&gt;-r /usr/src/app/requirements.txt (line 1))  Downloading Werkzeug-0.11.4-py2.py3-none-any.whl (305kB)Collecting Jinja2&gt;=2.4 (from Flask==0.10.1-&gt;-r /usr/src/app/requirements.txt (line 1))  Downloading Jinja2-2.8-py2.py3-none-any.whl (263kB)Collecting itsdangerous&gt;=0.21 (from Flask==0.10.1-&gt;-r /usr/src/app/requirements.txt (line 1))  Downloading itsdangerous-0.24.tar.gz (46kB)Collecting MarkupSafe (from Jinja2&gt;=2.4-&gt;Flask==0.10.1-&gt;-r /usr/src/app/requirements.txt (line 1))  Downloading MarkupSafe-0.23.tar.gzInstalling collected packages: Werkzeug, MarkupSafe, Jinja2, itsdangerous, Flask  Running setup.py install for MarkupSafe  Running setup.py install for itsdangerous  Running setup.py install for FlaskSuccessfully installed Flask-0.10.1 Jinja2-2.8 MarkupSafe-0.23 Werkzeug-0.11.4 itsdangerous-0.24You are using pip version 7.1.2, however version 8.1.1 is available.You should consider upgrading via the &apos;pip install --upgrade pip&apos; command. ---&gt; 8de73b0730c2Removing intermediate container a1f26ded28e7Step 5 : COPY app.py /usr/src/app/ ---&gt; 6a3436fca83eRemoving intermediate container d51b81a8b698Step 6 : COPY templates/index.html /usr/src/app/templates/ ---&gt; 8098386bee99Removing intermediate container b783d7646f83Step 7 : EXPOSE 5000 ---&gt; Running in 31401b7dea40 ---&gt; 5e9988d87da7Removing intermediate container 31401b7dea40Step 8 : CMD python /usr/src/app/app.py ---&gt; Running in 78e324d26576 ---&gt; 2f7357a0805dRemoving intermediate container 78e324d26576Successfully built 2f7357a0805d</code></pre><p>如果你并没有alpine:3.5的镜像,客户端将会首先拉取这个镜像，然后再创建你的镜像.因此,你运行命令之后的输出可能会稍有不同.如果一切运行正常,你的镜像就应该创建准备完毕.运行<strong>docker images</strong> 命令查看你的镜像(<your_username>/myfirstapp)是否展示.</your_username></p><h3 id="运行你的镜像"><a href="#运行你的镜像" class="headerlink" title="运行你的镜像"></a>运行你的镜像</h3><p>下一步骤是运行你的镜像并且查看它是否正常工作.</p><pre><code>$ docker run -p 8888:5000 --name myfirstapp YOUR_USERNAME/myfirstapp * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)</code></pre><p>访问 <a href="http://localhost:8888" target="_blank" rel="external">http://localhost:8888</a> 确认你的app是否存活.<br>注意: 如果你使用Docker Machine,你可能需要打开另一个终端并且使用<strong>docker-machine ip default</strong>命令来决定容器的ip地址.</p><p>点击在web浏览器的刷新按钮来查看更多猫的图片.</p><h3 id="推送你的镜像-push-your-image"><a href="#推送你的镜像-push-your-image" class="headerlink" title="推送你的镜像(push your image)"></a>推送你的镜像(push your image)</h3><p>现在你已经创建并且测试了你的镜像,你可以把它推送到<a href="https://cloud.docker.com/" target="_blank" rel="external">Docker Cloud</a>.</p><p>首先你必须登录到你的Docker Cloud 账户:</p><pre><code>docker login</code></pre><p>输入你的用户名和密码然后执行如下命令:</p><pre><code>docker push YOUR_USERNAME/myfirstapp</code></pre><p>现在你这个容器的工作以及完成了,停止并且移除它因为你不再需要再次使用它了.</p><p>打开另一个终端窗口并且执行如下命令:</p><pre><code>$ docker stop myfirstapp$ docker rm myfirstapp</code></pre><p>或者</p><pre><code>$ docker rm -f myfirstapp</code></pre><h3 id="Dockerfile-命令总结"><a href="#Dockerfile-命令总结" class="headerlink" title="Dockerfile 命令总结"></a>Dockerfile 命令总结</h3><p>这是一个我们在Dockerfile中使用的基础命令的快速总结.</p><ul><li><p><strong>FROM</strong> 是Dockerfile的开头.Dockerfile必须以<strong>FROM</strong>命令开头.镜像是在layers中创建,这意味着你可以使用另一个镜像作为base镜像.<strong>FROM</strong>命令定义你的base layer.它将镜像的名称作为参数.你可以选择是否添加维护者的Docker Cloud用户名和镜像版本，以 username/imagename:version的格式.</p></li><li><p><strong>RUN</strong>是用来构建你创建的镜像.对于每个<strong>RUN</strong>命令来说，Docker将会运行这个命令然后为这个镜像创建新的layer.这种方式你可以你可以轻松回滚你的镜像到邻近的状态.<strong>RUN</strong>指令的语法是在RUN命令后放置shell命令(eg.,RUN mkdir /user/local/foo).这将会自动在一个 /bin/sh shell环境中运行.你可以像这样定义一个不同的shell:<strong>RUN /bin/bash -c ‘mkdir /user/local/foo’</strong></p></li><li><p>COPY 复制本地文件到容器当中.</p></li><li><p>CMD 定义在镜像启动阶段将会运行的命令.不同于<strong>RUN</strong>，这个命令不会为镜像创建新的layer,只是单纯的运行命令.每个Dockerfille/Image只能有一个<strong>CMD</strong>.如果你需要运行多个指令,最好的方式是用<strong>CMD</strong>运行一个script脚本.<strong>CMD</strong>需要你告诉它去哪里运行命令,不像<strong>RUN</strong>.示例如下:</p><pre><code>CMD [&quot;python&quot;, &quot;./app.py&quot;]CMD [&quot;/bin/bash&quot;, &quot;echo&quot;, &quot;Hello World&quot;]</code></pre></li><li><p>EXPOSE 为用户的镜像创建线索，比如ports提供服务.它包含了可以经由<strong>$ docker inspect <container-id></container-id></strong>命令恢复的所有信息.</p></li></ul><p>Note: <strong>EXPOSE</strong>命令实际上并不是让主机上的任何端口变得可访问!相反,这意味着需要通过使用 <strong> $ docker run -p</strong>命令在发布端口</p><ul><li>PUSH 推送你的镜像到Docker Cloud,或一个<a href="https://docs.docker.com/registry/" target="_blank" rel="external">私人的registry</a>.</li></ul><p>Note: 如果你想要了解更多关于Dockerfiles的内容,查看<a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/" target="_blank" rel="external">Best practices for writing Dockerfiles</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在&lt;a href=&quot;&quot;&gt;1.0运行你的第一个容器&lt;/a&gt;中我们已经顺利让docker运行起来，并且熟悉了一些术语的含义.通过这些基础，我们终于可以实践一些更有意义的东西——用Docker部署web项目.&lt;/p&gt;
    
    </summary>
    
    
      <category term="docker" scheme="http://www.zhz.gift/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>3.0部署一个app到Swarm上</title>
    <link href="http://www.zhz.gift/2018/02/12/%E9%83%A8%E7%BD%B2%E4%B8%80%E4%B8%AAapp%E5%88%B0Swarm%E4%B8%8A/"/>
    <id>http://www.zhz.gift/2018/02/12/部署一个app到Swarm上/</id>
    <published>2018-02-12T03:07:42.000Z</published>
    <updated>2018-02-12T03:04:02.610Z</updated>
    
    <content type="html"><![CDATA[<p>这个教程将会通过创建和定制一个投票app来知道你关于swarm上面的部署.<br>按步骤完成教程至关重要，并且确保定制的部分是开放了定制功能的.</p><p>注意：完成这个章节的教程，你需要先完成Docker和git的安装.</p><a id="more"></a><h2 id="Voting-app"><a href="#Voting-app" class="headerlink" title="Voting app"></a>Voting app</h2><p>应用源代码路径<a href="https://github.com/docker/example-voting-app" target="_blank" rel="external">Docker Example Voting App</a>.这个app包含5个组件:</p><ul><li>Python webapp 组件，实现在两个选项之间投票的功能</li><li>Redis queue 收集新的投票</li><li>.NET worker 消费投票并且保存它们在…</li><li>Postgres database 通过Docker volume 来支持</li><li>Node.js webapp 即时展示投票结果</li></ul><p>克隆仓库到你的机器上并且通过cd命令到对应目录下:</p><pre><code>git clone https://github.com/docker/example-voting-app.gitcd example-voting-app</code></pre><h2 id="部署app"><a href="#部署app" class="headerlink" title="部署app"></a>部署app</h2><p>在这首个阶段，我们将会使用在Docker Store中的首个镜像.</p><p>这个app依赖<a href="https://docs.docker.com/engine/swarm/" target="_blank" rel="external">Docker Swarm模式</a>.Swarm mode是嵌入在Docker engine中的集群管理和编排特性.你可以用一个描述你app期望状态的文件来轻松部署到swarm.Swarm允许你运行你的容器在多台机器上.<br>在这个教程中，你可以使用一台机器，或者使用一些像<a href="https://beta.docker.com/" target="_blank" rel="external">Docker for AWS</a>或者<a href="https://beta.docker.com/" target="_blank" rel="external">Docker for Azure</a>来快速的创建多个节点的机器.另外，你还可以使用Docker Machine 在你的部署机器上创建多个本地节点.查看<a href="https://github.com/docker/labs/blob/master/swarm-mode/beginner-tutorial/README.md#creating-the-nodes-and-swarm" target="_blank" rel="external">Swarm Mode lab</a>查询更多相关信息</p><p>首先,创建一个Swarm.</p><pre><code>docker swarm init</code></pre><p>接下来，你将需要一个<a href="https://docs.docker.com/compose" target="_blank" rel="external">Docker Compose</a>文件.你并不需要安装Docker Compose,尽管如果你使用的是Docker for Mac 或者 Docker for Windows的话默认是已经安装的了.然而<strong>docker stack deploy</strong>接受一个Docker Compose 格式的文件.你需要的文件就在Docker Example Voting App的根目录.文件名为docker-stack.yml.你也可以直接复制和粘贴以下内容:</p><pre><code>version: &quot;3&quot;services:  redis:    image: redis:alpine    ports:      - &quot;6379&quot;    networks:      - frontend    deploy:      replicas: 2      update_config:        parallelism: 2        delay: 10s      restart_policy:        condition: on-failure  db:    image: postgres:9.4    volumes:      - db-data:/var/lib/postgresql/data    networks:      - backend    deploy:      placement:        constraints: [node.role == manager]  vote:    image: dockersamples/examplevotingapp_vote:before    ports:      - 5000:80    networks:      - frontend    depends_on:      - redis    deploy:      replicas: 2      update_config:        parallelism: 2      restart_policy:        condition: on-failure  result:    image: dockersamples/examplevotingapp_result:before    ports:      - 5001:80    networks:      - backend    depends_on:      - db    deploy:      replicas: 1      update_config:        parallelism: 2        delay: 10s      restart_policy:        condition: on-failure  worker:    image: dockersamples/examplevotingapp_worker    networks:      - frontend      - backend    deploy:      mode: replicated      replicas: 1      labels: [APP=VOTING]      restart_policy:        condition: on-failure        delay: 10s        max_attempts: 3        window: 120s      placement:        constraints: [node.role == manager]  visualizer:    image: dockersamples/visualizer    ports:      - &quot;8080:8080&quot;    stop_grace_period: 1m30s    volumes:      - /var/run/docker.sock:/var/run/docker.sock    deploy:      placement:        constraints: [node.role == manager]networks:  frontend:  backend:volumes:  db-data:</code></pre><p>首先部署它，然后我们将会深入了解更多细节:</p><pre><code>docker stack deploy --compose-file docker-stack.yml voteCreating network vote_frontendCreating network vote_backendCreating network vote_defaultCreating service vote_voteCreating service vote_resultCreating service vote_workerCreating service vote_redisCreating service vote_db</code></pre><p>验证已经成功部署的堆栈,使用<code>docker stack services vote</code></p><pre><code>docker stack services voteID            NAME         MODE        REPLICAS  IMAGE25wo6p7fltyn  vote_db      replicated  1/1       postgres:9.42ot4sz0cgvw3  vote_worker  replicated  1/1       dockersamples/examplevotingapp_worker:latest9faz4wbvxpck  vote_redis   replicated  2/2       redis:alpineocm8x2ijtt88  vote_vote    replicated  2/2       dockersamples/examplevotingapp_vote:beforep1dcwi0fkcbb  vote_result  replicated  2/2       dockersamples/examplevotingapp_result:before</code></pre><p>如果你查看<code>docker-stack.yml文件</code>,你将会看到文件定义    </p><ul><li>基于Python image的vote container</li><li>基于Node.js image的 result container</li><li>基于redis image的redis container,用以临时存储数据.</li><li>基于.NET image的.NET based worker app</li><li>基于postgres image 的Postgres 容器.</li></ul><p>Compose文件同样定义两个networks,front-tier 和back-tier .每个容器都是被放置在一个或者两个networks.一旦在那些networks中,它们就可以在那个network中以使用service名称的方式在代码中访问其它处于这个network的services.Services可以处于任意数量的networks.Services被它们各自的network所隔离.即使Services处于同一个network中,Services也只能通过name名称去发现彼此.想了解更多networking,点击<a href="https://github.com/docker/labs/tree/master/networking" target="_blank" rel="external">Networking Lab</a>.</p><p>再看一下Compose文件，你会发现它是以:</p><pre><code>version: &quot;3&quot;</code></pre><p>version 3 这个版本号对compose 文件来说非常重要,因为<code>docker stack deploy</code> 命令不支持更早版本的.你将会看到那里同样有个<code>services</code>key,在下面的是一个分割键(<del>不就是一个yml文件么..这么啰嗦</del>)，用来隔离每个services,例如:</p><pre><code>vote:   image: dockersamples/examplevotingapp_vote:before   ports:     - 5000:80   networks:     - frontend   depends_on:     - redis   deploy:     replicas: 2     update_config:       parallelism: 2     restart_policy:       condition: on-failure</code></pre><p><code>image</code>键 指定了你能使用哪个镜像,在这个例子中就是<code>dockersamples/examplevotingapp_vote:before</code>，如果你对Compose足够熟悉,你可能知道有一个<code>build</code>键,用来基于Dockerfile进行构建.然而,<code>docker stack deploy</code>不支持<code>build</code>，所以你需要使用预构建镜像.</p><p>与<code>docker run</code>很相似,你能够定义<code>ports</code> 和 <code>networks</code>.<code>depends_on</code>键用来指定一个service只在另一个service之后才进行部署.在这个例子中<code>vote</code>只在<code>redis</code>之后进行部署.</p><p><code>deploy</code>键是version3 版本新增的.它允许你在部署到Swarm时指定不同的属性.在这个例子中,你指定了需要两个 replicas(复制品),也就是在Swarm上部署两个容器.你可以指定其它属性,像什么时候去重启(restart),使用什么样的<a href="https://docs.docker.com/engine/reference/builder/#healthcheck" target="_blank" rel="external">healthcheck</a>,配置约束(placement constraints),资源(resources)等等.</p><h2 id="测试运行"><a href="#测试运行" class="headerlink" title="测试运行"></a>测试运行</h2><p>现在app已经开始运行了,你可以通过<a href="http://localhost:5000来进行访问" target="_blank" rel="external">http://localhost:5000来进行访问</a>.</p><p>点击其中一个进行投票.你可以通过<a href="http://localhost:5001来查看结果" target="_blank" rel="external">http://localhost:5001来查看结果</a>.</p><p>NOTE: 如果你是在云环境运行这个教程，像AWS,Azure,Digital Ocean,或者GCE 你将不能直接通过localhost或者127.0.0.1来进行访问.一个变通的手段是利用ssh port forwarding.下面是Mac OS的一个例子.这同样适用于Windows 和Putty 用户.</p><pre><code>$ ssh -L 5000:localhost:5000 &lt;ssh-user&gt;@&lt;CLOUD_INSTANCE_IP_ADDRESS&gt;</code></pre><h2 id="定做app"><a href="#定做app" class="headerlink" title="定做app"></a>定做app</h2><p>在这个步骤，你将会定制app并且重新部署它。我们将会使用相同的图片，但是通过使用<code>after</code>标签将投票选项cats和dogs换成Java和.NET.</p><h3 id="改变使用的图片"><a href="#改变使用的图片" class="headerlink" title="改变使用的图片"></a>改变使用的图片</h3><p>重新修改<code>docker-stack.yml</code>文件,将<code>vote</code>和<code>result</code> 图片修改为<code>after</code>标签,如下:</p><pre><code>vote:   image: dockersamples/examplevotingapp_vote:after   ports:     - 5000:80   networks:     - frontend   depends_on:     - redis   deploy:     replicas: 2     update_config:       parallelism: 2     restart_policy:       condition: on-failure result:   image: dockersamples/examplevotingapp_result:after   ports:     - 5001:80   networks:     - backend   depends_on:     - db   deploy:     replicas: 2     update_config:       parallelism: 2       delay: 10s     restart_policy:       condition: on-failure</code></pre><h3 id="重新部署"><a href="#重新部署" class="headerlink" title="重新部署"></a>重新部署</h3><p>重新部署跟之前的操作一样.</p><pre><code>docker stack deploy --compose-file docker-stack.yml vote</code></pre><h3 id="测试运行-1"><a href="#测试运行-1" class="headerlink" title="测试运行"></a>测试运行</h3><p>再次查看app运行界面结果.</p><h3 id="移除堆栈"><a href="#移除堆栈" class="headerlink" title="移除堆栈"></a>移除堆栈</h3><p>从swarm移除堆栈.</p><pre><code>docker stack rm vote</code></pre><h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><p>现在你已经构建了一些镜像并且把它们推送到Docker Cloud，并且学习到基础的Swarm mode,你可以通过查看<a href="https://docs.docker.com/" target="_blank" rel="external">the documentation</a>文档了解更多信息.并且如果你需要任何帮助的话，可以访问<a href="https://forums.docker.com/" target="_blank" rel="external">Docker Forums</a>或者<a href="https://stackoverflow.com/tags/docker/" target="_blank" rel="external">StackOverflow</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这个教程将会通过创建和定制一个投票app来知道你关于swarm上面的部署.&lt;br&gt;按步骤完成教程至关重要，并且确保定制的部分是开放了定制功能的.&lt;/p&gt;
&lt;p&gt;注意：完成这个章节的教程，你需要先完成Docker和git的安装.&lt;/p&gt;
    
    </summary>
    
    
      <category term="docker" scheme="http://www.zhz.gift/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>1.0 运行你的第一个容器</title>
    <link href="http://www.zhz.gift/2018/02/04/%E8%BF%90%E8%A1%8C%E4%BD%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%AE%B9%E5%99%A8/"/>
    <id>http://www.zhz.gift/2018/02/04/运行你的第一个容器/</id>
    <published>2018-02-03T16:07:42.000Z</published>
    <updated>2018-03-15T14:41:40.283Z</updated>
    
    <content type="html"><![CDATA[<h2 id="运行你的第一个容器"><a href="#运行你的第一个容器" class="headerlink" title="运行你的第一个容器"></a>运行你的第一个容器</h2><p>现在你已经准备好了所有的东西,是时候开始实践了.<br>在这个章节,我们将要运行一个 Alpine Linux 容器(一个轻量级的linux 发布版本)在你的系统上并且尝试一下docker的运行命令.</p><a id="more"></a><p>首先运行以下命令:</p><pre><code>$ docker pull alpine</code></pre><p>Note:根据你在系统中安装docker的方式,在运行以上命令后你可能会看到一个ermission denied的错误.尝试在安装教程中的命令去验证你的安装.如果你是Linux系统,你可能需要在你的命令前面加上sudo.或者你可以创建一个docker group来拜托这个问题.</p><p>pull命令从Dcoker仓库获取 alpine 镜像并且保存在我们的系统中.你可以使用<strong>docker images</strong> 命令来查看在你系统中的所有镜像.</p><pre><code>$ docker images</code></pre><table><thead><tr><th style="text-align:center">REPOSITORY</th><th style="text-align:center">TAG</th><th style="text-align:center">IMAGE ID</th><th style="text-align:center">CREATED</th><th style="text-align:center">VIRTUAL SIZE</th></tr></thead><tbody><tr><td style="text-align:center">alpine</td><td style="text-align:center">latest</td><td style="text-align:center">c51f86c28340</td><td style="text-align:center">4 weeks ago</td><td style="text-align:center">1.109 MB</td></tr><tr><td style="text-align:center">hello-world</td><td style="text-align:center">latest</td><td style="text-align:center">690ed74de00f</td><td style="text-align:center">5 months ago</td><td style="text-align:center">960 B</td></tr></tbody></table><h2 id="Docker-Run"><a href="#Docker-Run" class="headerlink" title="Docker Run"></a>Docker Run</h2><p>接下来基于这个镜像运行一个Docker 容器.只需要通过 <strong>docker run</strong>命令我们就能做到这一点.</p><pre><code>$ docker run alpine ls -ltotal 48drwxr-xr-x    2 root     root          4096 Mar  2 16:20 bindrwxr-xr-x    5 root     root           360 Mar 18 09:47 devdrwxr-xr-x   13 root     root          4096 Mar 18 09:47 etcdrwxr-xr-x    2 root     root          4096 Mar  2 16:20 homedrwxr-xr-x    5 root     root          4096 Mar  2 16:20 lib............</code></pre><ol><li><p>当你运行 <strong>docker run</strong>命令的时候,Docker 客户端联系Docker守护进程.</p></li><li><p>Docker 守护进程会首先检查所有本地存储,确定镜像(本例是alpine)在本地可用,如果不可用的话，从Docker Store 下载.(直到我们发布<strong>docker pull alpine</strong> 之前,下载步骤不是必须的)</p></li><li><p>Docker 守护进程创建容器接下来在容器内运行一个命令.</p></li><li><p>Docker守护进程将该命令的输出以流的形式返回给客户端.</p></li></ol><p>接下来运行如下命令:</p><pre><code>$ docker run alpine echo &quot;hello from alpine&quot;hello from alpine</code></pre><p>“hello from alpine”就是实际的输出.在这个场景,Docker 客户端忠实地在我们的alpine容器运行echo命令然后自动退出.如果你多加注意的话，你会发现所有的一切发生的相当快.镜像在虚拟机中启动,运行一个命令然后销毁它.现在你知道为什么容器运行速度如此之快！</p><p>接下来运行另一个命令:</p><pre><code>$ docker run alpine /bin/sh</code></pre><p>什么都没有发生,这些交互式shell会在运行任意scripted命令之后退出.除非它们是在一个交互式终端中运行 - 所以为了让它不自动退出，你需要用<strong>docker run -it alpine /bin/sh</strong>命令来代替.</p><p>你现在便处于容器 shell 当中 ,并且可以尝试使用一些命令比如:ls -l,uname -a 或者其它等等.通过<strong>exit</strong>命令来退出容器.</p><p><strong>docker ps</strong>命令向你展示所有正确运行的容器.</p><pre><code>$ docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES  </code></pre><p>因为没有运行中的容器,所以展示列表是空的.接下来尝试使用一个有用的变量,<br>运行 <strong>docker ps -a</strong>命令</p><pre><code>$ docker ps -a</code></pre><p>$ docker ps -a<br>|CONTAINER ID        |IMAGE               |COMMAND                  |CREATED             |STATUS                     | PORTS               |NAMES|<br>|:—-:|:—-:|:—-:|:—-:|:—-:|:—-:|:—-:|<br>|36171a5da744        |alpine             | “/bin/sh”               | 5 minutes ago       |Exited (0) 2 minutes ago   |                     |fervent_newton|<br>|a6a9d46d0b2f       | alpine            | “echo ‘hello from alp”    |6 minutes ago       |Exited (0) 6 minutes ago    |                    |lonely_kilby<br>|ff0a5c3750b9       | alpine            | “ls -l”                   |8 minutes ago      | Exited (0) 8 minutes ago     |                   |elated_ramanujan<br>|c317d0a9e3d2       | hello-world        | “/hello”                 |34 seconds ago     |Exited (0) 12 minutes ago    |                   |stupefied_mcclintock    </p><p>上面是所有你能够运行的容器.可以注意到<strong>STATUS</strong>列展示了容器是在几分钟前推出的.接下来尝试在一个容器中运行多条命令.</p><pre><code>$ docker run -it alpine /bin/sh/ # lsbin      dev      etc      home     lib      linuxrc  media    mnt      proc     root     run      sbin     sys      tmp      usr      var/ # uname -aLinux 97916e8cb5dc 4.4.27-moby #1 SMP Wed Oct 26 14:01:48 UTC 2016 x86_64 Linux</code></pre><p>通过运行<strong>run</strong>命令附加<strong>-it</strong>标志的方式使我们能在容器中以交互式终端的方式进行交互.现在你能在容器运行任意数量的命令.</p><p>如上述我们已经展示了你可能使用最频繁的命令,你可以通过使用<strong>docker run –help</strong>来展示该命令所有支持的附加选项.随着你继续深入的学习,我们也将会看到<strong>docker run</strong>命令支持的更多变量.</p><h2 id="Terminology-术语"><a href="#Terminology-术语" class="headerlink" title="Terminology(术语)"></a>Terminology(术语)</h2><p>在上一小节,你已经看到了许多Docker 特殊的术语,你可能会对其中一些感到困惑.所以在我们继续深入之前,先阐述一下一些我们在Docker 生态系统(ecosystem)中经常性使用的术语.</p><ul><li><p>Images - 用来创建容器的属于我们应用的文件系统和相关配置.想要知道更多关于Docker镜像,运行<strong>docker inspect alpine</strong>命令.在上面的demo中,我们通过<strong>docker pull</strong>命令来下载alpine镜像.当你执行<strong>docker run hello-world</strong>命令,它同样会在后台运行<strong>docker pull</strong>命令以下载hello-world镜像.</p></li><li><p>Containers - 用以运行Docker镜像的实例 - 容器会运行实际的应用.一个容器包含一个应用和它的所有依赖.它和其它容器共享内核,并且在宿主操作系统上面的用户空间以一个隔离进程运行.你通过<strong>docker run</strong>命令创建一个容器以运行alpine image 的实例.通过<strong>docker ps</strong>命令来展示一系列正在运行的容器.</p></li><li><p>Docker daemon - Docker 守护进程是一个运行在主机上的后台服务,它用于提供管理构建,运行和分配Docker容器.</p></li><li><p>Docker client - Docker 客户端,这是一个命令行工具，允许用户和Docker守护进程进行交互.</p></li><li><p>Docker Store - Docker 商店,一个Docker镜像的登记处,在这个平台上你可以查询找到可信以及可供企业使用的容器,插件以及 其它Docker的特别版本.在这个教程中你将在之后使用到它.</p></li></ul><p><a href="https://github.com/darkleave/labs/blob/master/beginner/chapters/alpine.md" target="_blank" rel="external">参考链接</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;运行你的第一个容器&quot;&gt;&lt;a href=&quot;#运行你的第一个容器&quot; class=&quot;headerlink&quot; title=&quot;运行你的第一个容器&quot;&gt;&lt;/a&gt;运行你的第一个容器&lt;/h2&gt;&lt;p&gt;现在你已经准备好了所有的东西,是时候开始实践了.&lt;br&gt;在这个章节,我们将要运行一个 Alpine Linux 容器(一个轻量级的linux 发布版本)在你的系统上并且尝试一下docker的运行命令.&lt;/p&gt;
    
    </summary>
    
    
      <category term="docker" scheme="http://www.zhz.gift/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu docker 安装</title>
    <link href="http://www.zhz.gift/2018/02/04/Ubuntu%20docker%20%E5%AE%89%E8%A3%85/"/>
    <id>http://www.zhz.gift/2018/02/04/Ubuntu docker 安装/</id>
    <published>2018-02-03T16:07:42.000Z</published>
    <updated>2018-02-03T16:24:48.815Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Docker是什么"><a href="#Docker是什么" class="headerlink" title="Docker是什么?"></a>Docker是什么?</h2><p>Docker是一种容器技术.<br>Docker容器技术已在云计算市场上风靡一时了，使docker容器技术如此受欢迎的原因是，容器技术可实现不同云计算之间应用程序的可移植性，以及提供了一个把应用程序拆分为分布式组件的方法，此外，用户还可以管理和扩展这些组件成为集群.</p><a id="more"></a><p><a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/" target="_blank" rel="external">官网链接</a></p><p>一旦你完成docker的安装后,可以用如下命令对你的docker进行测试:</p><pre><code>$ docker run hello-worldUnable to find image &apos;hello-world:latest&apos; locallylatest: Pulling from library/hello-world03f4658f8b78: Pull completea3ed95caeb02: Pull completeDigest: sha256:8be990ef2aeb16dbcb9271ddfe2610fa6658d13f6dfb8bc72074cc1ca36966a7Status: Downloaded newer image for hello-world:latestHello from Docker.This message shows that your installation appears to be working correctly....</code></pre><h3 id="卸载老版本"><a href="#卸载老版本" class="headerlink" title="卸载老版本"></a>卸载老版本</h3><p>老版本的Docker一般命名为 docker 或者 docker-engine.在安装新版本前需要对他们进行卸载.</p><pre><code>$ sudo apt-get remove docker docker-engine docker.io</code></pre><p>即时apt-get命令提示没有上述的任意包被安装也没有影响.<br>/var/lib/docker/ 文件夹一般包含images, containers, volumes, and networks等.<br> Docker CE包现在被命名为: docker-ce</p><h3 id="安装Docker-CE"><a href="#安装Docker-CE" class="headerlink" title="安装Docker CE"></a>安装Docker CE</h3><p>你可以根据需要选择以下合适的方式来安装Docker CE：</p><ul><li><p>通过repository进行安装<br>在你第一次在一台新主机上安装docker之前,你需要先设置Docker仓库,之后,你就可以直接通过仓库安装和更新Docker.<br><strong>设置仓库</strong></p><ol><li><p>更新apt命令的包索引</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get update</div></pre></td></tr></table></figure></li><li><p>安装仓库使用所需的https依赖包</p>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install \</div><div class="line">apt-transport-https \</div><div class="line">ca-certificates \</div><div class="line">curl \</div><div class="line">software-properties-common</div></pre></td></tr></table></figure></li><li><p>添加Docker的官方GPG key</p>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</div></pre></td></tr></table></figure><p>验证你现在拥有的指纹秘钥:(eg:)<br><code>9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88</code><br>搜索最后八个长度的指纹:</p>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">  </div><div class="line">      $ sudo apt-key fingerprint 0EBFCD88</div><div class="line">      </div><div class="line">      pub   4096R/0EBFCD88 2017-02-22</div><div class="line">            Key fingerprint = 9DC8 5822 9FC7 DD38 854A  E2D8 8D81 803C 0EBF CD88</div><div class="line">      uid                  Docker Release (CE deb) &lt;docker@docker.com&gt;</div><div class="line">      sub   4096R/F273FCD8 2017-02-22</div><div class="line">      ```    </div><div class="line">4. 使用以下命令来设置你的stable repository(稳定仓库).你总是需要stable repository,即使你想要从edge或者test仓库安装构建也一样.想要添加edge或者test仓库,只需在以下命令的stable后面添加相应的edge或者test即可.</div></pre></td></tr></table></figure></li></ol></li></ul><pre><code>   提示：lsb_release -cs 子命令返回你Ubuntu发布版本的名称,例如xenial.有时候,一些发布版本,比如Linux Mint,你可能需要把 $(lsb_release -cs)命令换成你对应的父级 Ubuntu 发布版本比如,如果你正在使用Linux Mint Rafaela,你可能要使用 trusty.    <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">**x86_64 / amd64**</div></pre></td></tr></table></figure>$ sudo add-apt-repository \   &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \   $(lsb_release -cs) \   stable&quot;<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">   **提示:从17.06版本开始,stable 发布时会同样推送到edge和test仓库.**</div><div class="line">   </div><div class="line">      [Learn about stable and edge channels.](https://docs.docker.com/install/)</div><div class="line">      </div><div class="line">**Docker CE安装步骤**</div><div class="line">  </div><div class="line">1. 更新apt包索引...</div></pre></td></tr></table></figure>    $ sudo apt-get update    <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">      </div><div class="line">2. 安装最新版本的Docker CE或者直接到下一步安装特定版本的Docker CE.</div><div class="line">    任何当前的版本会被替换为安装的版本.</div></pre></td></tr></table></figure>    $ sudo apt-get install docker-ce  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"> </div></pre></td></tr></table></figure>  获取多个Docker仓库?  如果你有多个可用的Docker仓库,安装或者更新操作没有指定特定的版本,apt-get install 或者apt-get update 命令总是会按照最高的可用版本,可能并不满足你稳定性的需要. <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">     </div><div class="line"> 3. 在生产环境,你需要使用特定版本的Docker CE版本而不是一直使用最新的.</div><div class="line">    以下命令会列出所有可用版本(输出只展示了一部分):</div><div class="line"></div><div class="line">     ```  </div><div class="line">     </div><div class="line">     $ apt-cache madison docker-ce</div><div class="line">    docker-ce | 17.12.0~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages</div><div class="line">     ```  </div><div class="line">    该列表数据依赖于你可用的仓库.选择一个特定的版本去安装.第二列是版本字符串.第三列是仓库名,用来表明该仓库的来源地址和稳定性等级,stable,edge或者test.想要安装特定的版本,只需在包名后面添加(=)后和版本字符串即可.</div><div class="line">    </div><div class="line">     ```  </div><div class="line">     $ sudo apt-get install docker-ce=&lt;VERSION&gt;   </div><div class="line">     ``` </div><div class="line">Docker守护进程在安装完成后会自动启动.</div><div class="line"></div><div class="line">4. 通过运行hello-world image 来验证Docker CE是否已经正确安装.</div><div class="line">``` </div><div class="line">$ sudo docker run hello-world</div><div class="line">  ```    </div><div class="line">这个命令会下载一个测试镜像并且在容器中运行它.当容器运行,它会打印提示信息并且退出.</div><div class="line"></div><div class="line">Dcoker CE 已经安装并且运行.docker group 已经创建但是没有用户添加到它上面.你需要通过使用sudo命令去运行Docker命令.继续到[Linux postinstall](https://docs.docker.com/install/linux/linux-postinstall/)去允许未授权的用户能够运行Docker命令和一些可选的配置步骤.</div><div class="line"></div><div class="line">**升级 DOCKER CE**</div><div class="line"></div><div class="line">升级Docker CE,首先同样通过sudo命令更新包索引apt-get update,然后按照按照指令,选择新的版本直接进行安装即可.</div><div class="line"></div><div class="line">**卸载Docker CE**</div><div class="line"></div><div class="line">1. 卸载Docker CE包:</div></pre></td></tr></table></figure></code></pre><p>   $ sudo apt-get purge docker-ce<br>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">2. 手动删除镜像，容器等文件(Images, containers, volumes, or customized configuration files)</div></pre></td></tr></table></figure></p><p>   $ sudo rm -rf /var/lib/docker<br>   ```<br>   你必须删除所有已编辑的配置文件.</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Docker是什么&quot;&gt;&lt;a href=&quot;#Docker是什么&quot; class=&quot;headerlink&quot; title=&quot;Docker是什么?&quot;&gt;&lt;/a&gt;Docker是什么?&lt;/h2&gt;&lt;p&gt;Docker是一种容器技术.&lt;br&gt;Docker容器技术已在云计算市场上风靡一时了，使docker容器技术如此受欢迎的原因是，容器技术可实现不同云计算之间应用程序的可移植性，以及提供了一个把应用程序拆分为分布式组件的方法，此外，用户还可以管理和扩展这些组件成为集群.&lt;/p&gt;
    
    </summary>
    
    
      <category term="docker" scheme="http://www.zhz.gift/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>HikariCP 配置说明</title>
    <link href="http://www.zhz.gift/2018/01/30/HikariCP%20%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/"/>
    <id>http://www.zhz.gift/2018/01/30/HikariCP 配置说明/</id>
    <published>2018-01-29T16:07:42.000Z</published>
    <updated>2018-01-30T14:37:52.602Z</updated>
    
    <content type="html"><![CDATA[<p>Fast, simple, reliable. HikariCP is a “zero-overhead” production ready JDBC connection pool. At roughly 130Kb, the library is very light.</p><a id="more"></a><p><a href="https://github.com/darkleave/HikariCP" target="_blank" rel="external">官网连接</a></p><h2 id="必要配置"><a href="#必要配置" class="headerlink" title="必要配置"></a>必要配置</h2><ol><li>dataSourceClassName 数据源驱动名</li><li>jdbcUrl jdbc数据库连接</li><li>username 用户名</li><li>password 密码</li></ol><p>其中dataSourceClassName和jdbcUrl二选一，当使用比较老版本的驱动时，需要同时设置jdbcUrl和driverClassName，dataSourceClassName则不用进行设置</p><h2 id="可选配置"><a href="#可选配置" class="headerlink" title="可选配置"></a>可选配置</h2><ol><li><p>常用属性</p><ul><li>connectionTimeout 连接超时时间,最小时间为250 ms，默认为30000ms(30秒)</li><li><p>idleTimeout 空闲超时时间，这个属性用来控制空闲连接允许保留在连接池中的最大时间，这个属性只有在minimumIdle（最小空闲连接数）小于maximumPoolSize(最大连接数)时才会生效,空闲连接断开会有15s-30s的延迟变动时间.在这个超时时间之前空闲连接永远不会断开,当连接池达到minimumIdle,连接将永远不会断开，即使处于闲置状态.值为0表示空闲连接将永远不会从连接池中移除，最小值为10000ms （10s),默认值为600000(10min)</p></li><li><p>maxLifetime 最大生命周期.这个属性用来控制连接池中连接的最大生命周期,一个使用中的连接永远不会被断开,只有当它处于关闭状态然后才会被移除.推荐设置比任何数据库或基础设施规定的连接时间限制少至少30秒。 值为0表示没有最大寿命（无限寿命）， 默认：1800000（30分钟）,由于HikariCP的housekeeper默认每30s运行一次,以维护minimumIdle最小空闲连接数，它可能添加新连接或者断开空闲连接，所以你必须设置maxLifetime属性比（mysql)wait_timeout时间少一些来避免 broken connection / exceptions.意思就是说比如mysql wait_timeout为10min,此时有一个连接由于达到超时时间，mysql主动断开了连接，而HakariCP仍然持有此连接，如果再使用此连接去请求数据库则会发生异常,设置maxLifetime最大生命周期比wait_timeout少30s后,就能确保再housekeeper运行期间提前断开此连接，避免发生异常.</p></li><li>connectionTestQuery 连接测试查询,如果你的驱动支持jdbc4，则不需要设置此属性，这个属性是为那些不支持Connection.isValid() API的古董级驱动准备的，这是一个查询，用来确保所有请求得到的连接都是alive有效的，尝试不设置这个属性运行连接池，如果你的驱动不支持jdbc4，HikariCP会有错误日志提示.Default:None</li><li>minimumIdle 最小空闲连接，当空闲连接小于这个值并且总连接数小于maximumPoolSize（最大连接数)HikariCP会尽可能快速有效率地创建额外的连接，然而为了最大限度地提高性能和响应能力，不建议设置这个值，而是用固定大小的连接池取代.Default:与maximumPoolSize相同</li><li>maximumPoolSize 最大连接池数量，包括使用中和空闲的连接，当达到最大连接池数量时，再尝试获取连接，只能得到connectionTimeout 超时信息.Default:10.</li><li>metricRegistry 度量注册, Default: none <a href="https://www.jianshu.com/p/070f615dfb57" target="_blank" rel="external">参考链接</a></li><li>healthCheckRegistry 健康检查注册  Default: none</li><li>poolName 连接池名字,一般用于日志输出 Default: auto-generated</li></ul></li><li>不常使用<ul><li>initializationFailTimeout 初始化失败超时时间 Default: 1</li><li>isolateInternalQueries 是否隔离默认查询 Default: 1</li><li>allowPoolSuspension 是否允许连接池暂停 Default: false</li><li>readOnly 连接是否只读 Default: false</li><li>registerMbeans 是否注册JMX Management Beans Default: false</li><li>catalog 目录服务</li><li>connectionInitSql 连接初始化sql Default: none</li><li>driverClassName 驱动名称  Default: none</li><li>transactionIsolation 事务隔离 Default: driver default</li><li>validationTimeout 验证超时时间 Default: 5000 </li><li>leakDetectionThreshold 最低发现阈值 Default: 0</li><li>dataSource 数据源 Default: none</li><li>schema 架构  Default: driver default</li><li>threadFactory 线程工厂 Default: none </li><li>scheduledExecutor 计划执行器 Default: none</li></ul></li></ol><h2 id="Statement-Cache"><a href="#Statement-Cache" class="headerlink" title="Statement Cache"></a>Statement Cache</h2><p>Many connection pools, including Apache DBCP, Vibur, c3p0 and others offer PreparedStatement caching. HikariCP does not. Why?<br>许多连接池，包括Aache DBCP,Vibur,c3p0 等都是提供PreparedStatement caching.HikariCP并不这样做，为什么？</p><p>At the connection pool layer PreparedStatements can only be cached per connection. If your application has 250 commonly executed queries and a pool of 20 connections you are asking your database to hold on to 5000 query execution plans – and similarly the pool must cache this many PreparedStatements and their related graph of objects.</p><p>在连接池中每个连接只能缓存各自的PreparedStatements对象.如果你的应用有250个要执行的普通查询和一个20个连接的连接池，然后你需要不间断地请求你的数据库去完成一个5000查询的执行计划，显然你的连接池必须缓存这所有的PreparedStatements对象和它们相关联的表对象.</p><p>Most major database JDBC drivers already have a Statement cache that can be configured, including PostgreSQL, Oracle, Derby, MySQL, DB2, and many others. JDBC drivers are in a unique position to exploit database specific features, and nearly all of the caching implementations are capable of sharing execution plans across connections. This means that instead of 5000 statements in memory and associated execution plans, your 250 commonly executed queries result in exactly 250 execution plans in the database. Clever implementations do not even retain PreparedStatement objects in memory at the driver-level but instead merely attach new instances to existing plan IDs.</p><p>许多主流的数据库，它们的jdbc驱动已经有了一个可配置的Statement缓存，包括PostgreSQL, Oracle, Derby, MySQL, DB2等等.JDBC驱动是唯一能利用数据库特定属性的方式，并且近乎所有的缓存实现都可以通过连接共享执行计划.这意味着你的250个普通查询结果在数据库中就是250个执行计划，而不是存储在内存中的5000个statements及其相关联的执行计划.聪明的缓存实现在驱动这一级别并不保持PreparedStatement对象在内存当中，而是为已存在的计划创建新的PreparedStatement实例.</p><p>Using a statement cache at the pooling layer is an anti-pattern, and will negatively impact your application performance compared to driver-provided caches.</p><p>在连接池层使用statement缓存是一个反面教材,并且相较驱动提供的缓存会对你的应用性能造成更大的消极影响.</p><h2 id="Log-Statement-Text-Slow-Query-Logging"><a href="#Log-Statement-Text-Slow-Query-Logging" class="headerlink" title="Log Statement Text / Slow Query Logging"></a>Log Statement Text / Slow Query Logging</h2><p>Like Statement caching, most major database vendors support statement logging through properties of their own driver. This includes Oracle, MySQL, Derby, MSSQL, and others. Some even support slow query logging. For those few databases that do not support it, several options are available. We have received a report that p6spy works well, and also note the availability of log4jdbc and jdbcdslog-exp.</p><p>就像Statement缓存，许多主流数据库供应商支持通过它们驱动的属性配置来添加statement logging的日志功能.这些数据库包括racle, MySQL, Derby, MSSQL等等.一些甚至支持<a href="https://baike.baidu.com/item/%E6%85%A2%E6%9F%A5%E8%AF%A2/9200910?fr=aladdin" target="_blank" rel="external">慢查询</a>日志记录功能.对于那些少数不支持的数据库,还有许多可用的其它方式.比如,p6spy,log4jdbc以及jdbcdslog-exp等等.</p><p><a href="https://github.com/brettwooldridge/HikariCP/wiki/MySQL-Configuration" target="_blank" rel="external">mysql推荐配置</a><br><a href="http://blog.csdn.net/suwu150/article/details/52745055" target="_blank" rel="external">Statement和PreparedStatement对象的区别</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Fast, simple, reliable. HikariCP is a “zero-overhead” production ready JDBC connection pool. At roughly 130Kb, the library is very light.&lt;/p&gt;
    
    </summary>
    
    
      <category term="pool" scheme="http://www.zhz.gift/tags/pool/"/>
    
  </entry>
  
  <entry>
    <title>git 换行符LF与CRLF转换问题</title>
    <link href="http://www.zhz.gift/2018/01/29/git%20%E6%8D%A2%E8%A1%8C%E7%AC%A6LF%E4%B8%8ECRLF%E8%BD%AC%E6%8D%A2%E9%97%AE%E9%A2%98/"/>
    <id>http://www.zhz.gift/2018/01/29/git 换行符LF与CRLF转换问题/</id>
    <published>2018-01-28T16:07:42.000Z</published>
    <updated>2018-01-29T14:04:28.319Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><p>在各操作系统下，文本文件所使用的换行符是不一样的。UNIX/Linux 使用的是 0x0A（LF），早期的 Mac OS 使用的是0x0D（CR），后来的 OS X 在更换内核后与 UNIX 保持一致了。但 DOS/Windows 一直使用 0x0D0A（CRLF）作为换行符。Git提供了一个“换行符自动转换”功能。这个功能默认处于“自动模式”，当你在签出文件时，它试图将 UNIX 换行符（LF）替换为 Windows 的换行符（CRLF）；当你在提交文件时，它又试图将 CRLF 替换为 LF。Git 的“换行符自动转换”功能听起来似乎很智能、很贴心，因为它试图一方面保持仓库内文件的一致性（UNIX 风格），一方面又保证本地文件的兼容性（Windows 风格）。但遗憾的是，这个功能是有 bug 的，而且在短期内都不太可能会修正。</p><a id="more"></a><h2 id="二、解决方案"><a href="#二、解决方案" class="headerlink" title="二、解决方案"></a>二、解决方案</h2><p>1.Git设置</p><p>git config –global core.autocrlf false<br>git config –global core.safecrlf true<br>含义：<br>AutoCRLF<br><strong>提交时转换为LF，检出时转换为CRLF</strong><br>git config –global core.autocrlf true</p><p><strong>提交时转换为LF，检出时不转换</strong><br>git config –global core.autocrlf input</p><p><strong>提交检出均不转换</strong><br>git config –global core.autocrlf false<br>SafeCRLF<br><strong>拒绝提交包含混合换行符的文件</strong><br>git config –global core.safecrlf true</p><p><strong>允许提交包含混合换行符的文件</strong><br>git config –global core.safecrlf false</p><p><strong>提交包含混合换行符的文件时给出警告</strong><br>git config –global core.safecrlf warn</p><p>一般在开发中为了保持项目换行符转换不出错，将autocrlf设置为false,<br>然后重新clone项目。</p><p>也可以直接修改git全局配置文件，windows配置路径:<br>C:\Users\Administrator.gitconfig</p><pre><code>[filter &quot;lfs&quot;]    required = true    clean = git-lfs clean %f    smudge = git-lfs smudge %f[user]    name = zhonghanzhong[user]    email = yyesnnovv@aliyun.com[credential]    helper = manager[http]    sslVerify = false[core]    autocrlf = false</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、背景&quot;&gt;&lt;a href=&quot;#一、背景&quot; class=&quot;headerlink&quot; title=&quot;一、背景&quot;&gt;&lt;/a&gt;一、背景&lt;/h2&gt;&lt;p&gt;在各操作系统下，文本文件所使用的换行符是不一样的。UNIX/Linux 使用的是 0x0A（LF），早期的 Mac OS 使用的是0x0D（CR），后来的 OS X 在更换内核后与 UNIX 保持一致了。但 DOS/Windows 一直使用 0x0D0A（CRLF）作为换行符。Git提供了一个“换行符自动转换”功能。这个功能默认处于“自动模式”，当你在签出文件时，它试图将 UNIX 换行符（LF）替换为 Windows 的换行符（CRLF）；当你在提交文件时，它又试图将 CRLF 替换为 LF。Git 的“换行符自动转换”功能听起来似乎很智能、很贴心，因为它试图一方面保持仓库内文件的一致性（UNIX 风格），一方面又保证本地文件的兼容性（Windows 风格）。但遗憾的是，这个功能是有 bug 的，而且在短期内都不太可能会修正。&lt;/p&gt;
    
    </summary>
    
    
      <category term="DevelopNote" scheme="http://www.zhz.gift/tags/DevelopNote/"/>
    
      <category term="git" scheme="http://www.zhz.gift/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>jooq介绍</title>
    <link href="http://www.zhz.gift/2018/01/15/jooq%E4%BB%8B%E7%BB%8D/"/>
    <id>http://www.zhz.gift/2018/01/15/jooq介绍/</id>
    <published>2018-01-14T16:07:42.000Z</published>
    <updated>2018-01-15T14:05:22.808Z</updated>
    
    <content type="html"><![CDATA[<h2 id="jooq是什么"><a href="#jooq是什么" class="headerlink" title="jooq是什么"></a>jooq是什么</h2><p>jOOQ（Java Object Oriented Querying，即面向Java对象查询）是基于Java访问关系型数据库的工具包，轻量，简单，并且足够灵活，可以轻松的使用Java面向对象语法来实现各种复杂的sql;是一个高效地合并了复杂SQL、类型安全、源码生成、ActiveRecord、存储过程以及高级数据类型的Java API的类库.</p><a id="more"></a><h2 id="jooq的特点"><a href="#jooq的特点" class="headerlink" title="jooq的特点"></a>jooq的特点</h2><ol><li><p>类型安全(TypeSafe SQL)<br>jooq使用内部的DSL(domain specific language领域专用语言)对sql进行模块化，并且使用java编译器去编译你的sql语法，元数据以及数据类型.</p></li><li><p>映射代码生成<br>jooq可以从你的数据库元数据生成对应的java映射类，生成的实体类按照数据库字段以驼峰命名法重新命名，同时用户可以通过继承实体类的方式来添加自定义属性及方法.</p></li><li><p>ActiveRecords<br>我们jooq通过代码生成器生成的ActiveReocrds可以直接对POJO(Plain Old Java Object)映射对象进行CRUD(Create Retrieve Update Delete)操作</p></li><li><p>多架构(多模式Schema)<br>jooq允许你在运行时环境动态配置数据库模式和表并且支持行级别的安全性,即通过不同的jooq Configuration配置得到对应的DSLContext上下文再对数据库进行CRUD操作.</p></li><li><p>标准化<br>jooq可以通过配置数据库方言来支持不同的数据库:mysql,oracle等等,比如通过spring配置spring.jooq.sql-dialect = mysql 来支持mysql数据库</p></li><li><p>查询生命周期<br>jooq通过一些接口开放SQL生成的生命周期，包括日志，事务处理，id生成，sql转换等等。</p></li><li><p>存储过程<br>jooq允许你在模块化sql语句中嵌入存储过程调用.</p></li><li><p>强大的Fluent API和完善文档,使用方便流畅</p></li></ol><p><strong>参考链接</strong><br><a href="https://www.jianshu.com/p/46164f9ba53c" target="_blank" rel="external">https://www.jianshu.com/p/46164f9ba53c</a><br><a href="https://www.jooq.org/" target="_blank" rel="external">https://www.jooq.org/</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;jooq是什么&quot;&gt;&lt;a href=&quot;#jooq是什么&quot; class=&quot;headerlink&quot; title=&quot;jooq是什么&quot;&gt;&lt;/a&gt;jooq是什么&lt;/h2&gt;&lt;p&gt;jOOQ（Java Object Oriented Querying，即面向Java对象查询）是基于Java访问关系型数据库的工具包，轻量，简单，并且足够灵活，可以轻松的使用Java面向对象语法来实现各种复杂的sql;是一个高效地合并了复杂SQL、类型安全、源码生成、ActiveRecord、存储过程以及高级数据类型的Java API的类库.&lt;/p&gt;
    
    </summary>
    
    
      <category term="jooq" scheme="http://www.zhz.gift/tags/jooq/"/>
    
  </entry>
  
  <entry>
    <title>Pom.xml详解</title>
    <link href="http://www.zhz.gift/2018/01/11/Pom.xml%E8%AF%A6%E8%A7%A3/"/>
    <id>http://www.zhz.gift/2018/01/11/Pom.xml详解/</id>
    <published>2018-01-10T16:07:42.000Z</published>
    <updated>2018-01-11T15:29:33.548Z</updated>
    
    <content type="html"><![CDATA[<p>Maven pom.xml详细配置说明</p><a id="more"></a><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1.概述"></a>1.概述</h2><p>pom中节点如下分布</p><pre><code>&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0            http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;!-- 基本配置 --&gt;    &lt;groupId&gt;...&lt;/groupId&gt;    &lt;artifactId&gt;...&lt;/artifactId&gt;    &lt;version&gt;...&lt;/version&gt;    &lt;packaging&gt;...&lt;/packaging&gt;    &lt;!-- 依赖配置 --&gt;    &lt;dependencies&gt;...&lt;/dependencies&gt;    &lt;parent&gt;...&lt;/parent&gt;    &lt;dependencyManagement&gt;...&lt;/dependencyManagement&gt;    &lt;modules&gt;...&lt;/modules&gt;    &lt;properties&gt;...&lt;/properties&gt;    &lt;!-- 构建配置 --&gt;    &lt;build&gt;...&lt;/build&gt;    &lt;reporting&gt;...&lt;/reporting&gt;    &lt;!-- 项目信息 --&gt;    &lt;name&gt;...&lt;/name&gt;    &lt;description&gt;...&lt;/description&gt;    &lt;url&gt;...&lt;/url&gt;    &lt;inceptionYear&gt;...&lt;/inceptionYear&gt;    &lt;licenses&gt;...&lt;/licenses&gt;    &lt;organization&gt;...&lt;/organization&gt;    &lt;developers&gt;...&lt;/developers&gt;    &lt;contributors&gt;...&lt;/contributors&gt;    &lt;!-- 环境设置 --&gt;    &lt;issueManagement&gt;...&lt;/issueManagement&gt;    &lt;ciManagement&gt;...&lt;/ciManagement&gt;    &lt;mailingLists&gt;...&lt;/mailingLists&gt;    &lt;scm&gt;...&lt;/scm&gt;    &lt;prerequisites&gt;...&lt;/prerequisites&gt;    &lt;repositories&gt;...&lt;/repositories&gt;    &lt;pluginRepositories&gt;...&lt;/pluginRepositories&gt;    &lt;distributionManagement&gt;...&lt;/distributionManagement&gt;    &lt;profiles&gt;...&lt;/profiles&gt;&lt;/project&gt;</code></pre><h2 id="2-基本配置"><a href="#2-基本配置" class="headerlink" title="2.基本配置"></a>2.基本配置</h2><ul><li>modelVersion：pom模型版本，maven2和3只能为4.0.0</li><li>groupId：组ID，maven用于定位</li><li>artifactId：在组中的唯一ID用于定位</li><li>version：项目版本</li><li>packaging：项目打包方式，有以下值：pom, jar, maven-plugin, ejb, war, ear, rar, par</li></ul><h2 id="3-依赖配置"><a href="#3-依赖配置" class="headerlink" title="3.依赖配置"></a>3.依赖配置</h2><p>parent</p><p>用于确定父项目的坐标。</p><pre><code>&lt;parent&gt;    &lt;groupId&gt;com.learnPro&lt;/groupId&gt;    &lt;artifactId&gt;SIP-parent&lt;/artifactId&gt;    &lt;relativePath&gt;&lt;/relativePath&gt;    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;</code></pre><ul><li>groupId：父项目的构件标识符</li><li>artifactId：父项目的唯一标识符</li><li>relativePath：Maven首先在当前项目的找父项目的pom，然后在文件系统的这个位置（relativePath），然后在本地仓库，再在远程仓库找。</li><li>version：父项目的版本</li></ul><p>modules</p><p>有些maven项目会做成多模块的，这个标签用于指定当前项目所包含的所有模块。之后对这个项目进行的maven操作，会让所有子模块也进行相同操作。</p><pre><code>&lt;modules&gt;   &lt;module&gt;com-a&lt;/module&gt;   &lt;module&gt;com-b&lt;/module&gt;   &lt;module&gt;com-c&lt;/module&gt;&lt;/modules&gt;</code></pre><p>properties</p><p>用于定义pom常量</p><pre><code>&lt;properties&gt;    &lt;java.version&gt;1.7&lt;/java.version&gt;&lt;/properties&gt;</code></pre><p>上面这个常量可以在pom文件的任意地方通过${java.version}来引用</p><p>dependencies</p><p>项目相关依赖配置，如果在父项目写的依赖，会被子项目引用，一般父项目会将子项目公用的依赖引入（将在之后详细讲解）</p><pre><code>&lt;dependencies&gt;    &lt;dependency&gt;            &lt;groupId&gt;junit&lt;/groupId&gt;            &lt;artifactId&gt;junit&lt;/artifactId&gt;            &lt;version&gt;4.12&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><p>这边依赖和中央仓库中的一致，就可以引入对应的jar</p><p>dependencyManagement</p><p>配置写法同dependencies</p><pre><code>&lt;dependencyManagement&gt;    &lt;dependencies&gt;    .....    &lt;/dependencies&gt;&lt;/dependencyManagement&gt;</code></pre><p>在父模块中定义后，子模块不会直接使用对应依赖，但是在使用相同依赖的时候可以不加版本号：</p><pre><code>父项目：&lt;dependencyManagement&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;junit&lt;/groupId&gt;            &lt;artifactId&gt;junit&lt;/artifactId&gt;            &lt;version&gt;4.12&lt;/version&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/dependencyManagement&gt;子项目：&lt;dependency&gt;    &lt;groupId&gt;junit&lt;/groupId&gt;    &lt;artifactId&gt;junit&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>这样的好处是，父项目统一了版本，而且子项目可以在需要的时候才引用对应的依赖    </p><h2 id="4-构建配置"><a href="#4-构建配置" class="headerlink" title="4.构建配置"></a>4.构建配置</h2><p>build</p><p>用于配置项目构建相关信息</p><pre><code>&lt;build&gt;        &lt;!--该元素设置了项目源码目录，当构建项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。--&gt;        &lt;sourceDirectory/&gt;        &lt;!--该元素设置了项目脚本源码目录，该目录和源码目录不同：绝大多数情况下，该目录下的内容 会被拷贝到输出目录(因为脚本是被解释的，而不是被编译的)。--&gt;      &lt;scriptSourceDirectory/&gt;      &lt;!--该元素设置了项目单元测试使用的源码目录，当测试项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。--&gt;      &lt;testSourceDirectory/&gt;      &lt;!--被编译过的应用程序class文件存放的目录。--&gt;      &lt;outputDirectory/&gt;      &lt;!--被编译过的测试class文件存放的目录。--&gt;      &lt;testOutputDirectory/&gt;      &lt;!--使用来自该项目的一系列构建扩展--&gt;      &lt;extensions&gt;       &lt;!--描述使用到的构建扩展。--&gt;       &lt;extension&gt;        &lt;!--构建扩展的groupId--&gt;        &lt;groupId/&gt;        &lt;!--构建扩展的artifactId--&gt;        &lt;artifactId/&gt;        &lt;!--构建扩展的版本--&gt;        &lt;version/&gt;       &lt;/extension&gt;      &lt;/extensions&gt;      &lt;!--当项目没有规定目标（Maven2 叫做阶段）时的默认值--&gt;      &lt;defaultGoal/&gt;      &lt;!--这个元素描述了项目相关的所有资源路径列表，例如和项目相关的属性文件，这些资源被包含在最终的打包文件里。--&gt;      &lt;resources&gt;       &lt;!--这个元素描述了项目相关或测试相关的所有资源路径--&gt;       &lt;resource&gt;        &lt;!-- 描述了资源的目标路径。该路径相对target/classes目录（例如${project.build.outputDirectory}）。举个例 子，如果你想资源在特定的包里(org.apache.maven.messages)，你就必须该元素设置为org/apache/maven /messages。然而，如果你只是想把资源放到源码目录结构里，就不需要该配置。--&gt;        &lt;targetPath/&gt;        &lt;!--是否使用参数值代替参数名。参数值取自properties元素或者文件里配置的属性，文件在filters元素里列出。--&gt;        &lt;filtering/&gt;        &lt;!--描述存放资源的目录，该路径相对POM路径--&gt;        &lt;directory/&gt;        &lt;!--包含的模式列表，例如**/*.xml.--&gt;        &lt;includes/&gt;        &lt;!--排除的模式列表，例如**/*.xml--&gt;        &lt;excludes/&gt;       &lt;/resource&gt;      &lt;/resources&gt;      &lt;!--这个元素描述了单元测试相关的所有资源路径，例如和单元测试相关的属性文件。--&gt;      &lt;testResources&gt;       &lt;!--这个元素描述了测试相关的所有资源路径，参见build/resources/resource元素的说明--&gt;       &lt;testResource&gt;        &lt;targetPath/&gt;&lt;filtering/&gt;&lt;directory/&gt;&lt;includes/&gt;&lt;excludes/&gt;       &lt;/testResource&gt;      &lt;/testResources&gt;      &lt;!--构建产生的所有文件存放的目录--&gt;      &lt;directory/&gt;      &lt;!--产生的构件的文件名，默认值是${artifactId}-${version}。--&gt;      &lt;finalName/&gt;      &lt;!--当filtering开关打开时，使用到的过滤器属性文件列表--&gt;      &lt;filters/&gt;      &lt;!--子项目可以引用的默认插件信息。该插件配置项直到被引用时才会被解析或绑定到生命周期。给定插件的任何本地配置都会覆盖这里的配置--&gt;      &lt;pluginManagement&gt;       &lt;!--使用的插件列表 。--&gt;       &lt;plugins&gt;        &lt;!--plugin元素包含描述插件所需要的信息。--&gt;        &lt;plugin&gt;         &lt;!--插件在仓库里的group ID--&gt;         &lt;groupId/&gt;         &lt;!--插件在仓库里的artifact ID--&gt;         &lt;artifactId/&gt;         &lt;!--被使用的插件的版本（或版本范围）--&gt;         &lt;version/&gt;         &lt;!--是否从该插件下载Maven扩展（例如打包和类型处理器），由于性能原因，只有在真需要下载时，该元素才被设置成enabled。--&gt;         &lt;extensions/&gt;         &lt;!--在构建生命周期中执行一组目标的配置。每个目标可能有不同的配置。--&gt;         &lt;executions&gt;          &lt;!--execution元素包含了插件执行需要的信息--&gt;          &lt;execution&gt;           &lt;!--执行目标的标识符，用于标识构建过程中的目标，或者匹配继承过程中需要合并的执行目标--&gt;           &lt;id/&gt;           &lt;!--绑定了目标的构建生命周期阶段，如果省略，目标会被绑定到源数据里配置的默认阶段--&gt;           &lt;phase/&gt;           &lt;!--配置的执行目标--&gt;           &lt;goals/&gt;           &lt;!--配置是否被传播到子POM--&gt;           &lt;inherited/&gt;           &lt;!--作为DOM对象的配置--&gt;           &lt;configuration/&gt;          &lt;/execution&gt;         &lt;/executions&gt;         &lt;!--项目引入插件所需要的额外依赖--&gt;         &lt;dependencies&gt;          &lt;!--参见dependencies/dependency元素--&gt;          &lt;dependency&gt;           ......          &lt;/dependency&gt;         &lt;/dependencies&gt;              &lt;!--任何配置是否被传播到子项目--&gt;         &lt;inherited/&gt;         &lt;!--作为DOM对象的配置--&gt;         &lt;configuration/&gt;        &lt;/plugin&gt;       &lt;/plugins&gt;      &lt;/pluginManagement&gt;      &lt;!--使用的插件列表--&gt;      &lt;plugins&gt;       &lt;!--参见build/pluginManagement/plugins/plugin元素--&gt;       &lt;plugin&gt;        &lt;groupId/&gt;&lt;artifactId/&gt;&lt;version/&gt;&lt;extensions/&gt;        &lt;executions&gt;         &lt;execution&gt;          &lt;id/&gt;&lt;phase/&gt;&lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt;         &lt;/execution&gt;        &lt;/executions&gt;        &lt;dependencies&gt;         &lt;!--参见dependencies/dependency元素--&gt;         &lt;dependency&gt;          ......         &lt;/dependency&gt;        &lt;/dependencies&gt;        &lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt;       &lt;/plugin&gt;      &lt;/plugins&gt;     &lt;/build&gt;</code></pre><p>reporting</p><p>该元素描述使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。</p><pre><code>&lt;reporting&gt;      &lt;!--true，则，网站不包括默认的报表。这包括“项目信息”菜单中的报表。--&gt;      &lt;excludeDefaults/&gt;      &lt;!--所有产生的报表存放到哪里。默认值是${project.build.directory}/site。--&gt;      &lt;outputDirectory/&gt;      &lt;!--使用的报表插件和他们的配置。--&gt;      &lt;plugins&gt;       &lt;!--plugin元素包含描述报表插件需要的信息--&gt;       &lt;plugin&gt;        &lt;!--报表插件在仓库里的group ID--&gt;        &lt;groupId/&gt;        &lt;!--报表插件在仓库里的artifact ID--&gt;        &lt;artifactId/&gt;        &lt;!--被使用的报表插件的版本（或版本范围）--&gt;        &lt;version/&gt;        &lt;!--任何配置是否被传播到子项目--&gt;        &lt;inherited/&gt;        &lt;!--报表插件的配置--&gt;        &lt;configuration/&gt;        &lt;!--一组报表的多重规范，每个规范可能有不同的配置。一个规范（报表集）对应一个执行目标 。例如，有1，2，3，4，5，6，7，8，9个报表。1，2，5构成A报表集，对应一个执行目标。2，5，8构成B报表集，对应另一个执行目标--&gt;        &lt;reportSets&gt;         &lt;!--表示报表的一个集合，以及产生该集合的配置--&gt;         &lt;reportSet&gt;          &lt;!--报表集合的唯一标识符，POM继承时用到--&gt;          &lt;id/&gt;          &lt;!--产生报表集合时，被使用的报表的配置--&gt;          &lt;configuration/&gt;          &lt;!--配置是否被继承到子POMs--&gt;          &lt;inherited/&gt;          &lt;!--这个集合里使用到哪些报表--&gt;          &lt;reports/&gt;         &lt;/reportSet&gt;        &lt;/reportSets&gt;       &lt;/plugin&gt;      &lt;/plugins&gt;     &lt;/reporting&gt;</code></pre><h2 id="5-项目信息"><a href="#5-项目信息" class="headerlink" title="5.项目信息"></a>5.项目信息</h2><ul><li>name：给用户提供更为友好的项目名</li><li>description：项目描述，maven文档中保存</li><li>url：主页的URL，maven文档中保存</li><li>inceptionYear：项目创建年份，4位数字。当产生版权信息时需要使用这个值</li><li>licenses：该元素描述了项目所有License列表。 应该只列出该项目的license列表，不要列出依赖项目的 license列表。如果列出多个license，用户可以选择它们中的一个而不是接受所有license。（如下）</li></ul><pre><code>&lt;license&gt;      &lt;!--license用于法律上的名称--&gt;        &lt;name&gt;...&lt;/name&gt;         &lt;!--官方的license正文页面的URL--&gt;        &lt;url&gt;....&lt;/url&gt;    &lt;!--项目分发的主要方式：repo，可以从Maven库下载 manual， 用户必须手动下载和安装依赖--&gt;        &lt;distribution&gt;repo&lt;/distribution&gt;         &lt;!--关于license的补充信息--&gt;        &lt;comments&gt;....&lt;/comments&gt;     &lt;/license&gt; </code></pre><ul><li>organization：1.name 组织名 2.url 组织主页url</li><li>developers：项目开发人员列表（如下）</li><li>contributors：项目其他贡献者列表，同developers    </li></ul><pre><code>&lt;developers&gt;  &lt;!--某个开发者信息--&gt;&lt;developer&gt;      &lt;!--开发者的唯一标识符--&gt;    &lt;id&gt;....&lt;/id&gt;      &lt;!--开发者的全名--&gt;    &lt;name&gt;...&lt;/name&gt;      &lt;!--开发者的email--&gt;    &lt;email&gt;...&lt;/email&gt;      &lt;!--开发者的主页--&gt;    &lt;url&gt;...&lt;url/&gt;    &lt;!--开发者在项目中的角色--&gt;    &lt;roles&gt;          &lt;role&gt;Java Dev&lt;/role&gt;          &lt;role&gt;Web UI&lt;/role&gt;      &lt;/roles&gt;     &lt;!--开发者所属组织--&gt;     &lt;organization&gt;sun&lt;/organization&gt;      &lt;!--开发者所属组织的URL--&gt;    &lt;organizationUrl&gt;...&lt;/organizationUrl&gt;      &lt;!--开发者属性，如即时消息如何处理等--&gt;    &lt;properties&gt;        &lt;!-- 和主标签中的properties一样，可以随意定义子标签 --&gt;    &lt;/properties&gt;     &lt;!--开发者所在时区， -11到12范围内的整数。--&gt;     &lt;timezone&gt;-5&lt;/timezone&gt;  &lt;/developer&gt;  &lt;/developers&gt;  </code></pre><h2 id="6-环境设置"><a href="#6-环境设置" class="headerlink" title="6.环境设置"></a>6.环境设置</h2><p>issueManagement</p><p>目的问题管理系统(Bugzilla, Jira, Scarab)的名称和URL</p><pre><code>&lt;issueManagement&gt;    &lt;system&gt;Bugzilla&lt;/system&gt;    &lt;url&gt;http://127.0.0.1/bugzilla/&lt;/url&gt;&lt;/issueManagement&gt;</code></pre><ul><li>system：系统类型</li><li>url：路径    </li></ul><p>ciManagement</p><p>项目的持续集成信息</p><pre><code>&lt;ciManagement&gt;    &lt;system&gt;continuum&lt;/system&gt;    &lt;url&gt;http://127.0.0.1:8080/continuum&lt;/url&gt;    &lt;notifiers&gt;      &lt;notifier&gt;        &lt;type&gt;mail&lt;/type&gt;        &lt;sendOnError&gt;true&lt;/sendOnError&gt;        &lt;sendOnFailure&gt;true&lt;/sendOnFailure&gt;        &lt;sendOnSuccess&gt;false&lt;/sendOnSuccess&gt;        &lt;sendOnWarning&gt;false&lt;/sendOnWarning&gt;        &lt;address&gt;continuum@127.0.0.1&lt;/address&gt;        &lt;configuration&gt;&lt;/configuration&gt;      &lt;/notifier&gt;    &lt;/notifiers&gt;  &lt;/ciManagement&gt;</code></pre><ul><li>system：持续集成系统的名字</li><li>url：持续集成系统的URL</li><li>notifiers：构建完成时，需要通知的开发者/用户的配置项。包括被通知者信息和通知条件（错误，失败，成功，警告） <ul><li>type：通知方式</li><li>sendOnError：错误时是否通知</li><li>sendOnFailure：失败时是否通知</li><li>sendOnSuccess：成功时是否通知</li><li>sendOnWarning：警告时是否通知</li><li>address：通知发送到的地址</li><li>configuration：扩展项      </li></ul></li></ul><p>mailingLists</p><p>项目相关邮件列表信息</p><pre><code>&lt;mailingLists&gt;    &lt;mailingList&gt;      &lt;name&gt;User List&lt;/name&gt;      &lt;subscribe&gt;user-subscribe@127.0.0.1&lt;/subscribe&gt;      &lt;unsubscribe&gt;user-unsubscribe@127.0.0.1&lt;/unsubscribe&gt;      &lt;post&gt;user@127.0.0.1&lt;/post&gt;      &lt;archive&gt;http://127.0.0.1/user/&lt;/archive&gt;      &lt;otherArchives&gt;        &lt;otherArchive&gt;http://base.google.com/base/1/127.0.0.1&lt;/otherArchive&gt;      &lt;/otherArchives&gt;    &lt;/mailingList&gt;    .....  &lt;/mailingLists&gt;</code></pre><ul><li>subscribe, unsubscribe: 订阅邮件（取消订阅）的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建</li><li>archive：浏览邮件信息的URL</li><li>post：接收邮件的地址      </li></ul><p>scm</p><p>允许你配置你的代码库，供Maven web站点和其它插件使用</p><pre><code>&lt;scm&gt;    &lt;connection&gt;scm:svn:http://127.0.0.1/svn/my-project&lt;/connection&gt;    &lt;developerConnection&gt;scm:svn:https://127.0.0.1/svn/my-project&lt;/developerConnection&gt;    &lt;tag&gt;HEAD&lt;/tag&gt;    &lt;url&gt;http://127.0.0.1/websvn/my-project&lt;/url&gt;&lt;/scm&gt;</code></pre><ul><li>connection, developerConnection：这两个表示我们如何连接到maven的版本库。connection只提供读，developerConnection将提供写的请求 <ul><li>写法如：scm:[provider]:[provider_specific]</li><li>如果连接到CVS仓库，可以配置如下：scm:cvs:pserver:127.0.0.1:/cvs/root:my-project</li></ul></li><li>tag：项目标签，默认HEAD</li><li>url：共有仓库路径    </li></ul><p>prerequisites</p><p>项目构建的前提</p><pre><code>&lt;prerequisites&gt;    &lt;maven&gt;2.0.6&lt;/maven&gt;&lt;/prerequisites&gt;</code></pre><p>repositories,pluginRepositories</p><p>依赖和扩展的远程仓库列表，同上篇文章，setting.xml配置中介绍的。</p><pre><code>&lt;repositories&gt;    &lt;repository&gt;      &lt;releases&gt;        &lt;enabled&gt;false&lt;/enabled&gt;        &lt;updatePolicy&gt;always&lt;/updatePolicy&gt;        &lt;checksumPolicy&gt;warn&lt;/checksumPolicy&gt;      &lt;/releases&gt;      &lt;snapshots&gt;        &lt;enabled&gt;true&lt;/enabled&gt;        &lt;updatePolicy&gt;never&lt;/updatePolicy&gt;        &lt;checksumPolicy&gt;fail&lt;/checksumPolicy&gt;      &lt;/snapshots&gt;      &lt;id&gt;codehausSnapshots&lt;/id&gt;      &lt;name&gt;Codehaus Snapshots&lt;/name&gt;      &lt;url&gt;http://snapshots.maven.codehaus.org/maven2&lt;/url&gt;      &lt;layout&gt;default&lt;/layout&gt;    &lt;/repository&gt;  &lt;/repositories&gt;  &lt;pluginRepositories&gt;    ...  &lt;/pluginRepositories&gt;</code></pre><ul><li>releases, snapshots:这是各种构件的策略，release或者snapshot。这两个集合，POM就可以根据独立仓库任意类型的依赖改变策略。如：一个人可能只激活下载snapshot用来开发。</li><li>enable：true或者false，决定仓库是否对于各自的类型激活(release 或者 snapshot)。</li><li>updatePolicy: 这个元素决定更新频率。maven将比较本地pom的时间戳（存储在仓库的maven数据文件中）和远程的. 有以下选择: always, daily (默认), interval:X (x是代表分钟的整型) ， never.</li><li>checksumPolicy：当Maven向仓库部署文件的时候，它也部署了相应的校验和文件。可选的为：ignore，fail，warn，或者不正确的校验和。</li><li>layout：在上面描述仓库的时候，提到他们有统一的布局。Maven 2有它仓库默认布局。然而，Maven 1.x有不同布局。使用这个元素来表明它是default还是legacy。      </li></ul><p>distributionManagement</p><p>它管理的分布在整个构建过程生成的工件和支持文件</p><pre><code>&lt;distributionManagement&gt;    ...    &lt;downloadUrl&gt;http://mojo.codehaus.org/my-project&lt;/downloadUrl&gt;    &lt;status&gt;deployed&lt;/status&gt;&lt;/distributionManagement&gt;</code></pre><ul><li>downloadUrl: 其他pom可以通过此url的仓库抓取组件</li><li>status：给出该构件在远程仓库的状态 <ul><li>none: 默认</li><li>converted: 将被早期Maven 2 POM转换过来</li><li>partner: 这个项目会从合作者仓库同步过来</li><li>deployed: 从Maven 2或3实例部署</li><li>verified: 被核实时正确的和最终的    </li></ul></li></ul><p>Repository</p><p>指定Maven pom从远程下载控件到当前项目的位置和方式，如果snapshotRepository没有被定义则使用repository相关的配置</p><pre><code>&lt;distributionManagement&gt;   &lt;repository&gt;     &lt;uniqueVersion&gt;false&lt;/uniqueVersion&gt;     &lt;id&gt;corp1&lt;/id&gt;     &lt;name&gt;Corporate Repository&lt;/name&gt;     &lt;url&gt;scp://repo/maven2&lt;/url&gt;     &lt;layout&gt;default&lt;/layout&gt;   &lt;/repository&gt;   &lt;snapshotRepository&gt;     &lt;uniqueVersion&gt;true&lt;/uniqueVersion&gt;     &lt;id&gt;propSnap&lt;/id&gt;     &lt;name&gt;Propellors Snapshots&lt;/name&gt;     &lt;url&gt;sftp://propellers.net/maven&lt;/url&gt;     &lt;layout&gt;legacy&lt;/layout&gt;   &lt;/snapshotRepository&gt;   ... &lt;/distributionManagement&gt;</code></pre><ul><li>id, name：仓库的唯一标识</li><li>uniqueVersion：true或false，指明控件部署的时候是否获取独立的版本号。</li><li>url：repository元素的核心。指定位置和部署协议发布控件到仓库。</li><li>layout：布局，default或legacy</li></ul><p>Site Distribution</p><p>多分布存储库,distributionManagement负责定义如何部署项目的网站和文档。</p><pre><code>&lt;distributionManagement&gt;   ...   &lt;site&gt;     &lt;id&gt;mojo.website&lt;/id&gt;     &lt;name&gt;Mojo Website&lt;/name&gt;     &lt;url&gt;scp://beaver.codehaus.org/home/projects/mojo/public_html/&lt;/url&gt;   &lt;/site&gt;   ... &lt;/distributionManagement&gt;</code></pre><ul><li>id, name, url: 这些元素与distributionManagement repository中的相同</li></ul><p>Relocation</p><p>重新部署-项目不是静态的，是活的。他们需要被搬到更合适的地方。如：当你的下个成功的开源项目移到Apache下，重命名为org.apache:my-project:1.0 对你项目更有好处。</p><pre><code>&lt;distributionManagement&gt;    ...    &lt;relocation&gt;      &lt;groupId&gt;org.apache&lt;/groupId&gt;      &lt;artifactId&gt;my-project&lt;/artifactId&gt;      &lt;version&gt;1.0&lt;/version&gt;      &lt;message&gt;We have moved the Project under Apache&lt;/message&gt;    &lt;/relocation&gt;    ... &lt;/distributionManagement&gt;</code></pre><p><strong>原文链接: <a href="http://blog.csdn.net/oDeviloo/article/details/52050277" target="_blank" rel="external">http://blog.csdn.net/oDeviloo/article/details/52050277</a></strong><br><strong>参考官方文档： <a href="http://maven.apache.org/pom.html" target="_blank" rel="external">http://maven.apache.org/pom.html</a></strong>   </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Maven pom.xml详细配置说明&lt;/p&gt;
    
    </summary>
    
    
      <category term="Maven" scheme="http://www.zhz.gift/tags/Maven/"/>
    
  </entry>
  
</feed>
